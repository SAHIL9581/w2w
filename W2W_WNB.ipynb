{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO2mq/tGzL3ez0/cazOHeSg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SAHIL9581/w2w/blob/main/W2W_WNB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Setup Environment & Install Libraries\n",
        "\n",
        "# --- 1. Install All Required Libraries ---\n",
        "print(\"--> Installing all necessary Python libraries (this may take a few minutes)...\")\n",
        "!pip install wandb torch torchvision torchaudio lasio scikit-learn pandas tqdm matplotlib joblib pyyaml -q\n",
        "print(\"✅ Library installation complete.\")\n",
        "\n",
        "\n",
        "# --- 2. Define and Change to Project Directory ---\n",
        "import os\n",
        "\n",
        "# IMPORTANT: This folder is TEMPORARY. All local files will be DELETED when the Colab session ends.\n",
        "# Your results and models will be saved to your online W&B account.\n",
        "PROJECT_PATH = '/content/W2W_Pipeline_WandB'\n",
        "\n",
        "print(f\"\\n--> Setting up a temporary project directory at: {PROJECT_PATH}\")\n",
        "os.makedirs(f\"{PROJECT_PATH}/data/raw_las_files\", exist_ok=True)\n",
        "os.makedirs(f\"{PROJECT_PATH}/artifacts\", exist_ok=True)\n",
        "os.makedirs(f\"{PROJECT_PATH}/trained_models/autoencoder\", exist_ok=True)\n",
        "os.makedirs(f\"{PROJECT_PATH}/trained_models/boundary_detector\", exist_ok=True)\n",
        "\n",
        "# Change the current working directory to the project path\n",
        "os.chdir(PROJECT_PATH)\n",
        "print(f\"✅ Current directory changed to: {os.getcwd()}\")\n",
        "print(\"\\n--- Setup Complete ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRzHJfB1JNuw",
        "outputId": "36344044-b1f4-4206-e79c-15dd46f1f4e1"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> Installing all necessary Python libraries (this may take a few minutes)...\n",
            "✅ Library installation complete.\n",
            "\n",
            "--> Setting up a temporary project directory at: /content/W2W_Pipeline_WandB\n",
            "✅ Current directory changed to: /content/W2W_Pipeline_WandB\n",
            "\n",
            "--- Setup Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Login to Weights & Biases\n",
        "import wandb\n",
        "\n",
        "print(\"--> ACTION REQUIRED: Please log in to your Weights & Biases account.\")\n",
        "# You will be prompted to paste your W&B API key.\n",
        "# You can find your key here: https://wandb.ai/authorize\n",
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgO3SWzHJNw_",
        "outputId": "fbe55a8c-b197-480b-d588-3c74a4225a2f"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> ACTION REQUIRED: Please log in to your Weights & Biases account.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msahilpareek203\u001b[0m (\u001b[33msahilpareek203-amrita-vishwa-vidyapeetham\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Upload ZIP File with .las Data\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\">>> ACTION REQUIRED: Please upload the ZIP file containing your .las files.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if not uploaded:\n",
        "    print(\"\\n⚠️ Upload was cancelled or failed. Please run this cell again.\")\n",
        "else:\n",
        "    zip_filename = list(uploaded.keys())[0]\n",
        "    print(f\"\\n✅ '{zip_filename}' uploaded successfully.\")\n",
        "\n",
        "    # Unzip into the designated raw data folder\n",
        "    !unzip -q -o \"{zip_filename}\" -d data/raw_las_files/\n",
        "\n",
        "    print(\"--> ZIP file has been unzipped into 'data/raw_las_files/'.\")\n",
        "\n",
        "    # Clean up the uploaded zip file from the root directory\n",
        "    os.remove(zip_filename)\n",
        "    print(\"\\n✅ Data upload is complete. You can now proceed to the next step.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "iYbOznxCJNzP",
        "outputId": "71e42e77-7d05-41c1-93d4-6951b9376495"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> ACTION REQUIRED: Please upload the ZIP file containing your .las files.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8e276f68-a637-4138-a704-38da651f037f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8e276f68-a637-4138-a704-38da651f037f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train.zip to train.zip\n",
            "\n",
            "✅ 'train.zip' uploaded successfully.\n",
            "--> ZIP file has been unzipped into 'data/raw_las_files/'.\n",
            "\n",
            "✅ Data upload is complete. You can now proceed to the next step.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. Pipeline Configuration (Corrected)\n",
        "# All settings for the pipeline are controlled from this Python dictionary.\n",
        "\n",
        "config = {\n",
        "    \"run_data_preparation\": True,\n",
        "    \"run_pretraining\": True,\n",
        "    \"run_finetuning\": True,\n",
        "    \"run_inference\": True,\n",
        "\n",
        "    \"paths\": {\n",
        "        \"raw_las_folder\": \"data/raw_las_files/\",\n",
        "        \"processed_csv_path\": \"data/train.csv\",\n",
        "        \"label_encoder_path\": \"artifacts/label_encoder.json\",\n",
        "        \"std_scaler_path\": \"artifacts/StandardScaler.bin\",\n",
        "        \"pretrained_encoder_path\": \"trained_models/autoencoder/best_autoencoder.pt\",\n",
        "        \"final_model_path\": \"trained_models/boundary_detector/final_model.pt\"\n",
        "    },\n",
        "\n",
        "    \"wandb\": {\n",
        "        \"project\": \"W2W_Matcher_Pipeline_Notebook\", # Your W&B project name\n",
        "        \"entity\": None,                             # Your W&B username or team name (optional)\n",
        "        \"sweep_count\": 5                            # Number of hyperparameter combinations to try\n",
        "    },\n",
        "\n",
        "    \"pretraining_sweep\": {\n",
        "        \"name\": \"Autoencoder-Pre-training-Sweep\",\n",
        "        \"method\": \"random\",\n",
        "        \"metric\": {\"name\": \"loss\", \"goal\": \"minimize\"},\n",
        "        \"parameters\": {\n",
        "            \"epochs\": {\"value\": 25},\n",
        "            \"optimizer\": {\"values\": [\"RMSprop\", \"AdamW\", \"Adam\"]},\n",
        "            \"lr\": {\"values\": [0.001, 0.0001]},\n",
        "            \"act_name\": {\"values\": [\"prelu\", \"relu\"]},\n",
        "            \"batch_size\": {\"values\": [16, 32]},\n",
        "            # 'in_channels' will be added here automatically by the data prep step\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"finetuning\": {\n",
        "        \"learning_rate\": 0.0001, \"batch_size\": 16, \"epochs\": 100,\n",
        "        \"model_params\": {\n",
        "            # 'in_channels' is REMOVED from here. It will be added automatically.\n",
        "            \"patch_height\": 700, \"act_name\": \"prelu\",\n",
        "            \"project_in_features\": 2048, \"hidden_dim\": 256, \"num_queries\": 100,\n",
        "            \"num_heads\": 8, \"dropout\": 0.1, \"expansion_factor\": 4,\n",
        "            \"num_transformers\": 6, \"output_size\": 3\n",
        "        },\n",
        "        \"matcher_costs\": {\"set_cost_class\": 1, \"set_cost_bbox\": 5},\n",
        "        \"loss_weights\": {\"loss_matching\": 1.0, \"loss_unmatching\": 0.5, \"loss_height_constraint\": 0.5}\n",
        "    },\n",
        "\n",
        "    \"inference\": {\n",
        "        # IMPORTANT: Change these to valid well names from your data after running the Data Prep cell.\n",
        "        \"reference_well\": \"15_9-F-1 A\",\n",
        "        \"well_of_interest\": \"15_9-F-1 B\",\n",
        "        \"correlation_threshold\": 0.7\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"✅ Configuration dictionary created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbucfMA2JN1v",
        "outputId": "0f29629d-fe82-464f-a255-a3ae4a95d686"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Configuration dictionary created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5. Define Data Preparation Function (Corrected)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lasio\n",
        "import json\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from joblib import dump\n",
        "\n",
        "def run_data_preparation(config):\n",
        "    print(\"--- LAUNCHING PIPELINE 0: DATA PREPARATION ---\")\n",
        "    paths = config['paths']\n",
        "    search_folder = paths['raw_las_folder']\n",
        "    all_wells_df, las_files_found = [], []\n",
        "\n",
        "    print(f\"--> Searching for .las files in '{search_folder}'...\")\n",
        "    for root, dirs, files in os.walk(search_folder):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.las'):\n",
        "                las_files_found.append(os.path.join(root, file))\n",
        "\n",
        "    if not las_files_found: raise FileNotFoundError(f\"No .las files found in '{search_folder}'.\")\n",
        "    print(f\"--> Found {len(las_files_found)} .las files. Reading now...\")\n",
        "\n",
        "    for filepath in las_files_found:\n",
        "        try:\n",
        "            las = lasio.read(filepath)\n",
        "            df = las.df().reset_index()\n",
        "            df['WELL'] = las.well.WELL.value or os.path.splitext(os.path.basename(filepath))[0]\n",
        "            df['GROUP'] = 'UNKNOWN'\n",
        "            for param in las.params:\n",
        "                if 'GROUP' in param.mnemonic.upper(): df['GROUP'] = param.value\n",
        "            all_wells_df.append(df)\n",
        "        except Exception as e: print(f\"    - Could not read {filepath}: {e}\")\n",
        "\n",
        "    if not all_wells_df: raise ValueError(\"Could not process any .las files.\")\n",
        "    master_df = pd.concat(all_wells_df, ignore_index=True)\n",
        "    if 'DEPT' in master_df.columns: master_df.rename(columns={'DEPT': 'DEPTH_MD'}, inplace=True)\n",
        "    master_df.to_csv(paths['processed_csv_path'], index=False, sep=';')\n",
        "    print(f\"--> Saved combined data to '{paths['processed_csv_path']}'\")\n",
        "\n",
        "    unique_wells = master_df['WELL'].unique()\n",
        "    print(\"\\n--- Available Well Names for Inference ---\")\n",
        "    for well in unique_wells: print(f\"- {well}\")\n",
        "    print(\"------------------------------------------\")\n",
        "    print(\"TIP: Copy/paste two of these names into the 'inference' section of the config cell above.\\n\")\n",
        "\n",
        "    label_encoder = {str(g): i for i, g in enumerate(master_df['GROUP'].unique())}\n",
        "    with open(paths['label_encoder_path'], 'w') as f: json.dump(label_encoder, f, indent=4)\n",
        "    print(f\"--> Saved label encoder to '{paths['label_encoder_path']}'\")\n",
        "\n",
        "    cols_to_drop = ['WELL', 'GROUP'] + [col for col in master_df.columns if 'DEPT' in col.upper()]\n",
        "    numeric_df = master_df.drop(columns=cols_to_drop, errors='ignore').fillna(0)\n",
        "    scaler = StandardScaler().fit(numeric_df)\n",
        "    dump(scaler, paths['std_scaler_path'])\n",
        "    print(f\"--> Saved StandardScaler to '{paths['std_scaler_path']}'\")\n",
        "\n",
        "    # --- CRUCIAL FIX: Dynamically add the number of features to the config ---\n",
        "    num_features = scaler.n_features_in_\n",
        "    print(f\"\\n✅ Automatically detected {num_features} features (input channels) from the data.\")\n",
        "    config['finetuning']['model_params']['in_channels'] = num_features\n",
        "    config['pretraining_sweep']['parameters']['in_channels'] = {'value': num_features}\n",
        "    # --- END OF FIX ---\n",
        "\n",
        "print(\"✅ Data preparation function defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVqmQuw1JN3a",
        "outputId": "f2040878-7652-448e-d68b-e0d5399f9371"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Data preparation function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6. Define Dataset Classes (Corrected)\n",
        "import torch\n",
        "from torch.utils import data\n",
        "from joblib import load\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- CORRECTED: AutoencoderDataset now creates patches ---\n",
        "class AutoencoderDataset(data.Dataset):\n",
        "    def __init__(self, c):\n",
        "        p = c['paths']\n",
        "        # Use the same patch height as the fine-tuning stage for consistency\n",
        "        patch_height = c['finetuning']['model_params']['patch_height']\n",
        "\n",
        "        df = pd.read_csv(p['processed_csv_path'], delimiter=';')\n",
        "        scaler = load(p['std_scaler_path'])\n",
        "\n",
        "        self.data_patches = []\n",
        "        # Group by each well to create contiguous patches\n",
        "        for well_name, well_df in df.groupby('WELL'):\n",
        "            cols_to_drop = ['WELL', 'GROUP'] + [col for col in well_df.columns if 'DEPT' in col.upper()]\n",
        "            well_numeric = well_df.drop(columns=cols_to_drop, errors='ignore').fillna(0)\n",
        "\n",
        "            # Ensure the scaler is applied with the correct feature names\n",
        "            if hasattr(scaler, 'feature_names_in_'):\n",
        "                well_numeric = well_numeric[scaler.feature_names_in_]\n",
        "\n",
        "            scaled_data = scaler.transform(well_numeric).astype(np.float32)\n",
        "\n",
        "            # Create patches from this well's data\n",
        "            for i in range(0, len(scaled_data) - patch_height + 1, patch_height):\n",
        "                patch = scaled_data[i:i + patch_height]\n",
        "                # The input to Conv1d should be (channels, length)\n",
        "                self.data_patches.append(patch.T)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_patches)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        patch = self.data_patches[i]\n",
        "        return torch.from_numpy(patch), torch.from_numpy(patch)\n",
        "\n",
        "class BoundaryDataset(data.Dataset):\n",
        "    def __init__(self, c, seed=None):\n",
        "        self.p, self.d = c['finetuning']['model_params'], c['paths']\n",
        "        self.s = seed or np.random.randint(2**32 - 1)\n",
        "        self.x, self.gt = self.get_Xy()\n",
        "\n",
        "    def get_Xy(self):\n",
        "        d = pd.read_csv(self.d['processed_csv_path'], delimiter=';')\n",
        "        np.random.seed(self.s)\n",
        "        w = d[d['WELL'] == np.random.choice(d.WELL.unique())].copy()\n",
        "\n",
        "        with open(self.d['label_encoder_path']) as f: le = json.load(f)\n",
        "        w['GROUP'] = w['GROUP'].astype(str).map(le).bfill().ffill()\n",
        "\n",
        "        cols_to_drop = ['WELL', 'GROUP'] + [col for col in w.columns if 'DEPT' in col.upper()]\n",
        "        w_numeric = w.drop(columns=cols_to_drop, errors='ignore').fillna(0)\n",
        "\n",
        "        scaler = load(self.d['std_scaler_path'])\n",
        "        if hasattr(scaler, 'feature_names_in_'):\n",
        "            w_numeric = w_numeric[scaler.feature_names_in_]\n",
        "\n",
        "        s_d = scaler.transform(w_numeric)\n",
        "\n",
        "        ph = self.p['patch_height']\n",
        "        idx = list(range(0, s_d.shape[0], ph))\n",
        "        x = np.asarray([s_d[i:i + ph] for i in idx if len(s_d[i:i + ph]) == ph], dtype=np.float32)\n",
        "        y = np.asarray([w['GROUP'].values[i:i + ph] for i in idx if len(w['GROUP'].values[i:i + ph]) == ph])\n",
        "        return x, self._get_gt_boundaries(y)\n",
        "\n",
        "    def _get_gt_boundaries(self, y_patches):\n",
        "        gts = []\n",
        "        for y in y_patches:\n",
        "            gt, c = {}, 0\n",
        "            boundaries = np.where(y[:-1] != y[1:])[0] + 1\n",
        "            k = np.concatenate(([0], boundaries, [len(y)]))\n",
        "            for i in range(len(k) - 1):\n",
        "                top, bottom = k[i], k[i+1]\n",
        "                gt[c] = {'Group': int(y[top]), 'Top': top, 'Height': bottom - top}; c += 1\n",
        "            gts.append(gt)\n",
        "        return gts\n",
        "\n",
        "    def __len__(self): return len(self.x)\n",
        "    def __getitem__(self, idx):\n",
        "        img = np.expand_dims(self.x[idx], 0)\n",
        "        data = self.gt[idx]\n",
        "        ph = self.p['patch_height']\n",
        "        tops = torch.tensor([d['Top'] / ph for d in data.values()], dtype=torch.float32).view(-1, 1)\n",
        "        heights = torch.tensor([d['Height'] / ph for d in data.values()], dtype=torch.float32).view(-1, 1)\n",
        "        tgt = {'labels': torch.ones(len(data), dtype=torch.long), 'loc_info': torch.hstack((tops, heights))}\n",
        "        return torch.from_numpy(img), tgt\n",
        "\n",
        "print(\"✅ Dataset classes corrected for patching.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfmlV46sJN5v",
        "outputId": "a13b6adc-55d0-4078-e84a-ba3671c6077b"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset classes corrected for patching.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 7. Define Model Architectures (Corrected and Robust)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def get_activation(name): return nn.PReLU() if name == 'prelu' else nn.ReLU() if name == 'relu' else nn.GELU()\n",
        "\n",
        "class Block1D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=2, kernel_size=3, activation='prelu'):\n",
        "        super().__init__()\n",
        "        self.b = nn.Sequential(\n",
        "            nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding=kernel_size//2),\n",
        "            nn.BatchNorm1d(out_channels), get_activation(activation),\n",
        "            nn.Conv1d(out_channels, out_channels, kernel_size, 1, padding=kernel_size//2),\n",
        "            nn.BatchNorm1d(out_channels), get_activation(activation)\n",
        "        )\n",
        "    def forward(self, x): return self.b(x)\n",
        "\n",
        "# --- CORRECTED: UNet1D with robust skip connections ---\n",
        "class UNet1D(nn.Module):\n",
        "    def __init__(self, in_channels, activation='prelu'):\n",
        "        super().__init__()\n",
        "        self.start = nn.Sequential(nn.Conv1d(in_channels, 32, 3, 1, 1), nn.BatchNorm1d(32), get_activation(activation))\n",
        "        self.e1 = Block1D(32, 64, 2, a=activation)\n",
        "        self.e2 = Block1D(64, 128, 2, a=activation)\n",
        "        self.e3 = Block1D(128, 256, 2, a=activation)\n",
        "        self.mid = nn.Sequential(nn.Conv1d(256, 512, 3, 1, 1), nn.BatchNorm1d(512), get_activation(activation))\n",
        "        self.uc3 = nn.ConvTranspose1d(512, 256, 2, 2)\n",
        "        self.d3 = Block1D(512, 256, 1, a=activation)\n",
        "        self.uc2 = nn.ConvTranspose1d(256, 128, 2, 2)\n",
        "        self.d2 = Block1D(256, 128, 1, a=activation)\n",
        "        self.uc1 = nn.ConvTranspose1d(128, 64, 2, 2)\n",
        "        self.d1 = Block1D(128, 64, 1, a=activation)\n",
        "        self.out = nn.Conv1d(64, in_channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input shape from AutoencoderDataset is already [batch, channels, length]\n",
        "        x1_skip = self.start(x)\n",
        "        x2_skip = self.e1(x1_skip)\n",
        "        x3_skip = self.e2(x2_skip)\n",
        "        x4_skip = self.e3(x3_skip)\n",
        "        m = self.mid(x4_skip)\n",
        "\n",
        "        u3 = self.uc3(m)\n",
        "        # Add resizing to ensure dimensions match\n",
        "        u3 = F.interpolate(u3, size=x4_skip.shape[2], mode='linear', align_corners=False)\n",
        "        d3 = self.d3(torch.cat((u3, x4_skip), 1))\n",
        "\n",
        "        u2 = self.uc2(d3)\n",
        "        u2 = F.interpolate(u2, size=x3_skip.shape[2], mode='linear', align_corners=False)\n",
        "        d2 = self.d2(torch.cat((u2, x3_skip), 1))\n",
        "\n",
        "        u1 = self.uc1(d2)\n",
        "        u1 = F.interpolate(u1, size=x2_skip.shape[2], mode='linear', align_corners=False)\n",
        "        d1 = self.d1(torch.cat((u1, x2_skip), 1))\n",
        "\n",
        "        # There is one more upsampling needed to match the original input size\n",
        "        out = F.interpolate(d1, size=x1_skip.shape[2], mode='linear', align_corners=False)\n",
        "        return self.out(out)\n",
        "\n",
        "class UNetEncoder1D(nn.Module):\n",
        "    def __init__(self, in_channels, activation='prelu'):\n",
        "        super().__init__()\n",
        "        self.start = nn.Sequential(nn.Conv1d(in_channels, 32, 3, 1, 1), nn.BatchNorm1d(32), get_activation(activation))\n",
        "        self.e1 = Block1D(32, 64, 2, a=activation)\n",
        "        self.e2 = Block1D(64, 128, 2, a=activation)\n",
        "        self.e3 = Block1D(128, 256, 2, a=activation)\n",
        "        self.mid = nn.Sequential(nn.Conv1d(256, 512, 3, 1, 1), nn.BatchNorm1d(512), get_activation(activation))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.squeeze(1).permute(0, 2, 1)\n",
        "        x1 = self.e1(self.start(x))\n",
        "        x2 = self.e2(x1)\n",
        "        x3 = self.e3(x2)\n",
        "        return self.mid(x3)\n",
        "\n",
        "class Project(nn.Module):\n",
        "    def __init__(self,i,o): super().__init__(); self.l=nn.Linear(i,o)\n",
        "    def forward(self,x): return self.l(x.flatten(1))\n",
        "\n",
        "class Query(nn.Module):\n",
        "    def __init__(self,s,d): super().__init__(); self.q=nn.Parameter(torch.randn(1,s,d))\n",
        "    def forward(self,x): return self.q.repeat(x.shape[0],1,1)\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self,i,n,d): super().__init__(); self.t=nn.TransformerEncoderLayer(d_model=i,nhead=n,dropout=d,batch_first=True,dim_feedforward=i*4)\n",
        "    def forward(self,q,c): return self.t(q)\n",
        "\n",
        "class W2WTransformerModel(nn.Module):\n",
        "    def __init__(self,c):\n",
        "        super().__init__()\n",
        "        p = c['finetuning']['model_params']\n",
        "        self.encoder = UNetEncoder1D(p['in_channels'], p['act_name'])\n",
        "        project_in_features = 512 * (p['patch_height'] // 8)\n",
        "        self.project = Project(project_in_features, p['hidden_dim'])\n",
        "        self.query = Query(p['num_queries'], p['hidden_dim'])\n",
        "        self.transformers = nn.ModuleList([Transformer(p['hidden_dim'],p['num_heads'],p['dropout']) for _ in range(p['num_transformers'])])\n",
        "        self.finalize = nn.Sequential(nn.Linear(p['hidden_dim'], p['output_size']), get_activation(p['act_name']), nn.LayerNorm(p['output_size']))\n",
        "\n",
        "    def forward(self,img):\n",
        "        encoded_features = self.encoder(img)\n",
        "        # Permute from [B, C, L] to [B, L, C] for projection and transformer\n",
        "        encoded_features = encoded_features.permute(0, 2, 1)\n",
        "        projected_seq = self.project(encoded_features)\n",
        "        q = self.query(projected_seq)\n",
        "        for t in self.transformers: q = t(q, projected_seq)\n",
        "        return self.finalize(q)\n",
        "\n",
        "print(\"✅ Model architectures corrected and made robust for 1D data.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naTJURjiJN7x",
        "outputId": "0fefe316-a5e7-4771-c696-917c40498114"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model architectures corrected and made robust for 1D data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 8. Define Matcher and Loss Functions\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class HungarianMatcher(nn.Module):\n",
        "    def __init__(self,c,b): super().__init__(); self.c,self.b=c,b\n",
        "    @torch.no_grad()\n",
        "    def forward(self,o,t):\n",
        "        op,ob=o[:,:,:1].flatten(0,1).sigmoid(),o[:,:,1:].flatten(0,1)\n",
        "        tb=torch.cat([v[\"loc_info\"] for v in t]).to(op.device)\n",
        "        C=(self.b*torch.cdist(ob,tb,p=1) - self.c*op[:,0]).view(o.shape[0],o.shape[1],-1).cpu()\n",
        "        return [(torch.as_tensor(i),torch.as_tensor(j)) for i,j in [linear_sum_assignment(c) for c in C.split([len(v[\"loc_info\"]) for v in t],-1)]]\n",
        "class SetCriterion(nn.Module):\n",
        "    def __init__(self,c):\n",
        "        super().__init__(); p=c['finetuning']; self.m=HungarianMatcher(p['matcher_costs']['set_cost_class'],p['matcher_costs']['set_cost_bbox']); self.w=p['loss_weights']; self.nq=p['model_params']['num_queries']\n",
        "    def loss_match(self,o,t,i): i=self._get_src_p_idx(i); return {'loss_matching':F.l1_loss(o[i],torch.cat([torch.cat((torch.ones_like(v[\"loc_info\"][:,:1]),v[\"loc_info\"]),1) for v,(_,j) in zip(t,i) if len(j)>0]))}\n",
        "    def loss_unmatch(self,o,t,i): return {'loss_unmatching': torch.cat([out[torch.where(torch.ones(self.nq,dtype=bool))[0],0] for out in o]).mean()}\n",
        "    def loss_height(self,o,t,i): return {'loss_height_constraint':sum([abs(ht[j].sum()-1) for ht,(j,_) in zip(o[:,:,2],i) if len(j)>0])/o.shape[0]}\n",
        "    def _get_src_p_idx(self,i): b=torch.cat([torch.full_like(s,k) for k,(s,_) in enumerate(i)]); s=torch.cat([s for s,_ in i]); return b,s\n",
        "    def forward(self,o,t): i=self.m(o,t); return {ln: l for ln,l in {**self.loss_match(o,t,i),**self.loss_unmatch(o,t,i),**self.loss_height(o,t,i)}.items() if self.w[ln]>0}\n",
        "\n",
        "print(\"✅ Matcher and loss functions defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkCs711SJN9w",
        "outputId": "74479f1c-6b7f-4b14-dfe9-c4bd894d99a0"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Matcher and loss functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 9. Define Helper and Utility Functions\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images, targets = zip(*batch)\n",
        "    return torch.stack(images), list(targets)\n",
        "\n",
        "def load_pretrained_encoder_weights(model, path):\n",
        "    print(f\"--> Loading pre-trained weights from {path}\")\n",
        "    pre_dict = torch.load(path)\n",
        "    model_dict = model.state_dict()\n",
        "    enc_dict = {k.replace('module.',''):v for k,v in pre_dict.items() if any(x in k for x in ['e1','e2','e3','mid','start'])}\n",
        "    enc_dict = {'encoder.'+k:v for k,v in enc_dict.items()}\n",
        "    model_dict.update(enc_dict)\n",
        "    model.load_state_dict(model_dict, strict=False)\n",
        "    print(f\"✅ Loaded {len(enc_dict)} pre-trained layers.\")\n",
        "    return model\n",
        "\n",
        "print(\"✅ Helper functions defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VustgxDJJOAq",
        "outputId": "ef9bc2bf-d032-4240-fba8-3a08426b0ae5"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Helper functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 10. Define Pre-training Stage Function (W&B Sweep) (Corrected)\n",
        "from tqdm import tqdm\n",
        "\n",
        "# A global variable to track the best loss across all sweep runs\n",
        "best_pretrain_loss = float('inf')\n",
        "\n",
        "def train_autoencoder_sweep():\n",
        "    global best_pretrain_loss, config\n",
        "    with wandb.init() as run:\n",
        "        sweep_cfg = wandb.config\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # --- CORRECTED: Use the new UNet1D model ---\n",
        "        model = UNet1D(in_channels=sweep_cfg.in_channels, activation=sweep_cfg.act_name).to(device)\n",
        "\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = getattr(torch.optim, sweep_cfg.optimizer)(model.parameters(), lr=sweep_cfg.lr)\n",
        "        train_loader = data.DataLoader(AutoencoderDataset(config), batch_size=sweep_cfg.batch_size, shuffle=True)\n",
        "\n",
        "        print(f\"--- Starting W&B Run with config: {dict(sweep_cfg)} ---\")\n",
        "        for epoch in range(sweep_cfg.epochs):\n",
        "            model.train()\n",
        "            total_loss = 0.0\n",
        "            for img, tgt in train_loader:\n",
        "                img, tgt = img.to(device), tgt.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                output = model(img)\n",
        "                loss = criterion(output, tgt)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            epoch_loss = total_loss / len(train_loader)\n",
        "            wandb.log({\"epoch\": epoch, \"loss\": epoch_loss})\n",
        "\n",
        "            if epoch_loss < best_pretrain_loss:\n",
        "                best_pretrain_loss = epoch_loss\n",
        "                print(f\"    *** New best model found! Loss: {best_pretrain_loss:.6f} (Epoch {epoch+1}) ***\")\n",
        "                torch.save(model.state_dict(), config['paths']['pretrained_encoder_path'])\n",
        "                wandb.summary[\"best_loss\"] = best_pretrain_loss\n",
        "\n",
        "print(\"✅ Pre-training (sweep) function defined with 1D U-Net.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKvDhkF-JOCi",
        "outputId": "90fda903-cdc3-4d3d-f637-d59330940a81"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Pre-training (sweep) function defined with 1D U-Net.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 11. Define Fine-tuning Stage Function\n",
        "\n",
        "def run_finetuning(config):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    ft_params = config['finetuning']\n",
        "    loader = data.DataLoader(BoundaryDataset(config, seed=42), batch_size=ft_params['batch_size'], shuffle=True, collate_fn=collate_fn)\n",
        "    model = W2WTransformerModel(config).to(device)\n",
        "    model = load_pretrained_encoder_weights(model, config['paths']['pretrained_encoder_path'])\n",
        "    criterion = SetCriterion(config).to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=ft_params['learning_rate'])\n",
        "\n",
        "    for epoch in range(ft_params['epochs']):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for images, targets in tqdm(loader, desc=f'Epoch {epoch+1}/{ft_params[\"epochs\"]}'):\n",
        "            images, targets = images.to(device), [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "            loss_dict = criterion(model(images), targets)\n",
        "            losses = sum(loss_dict[k] * criterion.w[k] for k in loss_dict.keys())\n",
        "            optimizer.zero_grad(); losses.backward(); optimizer.step()\n",
        "            total_loss += losses.item(); wandb.log({'finetune_batch_loss': losses.item()})\n",
        "\n",
        "        avg_loss = total_loss / len(loader)\n",
        "        print(f'Epoch {epoch+1} Average Loss: {avg_loss:.4f}')\n",
        "        wandb.log({'finetune_epoch_loss': avg_loss, 'epoch': epoch})\n",
        "\n",
        "    torch.save(model.state_dict(), config['paths']['final_model_path'])\n",
        "    print(f\"✅ Final model saved to {config['paths']['final_model_path']}\")\n",
        "\n",
        "print(\"✅ Fine-tuning function defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-Iw7726JOGh",
        "outputId": "7545e8ff-8371-4958-971a-0d9a8ff704bb"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fine-tuning function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 12. Define Inference and Plotting Functions\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def plot_well_correlation(well1, well2, layers1, layers2, matrix, threshold, path):\n",
        "    fig, ax = plt.subplots(figsize=(10, 12)); plt.style.use('seaborn-whitegrid')\n",
        "    if not layers1 or not layers2: print('Warning: One or both wells have no layers to plot.'); return\n",
        "    max_depth = max(layers1[-1]['bottom'], layers2[-1]['bottom']) if layers1 and layers2 else 1000\n",
        "    ax.set_ylim(max_depth + 50, -50); ax.set_xlim(-0.5, 2.5)\n",
        "    n1 = len(set(l['Group'] for l in layers1)); n2 = len(set(l['Group'] for l in layers2))\n",
        "    for l in layers1: ax.add_patch(patches.Rectangle((0, l['Top']), 1, l['Height'], ec='k', fc=plt.cm.viridis(l['Group']/(n1 if n1>0 else 1)), alpha=0.6))\n",
        "    for l in layers2: ax.add_patch(patches.Rectangle((1.5, l['Top']), 1, l['Height'], ec='k', fc=plt.cm.viridis(l['Group']/(n2 if n2>0 else 1)), alpha=0.6))\n",
        "    for i, row in enumerate(matrix):\n",
        "        for j, sim in enumerate(row):\n",
        "            if sim >= threshold: ax.add_patch(patches.Polygon([[1,layers1[i]['Top']],[1,layers1[i]['bottom']],[1.5,layers2[j]['bottom']],[1.5,layers2[j]['Top']]], fc=plt.cm.Greens(sim), alpha=0.5))\n",
        "    ax.set_xticks([0.5, 2]); ax.set_xticklabels([well1, well2], fontsize=14); ax.set_ylabel('Depth', fontsize=12)\n",
        "    ax.set_title('Well to Well Correlation', fontsize=16); plt.savefig(path); plt.close()\n",
        "    print(f'--> Correlation plot saved to {path}')\n",
        "\n",
        "def run_correlation(config):\n",
        "    inf, p = config['inference'], config['paths']\n",
        "    full_data = pd.read_csv(p['processed_csv_path'], delimiter=';')\n",
        "    ref_df, woi_df = full_data[full_data['WELL'] == inf['reference_well']], full_data[full_data['WELL'] == inf['well_of_interest']]\n",
        "    if ref_df.empty or woi_df.empty: print(f\"Error: One/both wells not found: '{inf['reference_well']}', '{inf['well_of_interest']}'.\"); return\n",
        "\n",
        "    with open(p['label_encoder_path']) as f: le = json.load(f)\n",
        "    def get_true_layers(df):\n",
        "        df = df.copy().reset_index(drop=True)\n",
        "        df['group_id'] = df['GROUP'].astype(str).map(le).fillna(-1).astype(int)\n",
        "        b = np.where(df['group_id'].iloc[:-1].values != df['group_id'].iloc[1:].values)[0] + 1\n",
        "        indices = np.concatenate(([0], b, [len(df)]))\n",
        "        layers = []\n",
        "        for i in range(len(indices) - 1):\n",
        "            s, e = indices[i], indices[i+1]\n",
        "            layers.append({'Top':df['DEPTH_MD'].iloc[s],'bottom':df['DEPTH_MD'].iloc[e-1],'Height':df['DEPTH_MD'].iloc[e-1]-df['DEPTH_MD'].iloc[s],'Group':df['group_id'].iloc[s]})\n",
        "        return layers\n",
        "\n",
        "    ref_layers, woi_layers = get_true_layers(ref_df), get_true_layers(woi_df)\n",
        "    sim_matrix = np.zeros((len(ref_layers), len(woi_layers)))\n",
        "    for i,l1 in enumerate(ref_layers):\n",
        "        for j,l2 in enumerate(woi_layers):\n",
        "            if l1['Group'] == l2['Group'] and l1['Group'] != -1: sim_matrix[i,j] = np.random.uniform(0.8, 0.95)\n",
        "            else: sim_matrix[i,j] = np.random.uniform(0.1, 0.4)\n",
        "\n",
        "    print('--> MOCK INFERENCE: Using ground truth layers for visualization.')\n",
        "    output_path = 'well_correlation_plot.png'\n",
        "    plot_well_correlation(inf['reference_well'], inf['well_of_interest'], ref_layers, woi_layers, sim_matrix, inf['correlation_threshold'], output_path)\n",
        "    wandb.log({\"well_correlation_plot\": wandb.Image(output_path)})\n",
        "\n",
        "print(\"✅ Inference and plotting functions defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bGlyIyTJOIw",
        "outputId": "2d4a99ca-4545-49ac-bb17-e2912f9ba840"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Inference and plotting functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 13. 🚀 Run the Full Pipeline\n",
        "\n",
        "# --- STAGE 0: DATA PREPARATION ---\n",
        "if config[\"run_data_preparation\"]:\n",
        "    run_data_preparation(config)\n",
        "    print(\"\\n--- STAGE 0 COMPLETE ---\\n\")\n",
        "\n",
        "# --- STAGE 1: PRE-TRAINING (W&B SWEEP) ---\n",
        "if config.get('run_pretraining', False):\n",
        "    print(\"\\n--- LAUNCHING PIPELINE 1: AUTOENCODER PRE-TRAINING (W&B SWEEP) ---\")\n",
        "    sweep_id = wandb.sweep(config['pretraining_sweep'], project=config['wandb']['project'], entity=config['wandb'].get('entity'))\n",
        "    wandb.agent(sweep_id, function=train_autoencoder_sweep, count=config['wandb']['sweep_count'])\n",
        "    print(f\"\\n🏆 Sweep finished. Best pre-trained model saved to {config['paths']['pretrained_encoder_path']}\")\n",
        "    print(\"\\n--- STAGE 1 COMPLETE ---\\n\")\n",
        "\n",
        "# --- STAGE 2: FINE-TUNING ---\n",
        "if config.get('run_finetuning', False):\n",
        "    print(\"\\n--- LAUNCHING PIPELINE 2: FINE-TUNING ---\")\n",
        "    with wandb.init(project=config['wandb']['project'], entity=config['wandb'].get('entity'), job_type='fine-tuning', config=config) as run:\n",
        "        print(f\"--> W&B Run started. View at: {run.get_url()}\")\n",
        "        run_finetuning(config)\n",
        "        artifact = wandb.Artifact(\"boundary-detector-model\", type=\"model\", description=\"Final fine-tuned W2W Transformer model\")\n",
        "        artifact.add_file(config['paths']['final_model_path'])\n",
        "        run.log_artifact(artifact)\n",
        "        print(\"✅ Final model logged as a W&B Artifact.\")\n",
        "    print(\"\\n--- STAGE 2 COMPLETE ---\\n\")\n",
        "\n",
        "# --- STAGE 3: INFERENCE ---\n",
        "if config.get('run_inference', False):\n",
        "    print(\"\\n--- LAUNCHING PIPELINE 3: WELL-TO-WELL INFERENCE ---\")\n",
        "    with wandb.init(project=config['wandb']['project'], entity=config['wandb'].get('entity'), job_type='inference', config=config) as run:\n",
        "        print(f\"--> W&B Run started. View at: {run.get_url()}\")\n",
        "        run_correlation(config)\n",
        "    print(\"\\n--- STAGE 3 COMPLETE ---\\n\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✅✅✅ All Requested Pipeline Stages are Complete! ✅✅✅\")\n",
        "print(\"You can view all your results, models, and charts in your Weights & Biases project.\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YNHZ52v_JOK7",
        "outputId": "988896c2-68b5-42d0-c11e-afd831c711a6"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- LAUNCHING PIPELINE 0: DATA PREPARATION ---\n",
            "--> Searching for .las files in 'data/raw_las_files/'...\n",
            "--> Found 118 .las files. Reading now...\n",
            "--> Saved combined data to 'data/train.csv'\n",
            "\n",
            "--- Available Well Names for Inference ---\n",
            "- 17/11-1\n",
            "- 31/2-10\n",
            "- 35/11-1\n",
            "- 35/9-8\n",
            "- 35/11-6\n",
            "- 34/10-19\n",
            "- 15/9-17\n",
            "- 31/3-2\n",
            "- 15/9-13 Sleipner East Appr\n",
            "- 34/12-1\n",
            "- 25/2-13 T4\n",
            "- 16/10-5 Isbjoern\n",
            "- 33/6-3 S\n",
            "- 31/2-7\n",
            "- 17/4-1\n",
            "- 25/5-4  Byggve\n",
            "- 16/11-1S T3\n",
            "- 16/1-6 A Verdandi Appr\n",
            "- 34/6-1\n",
            "- 34/4-10 R\n",
            "- 16/2-6 Johan Sverdrup\n",
            "- 31/2-9\n",
            "- 30/3-5S\n",
            "- 25/4-5\n",
            "- 25/8-5 S  Jotun\n",
            "- 36/7-3\n",
            "- 31/2-8\n",
            "- 34/5-1 A\n",
            "- 34/8-3\n",
            "- 33/9-1\n",
            "- 34/5-1 S\n",
            "- 25/11-24 Jakob South\n",
            "- 35/4-1\n",
            "- 15/9-15 Gungne\n",
            "- 35/11-13\n",
            "- 34/10-33\n",
            "- 16/2-11 A Johan Sverdrup Appr\n",
            "- 31/6-5\n",
            "- 16/1-2  Ivar Aasen Appr\n",
            "- 31/3-3\n",
            "- 35/9-2\n",
            "- 25/7-2\n",
            "- 35/6-2 S\n",
            "- 33/9-17\n",
            "- 25/3-1\n",
            "- 35/11-7\n",
            "- 25/10-10  Balder Triassic\n",
            "- 29/3-1\n",
            "- 31/5-4 S\n",
            "- 31/6-8\n",
            "- 31/2-1\n",
            "- 32/2-1\n",
            "- 29/6-1\n",
            "- 35/11-10\n",
            "- 16/4-1\n",
            "- 34/8-1\n",
            "- 25/8-7  Krap 1\n",
            "- 34/10-21\n",
            "- 25/11-15  Grane\n",
            "- 16/10-2 Delta\n",
            "- 31/4-5\n",
            "- 35/11-5\n",
            "- 16/7-4 Sigyn\n",
            "- 15/9-23 Skardkollen\n",
            "- 7/1-1\n",
            "- 25/6-3\n",
            "- 35/12-1\n",
            "- 34/11-1\n",
            "- 25/11-19 S  Balder Appr\n",
            "- 34/8-7R\n",
            "- 16/2-16 Johan Sverdrup Appr\n",
            "- 25/2-7\n",
            "- 34/7-21\n",
            "- 35/3-7 S\n",
            "- 16/10-1 Alpha\n",
            "- 34/3-2 S\n",
            "- 25/10-9 Aegis\n",
            "- 35/8-4\n",
            "- 25/2-14 Froey Appr\n",
            "- 35/11-11\n",
            "- 25/9-1  Rummel\n",
            "- 25/5-1 Froey\n",
            "- 31/3-4\n",
            "- 16/10-3 Tyr Central\n",
            "- 35/11-15 S\n",
            "- 25/11-5 Balder Appr\n",
            "- 34/3-1 A\n",
            "- 16/8-1\n",
            "- 35/9-6 S\n",
            "- 31/2-19 S\n",
            "- 34/10-16R\n",
            "- 30/3-3\n",
            "- 33/5-2\n",
            "- 35/9-10 S\n",
            "- 30/6-5\n",
            "- 34/7-20\n",
            "- 35/9-5\n",
            "- 34/11-2 S\n",
            "- 25/6-1\n",
            "- 34/10-35\n",
            "- 35/8-6 S\n",
            "- 34/3-3 A\n",
            "- 15/9-14\n",
            "- 34/2-4\n",
            "- 31/2-21 S\n",
            "- 31/3-1\n",
            "- 34/7-13\n",
            "- 25/5-3  Skirne\n",
            "- 16/7-6\n",
            "- 26/4-1\n",
            "- 16/2-7 Johan Sverdrup Appr\n",
            "- 25/6-2  Delta-Beta\n",
            "- 7/1-2 S\n",
            "- 35/11-12\n",
            "- 16/7-5\n",
            "- 16/5-3 Johan Sverdrup Appr\n",
            "- 35/9-7\n",
            "- 31/4-10\n",
            "------------------------------------------\n",
            "TIP: Copy/paste two of these names into the 'inference' section of the config cell above.\n",
            "\n",
            "--> Saved label encoder to 'artifacts/label_encoder.json'\n",
            "--> Saved StandardScaler to 'artifacts/StandardScaler.bin'\n",
            "\n",
            "✅ Automatically detected 25 features (input channels) from the data.\n",
            "\n",
            "--- STAGE 0 COMPLETE ---\n",
            "\n",
            "\n",
            "--- LAUNCHING PIPELINE 1: AUTOENCODER PRE-TRAINING (W&B SWEEP) ---\n",
            "Create sweep with ID: ceptx1dt\n",
            "Sweep URL: https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ceptx1dt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bzyzfun2 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tact_name: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_channels: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: AdamW\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250717_182712-bzyzfun2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/bzyzfun2' target=\"_blank\">likely-sweep-1</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ceptx1dt' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ceptx1dt</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ceptx1dt' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ceptx1dt</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/bzyzfun2' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/bzyzfun2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-100-776563796.py\", line 14, in train_autoencoder_sweep\n",
            "    model = UNet1D(in_channels=sweep_cfg.in_channels, activation=sweep_cfg.act_name).to(device)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-97-1972233692.py\", line 24, in __init__\n",
            "    self.e1 = Block1D(32, 64, 2, a=activation)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "TypeError: Block1D.__init__() got an unexpected keyword argument 'a'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">likely-sweep-1</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/bzyzfun2' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/bzyzfun2</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250717_182712-bzyzfun2/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run bzyzfun2 errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 302, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipython-input-100-776563796.py\", line 14, in train_autoencoder_sweep\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = UNet1D(in_channels=sweep_cfg.in_channels, activation=sweep_cfg.act_name).to(device)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipython-input-97-1972233692.py\", line 24, in __init__\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.e1 = Block1D(32, 64, 2, a=activation)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m TypeError: Block1D.__init__() got an unexpected keyword argument 'a'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2duj75m4 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tact_name: prelu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_channels: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250717_182718-2duj75m4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/2duj75m4' target=\"_blank\">lunar-sweep-2</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ceptx1dt' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ceptx1dt</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ceptx1dt' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ceptx1dt</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/2duj75m4' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/2duj75m4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-100-776563796.py\", line 14, in train_autoencoder_sweep\n",
            "    model = UNet1D(in_channels=sweep_cfg.in_channels, activation=sweep_cfg.act_name).to(device)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-97-1972233692.py\", line 24, in __init__\n",
            "    self.e1 = Block1D(32, 64, 2, a=activation)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "TypeError: Block1D.__init__() got an unexpected keyword argument 'a'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lunar-sweep-2</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/2duj75m4' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/2duj75m4</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250717_182718-2duj75m4/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 2duj75m4 errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 302, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipython-input-100-776563796.py\", line 14, in train_autoencoder_sweep\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = UNet1D(in_channels=sweep_cfg.in_channels, activation=sweep_cfg.act_name).to(device)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipython-input-97-1972233692.py\", line 24, in __init__\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.e1 = Block1D(32, 64, 2, a=activation)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m TypeError: Block1D.__init__() got an unexpected keyword argument 'a'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: c5691rqs with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tact_name: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_channels: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: AdamW\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250717_182722-c5691rqs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/c5691rqs' target=\"_blank\">ethereal-sweep-3</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ceptx1dt' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ceptx1dt</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ceptx1dt' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ceptx1dt</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/c5691rqs' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/c5691rqs</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-100-776563796.py\", line 14, in train_autoencoder_sweep\n",
            "    model = UNet1D(in_channels=sweep_cfg.in_channels, activation=sweep_cfg.act_name).to(device)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-97-1972233692.py\", line 24, in __init__\n",
            "    self.e1 = Block1D(32, 64, 2, a=activation)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "TypeError: Block1D.__init__() got an unexpected keyword argument 'a'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">ethereal-sweep-3</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/c5691rqs' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/c5691rqs</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250717_182722-c5691rqs/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run c5691rqs errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 302, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipython-input-100-776563796.py\", line 14, in train_autoencoder_sweep\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = UNet1D(in_channels=sweep_cfg.in_channels, activation=sweep_cfg.act_name).to(device)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipython-input-97-1972233692.py\", line 24, in __init__\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.e1 = Block1D(32, 64, 2, a=activation)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m TypeError: Block1D.__init__() got an unexpected keyword argument 'a'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Detected 3 failed runs in the first 60 seconds, killing sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🏆 Sweep finished. Best pre-trained model saved to trained_models/autoencoder/best_autoencoder.pt\n",
            "\n",
            "--- STAGE 1 COMPLETE ---\n",
            "\n",
            "\n",
            "--- LAUNCHING PIPELINE 2: FINE-TUNING ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'W2W_Matcher_Pipeline_Notebook' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250717_182724-c5691rqs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/c5691rqs' target=\"_blank\">ethereal-sweep-3</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ceptx1dt' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ceptx1dt</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ceptx1dt' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ceptx1dt</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/c5691rqs' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/c5691rqs</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> W&B Run started. View at: https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/c5691rqs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-103-3650830744.py\", line 21, in <cell line: 0>\n",
            "    run_finetuning(config)\n",
            "  File \"/tmp/ipython-input-101-2990093839.py\", line 7, in run_finetuning\n",
            "    model = W2WTransformerModel(config).to(device)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-97-1972233692.py\", line 93, in __init__\n",
            "    self.encoder = UNetEncoder1D(p['in_channels'], p['act_name'])\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-97-1972233692.py\", line 65, in __init__\n",
            "    self.e1 = Block1D(32, 64, 2, a=activation)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "TypeError: Block1D.__init__() got an unexpected keyword argument 'a'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">ethereal-sweep-3</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/c5691rqs' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/c5691rqs</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250717_182724-c5691rqs/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Block1D.__init__() got an unexpected keyword argument 'a'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-103-3650830744.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wandb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'project'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wandb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'entity'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fine-tuning'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"--> W&B Run started. View at: {run.get_url()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mrun_finetuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0martifact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArtifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"boundary-detector-model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Final fine-tuned W2W Transformer model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0martifact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'paths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'final_model_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-101-2990093839.py\u001b[0m in \u001b[0;36mrun_finetuning\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mft_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'finetuning'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBoundaryDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mft_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW2WTransformerModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_pretrained_encoder_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'paths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pretrained_encoder_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSetCriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-97-1972233692.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, c)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'finetuning'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNetEncoder1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'in_channels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'act_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mproject_in_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'patch_height'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_in_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hidden_dim'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-97-1972233692.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, activation)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlock1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlock1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlock1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Block1D.__init__() got an unexpected keyword argument 'a'"
          ]
        }
      ]
    }
  ]
}