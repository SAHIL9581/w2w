{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOgNc9twK8I2zYjGpDO739C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SAHIL9581/w2w/blob/main/W2W_WNB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Setup Environment & Install Libraries\n",
        "\n",
        "# --- 1. Install All Required Libraries ---\n",
        "print(\"--> Installing all necessary Python libraries (this may take a few minutes)...\")\n",
        "!pip install wandb torch torchvision torchaudio lasio scikit-learn pandas tqdm matplotlib joblib pyyaml -q\n",
        "print(\"✅ Library installation complete.\")\n",
        "\n",
        "\n",
        "# --- 2. Define and Change to Project Directory ---\n",
        "import os\n",
        "\n",
        "# IMPORTANT: This folder is TEMPORARY. All local files will be DELETED when the Colab session ends.\n",
        "# Your results and models will be saved to your online W&B account.\n",
        "PROJECT_PATH = '/content/W2W_Pipeline_WandB'\n",
        "\n",
        "print(f\"\\n--> Setting up a temporary project directory at: {PROJECT_PATH}\")\n",
        "os.makedirs(f\"{PROJECT_PATH}/data/raw_las_files\", exist_ok=True)\n",
        "os.makedirs(f\"{PROJECT_PATH}/artifacts\", exist_ok=True)\n",
        "os.makedirs(f\"{PROJECT_PATH}/trained_models/autoencoder\", exist_ok=True)\n",
        "os.makedirs(f\"{PROJECT_PATH}/trained_models/boundary_detector\", exist_ok=True)\n",
        "\n",
        "# Change the current working directory to the project path\n",
        "os.chdir(PROJECT_PATH)\n",
        "print(f\"✅ Current directory changed to: {os.getcwd()}\")\n",
        "print(\"\\n--- Setup Complete ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRzHJfB1JNuw",
        "outputId": "2091a869-fbad-47f3-aee3-992730e72234"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> Installing all necessary Python libraries (this may take a few minutes)...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✅ Library installation complete.\n",
            "\n",
            "--> Setting up a temporary project directory at: /content/W2W_Pipeline_WandB\n",
            "✅ Current directory changed to: /content/W2W_Pipeline_WandB\n",
            "\n",
            "--- Setup Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Login to Weights & Biases\n",
        "import wandb\n",
        "\n",
        "print(\"--> ACTION REQUIRED: Please log in to your Weights & Biases account.\")\n",
        "# You will be prompted to paste your W&B API key.\n",
        "# You can find your key here: https://wandb.ai/authorize\n",
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgO3SWzHJNw_",
        "outputId": "47c140ca-bad9-48c6-9476-1cd7a4c85638"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> ACTION REQUIRED: Please log in to your Weights & Biases account.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msahilpareek203\u001b[0m (\u001b[33msahilpareek203-amrita-vishwa-vidyapeetham\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Upload ZIP File with .las Data\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\">>> ACTION REQUIRED: Please upload the ZIP file containing your .las files.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if not uploaded:\n",
        "    print(\"\\n⚠️ Upload was cancelled or failed. Please run this cell again.\")\n",
        "else:\n",
        "    zip_filename = list(uploaded.keys())[0]\n",
        "    print(f\"\\n✅ '{zip_filename}' uploaded successfully.\")\n",
        "\n",
        "    # Unzip into the designated raw data folder\n",
        "    !unzip -q -o \"{zip_filename}\" -d data/raw_las_files/\n",
        "\n",
        "    print(\"--> ZIP file has been unzipped into 'data/raw_las_files/'.\")\n",
        "\n",
        "    # Clean up the uploaded zip file from the root directory\n",
        "    os.remove(zip_filename)\n",
        "    print(\"\\n✅ Data upload is complete. You can now proceed to the next step.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "iYbOznxCJNzP",
        "outputId": "a7d5df72-85ed-4071-9242-8ce0299f4946"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> ACTION REQUIRED: Please upload the ZIP file containing your .las files.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-23dda17d-08e6-41c9-bff4-696ec1f1c0cd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-23dda17d-08e6-41c9-bff4-696ec1f1c0cd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train.zip to train.zip\n",
            "\n",
            "✅ 'train.zip' uploaded successfully.\n",
            "--> ZIP file has been unzipped into 'data/raw_las_files/'.\n",
            "\n",
            "✅ Data upload is complete. You can now proceed to the next step.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. Pipeline Configuration (Corrected)\n",
        "# All settings for the pipeline are controlled from this Python dictionary.\n",
        "\n",
        "config = {\n",
        "    \"run_data_preparation\": True,\n",
        "    \"run_pretraining\": True,\n",
        "    \"run_finetuning\": True,\n",
        "    \"run_inference\": True,\n",
        "\n",
        "    \"paths\": {\n",
        "        \"raw_las_folder\": \"data/raw_las_files/\",\n",
        "        \"processed_csv_path\": \"data/train.csv\",\n",
        "        \"label_encoder_path\": \"artifacts/label_encoder.json\",\n",
        "        \"std_scaler_path\": \"artifacts/StandardScaler.bin\",\n",
        "        \"pretrained_encoder_path\": \"trained_models/autoencoder/best_autoencoder.pt\",\n",
        "        \"final_model_path\": \"trained_models/boundary_detector/final_model.pt\"\n",
        "    },\n",
        "\n",
        "    \"wandb\": {\n",
        "        \"project\": \"W2W_Matcher_Pipeline_Notebook\", # Your W&B project name\n",
        "        \"entity\": None,                             # Your W&B username or team name (optional)\n",
        "        \"sweep_count\": 5                            # Number of hyperparameter combinations to try\n",
        "    },\n",
        "\n",
        "    \"pretraining_sweep\": {\n",
        "        \"name\": \"Autoencoder-Pre-training-Sweep\",\n",
        "        \"method\": \"random\",\n",
        "        \"metric\": {\"name\": \"loss\", \"goal\": \"minimize\"},\n",
        "        \"parameters\": {\n",
        "            \"epochs\": {\"value\": 25},\n",
        "            \"optimizer\": {\"values\": [\"RMSprop\", \"AdamW\", \"Adam\"]},\n",
        "            \"lr\": {\"values\": [0.001, 0.0001]},\n",
        "            \"act_name\": {\"values\": [\"prelu\", \"relu\"]},\n",
        "            \"batch_size\": {\"values\": [16, 32]},\n",
        "            # 'in_channels' will be added here automatically by the data prep step\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"finetuning\": {\n",
        "        \"learning_rate\": 0.0001, \"batch_size\": 16, \"epochs\": 100,\n",
        "        \"model_params\": {\n",
        "            # 'in_channels' is REMOVED from here. It will be added automatically.\n",
        "            \"patch_height\": 700, \"act_name\": \"prelu\",\n",
        "            \"project_in_features\": 2048, \"hidden_dim\": 256, \"num_queries\": 100,\n",
        "            \"num_heads\": 8, \"dropout\": 0.1, \"expansion_factor\": 4,\n",
        "            \"num_transformers\": 6, \"output_size\": 3\n",
        "        },\n",
        "        \"matcher_costs\": {\"set_cost_class\": 1, \"set_cost_bbox\": 5},\n",
        "        \"loss_weights\": {\"loss_matching\": 1.0, \"loss_unmatching\": 0.5, \"loss_height_constraint\": 0.5}\n",
        "    },\n",
        "\n",
        "    \"inference\": {\n",
        "        # IMPORTANT: Change these to valid well names from your data after running the Data Prep cell.\n",
        "        \"reference_well\": \"15_9-F-1 A\",\n",
        "        \"well_of_interest\": \"15_9-F-1 B\",\n",
        "        \"correlation_threshold\": 0.7\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"✅ Configuration dictionary created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbucfMA2JN1v",
        "outputId": "f5d35888-da05-4f4b-afcc-87eb3a996670"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Configuration dictionary created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5. Define Data Preparation Function (Corrected)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lasio\n",
        "import json\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from joblib import dump\n",
        "\n",
        "def run_data_preparation(config):\n",
        "    print(\"--- LAUNCHING PIPELINE 0: DATA PREPARATION ---\")\n",
        "    paths = config['paths']\n",
        "    search_folder = paths['raw_las_folder']\n",
        "    all_wells_df, las_files_found = [], []\n",
        "\n",
        "    print(f\"--> Searching for .las files in '{search_folder}'...\")\n",
        "    for root, dirs, files in os.walk(search_folder):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.las'):\n",
        "                las_files_found.append(os.path.join(root, file))\n",
        "\n",
        "    if not las_files_found: raise FileNotFoundError(f\"No .las files found in '{search_folder}'.\")\n",
        "    print(f\"--> Found {len(las_files_found)} .las files. Reading now...\")\n",
        "\n",
        "    for filepath in las_files_found:\n",
        "        try:\n",
        "            las = lasio.read(filepath)\n",
        "            df = las.df().reset_index()\n",
        "            df['WELL'] = las.well.WELL.value or os.path.splitext(os.path.basename(filepath))[0]\n",
        "            df['GROUP'] = 'UNKNOWN'\n",
        "            for param in las.params:\n",
        "                if 'GROUP' in param.mnemonic.upper(): df['GROUP'] = param.value\n",
        "            all_wells_df.append(df)\n",
        "        except Exception as e: print(f\"    - Could not read {filepath}: {e}\")\n",
        "\n",
        "    if not all_wells_df: raise ValueError(\"Could not process any .las files.\")\n",
        "    master_df = pd.concat(all_wells_df, ignore_index=True)\n",
        "    if 'DEPT' in master_df.columns: master_df.rename(columns={'DEPT': 'DEPTH_MD'}, inplace=True)\n",
        "    master_df.to_csv(paths['processed_csv_path'], index=False, sep=';')\n",
        "    print(f\"--> Saved combined data to '{paths['processed_csv_path']}'\")\n",
        "\n",
        "    unique_wells = master_df['WELL'].unique()\n",
        "    print(\"\\n--- Available Well Names for Inference ---\")\n",
        "    for well in unique_wells: print(f\"- {well}\")\n",
        "    print(\"------------------------------------------\")\n",
        "    print(\"TIP: Copy/paste two of these names into the 'inference' section of the config cell above.\\n\")\n",
        "\n",
        "    label_encoder = {str(g): i for i, g in enumerate(master_df['GROUP'].unique())}\n",
        "    with open(paths['label_encoder_path'], 'w') as f: json.dump(label_encoder, f, indent=4)\n",
        "    print(f\"--> Saved label encoder to '{paths['label_encoder_path']}'\")\n",
        "\n",
        "    cols_to_drop = ['WELL', 'GROUP'] + [col for col in master_df.columns if 'DEPT' in col.upper()]\n",
        "    numeric_df = master_df.drop(columns=cols_to_drop, errors='ignore').fillna(0)\n",
        "    scaler = StandardScaler().fit(numeric_df)\n",
        "    dump(scaler, paths['std_scaler_path'])\n",
        "    print(f\"--> Saved StandardScaler to '{paths['std_scaler_path']}'\")\n",
        "\n",
        "    # --- CRUCIAL FIX: Dynamically add the number of features to the config ---\n",
        "    num_features = scaler.n_features_in_\n",
        "    print(f\"\\n✅ Automatically detected {num_features} features (input channels) from the data.\")\n",
        "    config['finetuning']['model_params']['in_channels'] = num_features\n",
        "    config['pretraining_sweep']['parameters']['in_channels'] = {'value': num_features}\n",
        "    # --- END OF FIX ---\n",
        "\n",
        "print(\"✅ Data preparation function defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVqmQuw1JN3a",
        "outputId": "4ebd4397-0e0d-42ef-91dd-c8c3d7be1aca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Data preparation function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6. Define Dataset Classes (Corrected)\n",
        "import torch\n",
        "from torch.utils import data\n",
        "from joblib import load\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- CORRECTED: AutoencoderDataset now creates patches ---\n",
        "class AutoencoderDataset(data.Dataset):\n",
        "    def __init__(self, c):\n",
        "        p = c['paths']\n",
        "        # Use the same patch height as the fine-tuning stage for consistency\n",
        "        patch_height = c['finetuning']['model_params']['patch_height']\n",
        "\n",
        "        df = pd.read_csv(p['processed_csv_path'], delimiter=';')\n",
        "        scaler = load(p['std_scaler_path'])\n",
        "\n",
        "        self.data_patches = []\n",
        "        # Group by each well to create contiguous patches\n",
        "        for well_name, well_df in df.groupby('WELL'):\n",
        "            cols_to_drop = ['WELL', 'GROUP'] + [col for col in well_df.columns if 'DEPT' in col.upper()]\n",
        "            well_numeric = well_df.drop(columns=cols_to_drop, errors='ignore').fillna(0)\n",
        "\n",
        "            # Ensure the scaler is applied with the correct feature names\n",
        "            if hasattr(scaler, 'feature_names_in_'):\n",
        "                well_numeric = well_numeric[scaler.feature_names_in_]\n",
        "\n",
        "            scaled_data = scaler.transform(well_numeric).astype(np.float32)\n",
        "\n",
        "            # Create patches from this well's data\n",
        "            for i in range(0, len(scaled_data) - patch_height + 1, patch_height):\n",
        "                patch = scaled_data[i:i + patch_height]\n",
        "                # The input to Conv1d should be (channels, length)\n",
        "                self.data_patches.append(patch.T)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_patches)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        patch = self.data_patches[i]\n",
        "        return torch.from_numpy(patch), torch.from_numpy(patch)\n",
        "\n",
        "class BoundaryDataset(data.Dataset):\n",
        "    def __init__(self, c, seed=None):\n",
        "        self.p, self.d = c['finetuning']['model_params'], c['paths']\n",
        "        self.s = seed or np.random.randint(2**32 - 1)\n",
        "        self.x, self.gt = self.get_Xy()\n",
        "\n",
        "    def get_Xy(self):\n",
        "        d = pd.read_csv(self.d['processed_csv_path'], delimiter=';')\n",
        "        np.random.seed(self.s)\n",
        "        w = d[d['WELL'] == np.random.choice(d.WELL.unique())].copy()\n",
        "\n",
        "        with open(self.d['label_encoder_path']) as f: le = json.load(f)\n",
        "        w['GROUP'] = w['GROUP'].astype(str).map(le).bfill().ffill()\n",
        "\n",
        "        cols_to_drop = ['WELL', 'GROUP'] + [col for col in w.columns if 'DEPT' in col.upper()]\n",
        "        w_numeric = w.drop(columns=cols_to_drop, errors='ignore').fillna(0)\n",
        "\n",
        "        scaler = load(self.d['std_scaler_path'])\n",
        "        if hasattr(scaler, 'feature_names_in_'):\n",
        "            w_numeric = w_numeric[scaler.feature_names_in_]\n",
        "\n",
        "        s_d = scaler.transform(w_numeric)\n",
        "\n",
        "        ph = self.p['patch_height']\n",
        "        idx = list(range(0, s_d.shape[0], ph))\n",
        "        x = np.asarray([s_d[i:i + ph] for i in idx if len(s_d[i:i + ph]) == ph], dtype=np.float32)\n",
        "        y = np.asarray([w['GROUP'].values[i:i + ph] for i in idx if len(w['GROUP'].values[i:i + ph]) == ph])\n",
        "        return x, self._get_gt_boundaries(y)\n",
        "\n",
        "    def _get_gt_boundaries(self, y_patches):\n",
        "        gts = []\n",
        "        for y in y_patches:\n",
        "            gt, c = {}, 0\n",
        "            boundaries = np.where(y[:-1] != y[1:])[0] + 1\n",
        "            k = np.concatenate(([0], boundaries, [len(y)]))\n",
        "            for i in range(len(k) - 1):\n",
        "                top, bottom = k[i], k[i+1]\n",
        "                gt[c] = {'Group': int(y[top]), 'Top': top, 'Height': bottom - top}; c += 1\n",
        "            gts.append(gt)\n",
        "        return gts\n",
        "\n",
        "    def __len__(self): return len(self.x)\n",
        "    def __getitem__(self, idx):\n",
        "        img = np.expand_dims(self.x[idx], 0)\n",
        "        data = self.gt[idx]\n",
        "        ph = self.p['patch_height']\n",
        "        tops = torch.tensor([d['Top'] / ph for d in data.values()], dtype=torch.float32).view(-1, 1)\n",
        "        heights = torch.tensor([d['Height'] / ph for d in data.values()], dtype=torch.float32).view(-1, 1)\n",
        "        tgt = {'labels': torch.ones(len(data), dtype=torch.long), 'loc_info': torch.hstack((tops, heights))}\n",
        "        return torch.from_numpy(img), tgt\n",
        "\n",
        "print(\"✅ Dataset classes corrected for patching.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfmlV46sJN5v",
        "outputId": "f6e798b3-ab1f-4087-ff5a-cfeed641df36"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset classes corrected for patching.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 7. Define Model Architectures (Final Corrected Version)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def get_activation(name):\n",
        "    \"\"\"Returns the activation function based on the provided name.\"\"\"\n",
        "    return nn.PReLU() if name == 'prelu' else nn.ReLU() if name == 'relu' else nn.GELU()\n",
        "\n",
        "class Block1D(nn.Module):\n",
        "    \"\"\"A basic 1D convolutional block with two convolution layers.\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride=2, kernel_size=3, activation='prelu'):\n",
        "        super().__init__()\n",
        "        self.b = nn.Sequential(\n",
        "            nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding=kernel_size//2),\n",
        "            nn.BatchNorm1d(out_channels), get_activation(activation),\n",
        "            nn.Conv1d(out_channels, out_channels, kernel_size, 1, padding=kernel_size//2),\n",
        "            nn.BatchNorm1d(out_channels), get_activation(activation)\n",
        "        )\n",
        "    def forward(self, x): return self.b(x)\n",
        "\n",
        "class UNet1D(nn.Module):\n",
        "    \"\"\"A 1D U-Net architecture with robust skip connections.\"\"\"\n",
        "    def __init__(self, in_channels, activation='prelu'):\n",
        "        super().__init__()\n",
        "        self.start = Block1D(in_channels, 32, stride=1, activation=activation)\n",
        "        self.e1 = Block1D(32, 64, stride=2, activation=activation)\n",
        "        self.e2 = Block1D(64, 128, stride=2, activation=activation)\n",
        "        self.e3 = Block1D(128, 256, stride=2, activation=activation)\n",
        "        self.mid = Block1D(256, 512, stride=2, activation=activation)\n",
        "        self.uc3 = nn.ConvTranspose1d(512, 256, 2, 2)\n",
        "        self.d3 = Block1D(512, 256, stride=1, activation=activation)\n",
        "        self.uc2 = nn.ConvTranspose1d(256, 128, 2, 2)\n",
        "        self.d2 = Block1D(256, 128, stride=1, activation=activation)\n",
        "        self.uc1 = nn.ConvTranspose1d(128, 64, 2, 2)\n",
        "        self.d1 = Block1D(128, 64, stride=1, activation=activation)\n",
        "        self.uc0 = nn.ConvTranspose1d(64, 32, 2, 2)\n",
        "        self.d0 = Block1D(64, 32, stride=1, activation=activation)\n",
        "        self.out_conv = nn.Conv1d(32, in_channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        s1 = self.start(x); s2 = self.e1(s1); s3 = self.e2(s2); s4 = self.e3(s3); m = self.mid(s4)\n",
        "        d3 = self.d3(torch.cat((F.interpolate(self.uc3(m), size=s4.shape[2]), s4), 1))\n",
        "        d2 = self.d2(torch.cat((F.interpolate(self.uc2(d3), size=s3.shape[2]), s3), 1))\n",
        "        d1 = self.d1(torch.cat((F.interpolate(self.uc1(d2), size=s2.shape[2]), s2), 1))\n",
        "        d0 = self.d0(torch.cat((F.interpolate(self.uc0(d1), size=s1.shape[2]), s1), 1))\n",
        "        return self.out_conv(d0)\n",
        "\n",
        "class UNetEncoder1D(nn.Module):\n",
        "    \"\"\"The encoder part of the 1D U-Net.\"\"\"\n",
        "    def __init__(self, in_channels, activation='prelu'):\n",
        "        super().__init__()\n",
        "        self.start = Block1D(in_channels, 32, stride=1, activation=activation)\n",
        "        self.e1 = Block1D(32, 64, stride=2, activation=activation)\n",
        "        self.e2 = Block1D(64, 128, stride=2, activation=activation)\n",
        "        self.e3 = Block1D(128, 256, stride=2, activation=activation)\n",
        "        self.mid = Block1D(256, 512, stride=2, activation=activation)\n",
        "    def forward(self, x):\n",
        "        x = x.squeeze(1).permute(0, 2, 1); s1 = self.start(x); s2 = self.e1(s1); s3 = self.e2(s2); s4 = self.e3(s3); return self.mid(s4)\n",
        "\n",
        "class Project(nn.Module):\n",
        "    \"\"\"Projects flattened features to a different dimension.\"\"\"\n",
        "    def __init__(self, i, o): super().__init__(); self.l = nn.Linear(i, o)\n",
        "    def forward(self, x): return self.l(x.flatten(1))\n",
        "\n",
        "class Query(nn.Module):\n",
        "    \"\"\"Creates a learnable query tensor for the transformer.\"\"\"\n",
        "    def __init__(self, s, d): super().__init__(); self.q = nn.Parameter(torch.randn(1, s, d))\n",
        "    def forward(self, x): return self.q.repeat(x.shape[0], 1, 1)\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    \"\"\"A standard transformer encoder layer.\"\"\"\n",
        "    def __init__(self, i, n, d): super().__init__(); self.t = nn.TransformerEncoderLayer(d_model=i, nhead=n, dropout=d, batch_first=True, dim_feedforward=i * 4)\n",
        "    def forward(self, q, c): return self.t(q)\n",
        "\n",
        "class W2WTransformerModel(nn.Module):\n",
        "    \"\"\"A transformer-based model using a U-Net encoder.\"\"\"\n",
        "    def __init__(self, c):\n",
        "        super().__init__()\n",
        "        p = c['finetuning']['model_params']\n",
        "        self.encoder = UNetEncoder1D(p['in_channels'], p['act_name'])\n",
        "\n",
        "        # --- CRUCIAL FIX: Dynamically calculate the flattened feature size ---\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.randn(1, 1, p['patch_height'], p['in_channels'])\n",
        "            dummy_output = self.encoder(dummy_input)\n",
        "            p_in = dummy_output.flatten(1).shape[1]\n",
        "            print(f\"--> Dynamically calculated transformer input features: {p_in}\")\n",
        "        # --- END OF FIX ---\n",
        "\n",
        "        self.project = Project(p_in, p['hidden_dim'])\n",
        "        self.query = Query(p['num_queries'], p['hidden_dim'])\n",
        "        self.transformers = nn.ModuleList([Transformer(p['hidden_dim'], p['num_heads'], p['dropout']) for _ in range(p['num_transformers'])])\n",
        "        self.finalize = nn.Sequential(nn.Linear(p['hidden_dim'], p['output_size']), get_activation(p['act_name']), nn.LayerNorm(p['output_size']))\n",
        "\n",
        "    def forward(self, img):\n",
        "        encoded_output = self.encoder(img)\n",
        "        projected_seq = self.project(encoded_output).unsqueeze(1)\n",
        "        q = self.query(projected_seq)\n",
        "        for t in self.transformers:\n",
        "            q = t(q, projected_seq)\n",
        "        return self.finalize(q)\n",
        "\n",
        "print(\"✅ Model architectures defined, made robust, and fully symmetrical.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naTJURjiJN7x",
        "outputId": "a6889cd9-b1f0-4a2f-b106-93d62a09b38f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model architectures defined, made robust, and fully symmetrical.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 8. Define Matcher and Loss Functions (Final Corrected Version)\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class HungarianMatcher(nn.Module):\n",
        "    \"\"\"\n",
        "    This class computes an assignment between the model's predictions and the ground truth.\n",
        "    It loops through each sample in the batch to create a 2D cost matrix, which is what\n",
        "    the assignment algorithm expects.\n",
        "    \"\"\"\n",
        "    def __init__(self, cost_class: float = 1, cost_bbox: float = 1):\n",
        "        super().__init__()\n",
        "        self.cost_class = cost_class\n",
        "        self.cost_bbox = cost_bbox\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def forward(self, outputs, targets):\n",
        "        bs, num_queries = outputs.shape[:2]\n",
        "\n",
        "        indices = []\n",
        "        # --- CRUCIAL FIX: Iterate over each sample in the batch ---\n",
        "        for i in range(bs):\n",
        "            out_prob = outputs[i, :, :1].sigmoid() # Probabilities for this sample\n",
        "            out_bbox = outputs[i, :, 1:]           # Predicted boxes for this sample\n",
        "\n",
        "            tgt_bbox = targets[i][\"loc_info\"].to(out_prob.device) # Target boxes for this sample\n",
        "\n",
        "            # Compute the classification cost (L1)\n",
        "            cost_class = -out_prob\n",
        "\n",
        "            # Compute the L1 cost between boxes\n",
        "            cost_bbox = torch.cdist(out_bbox, tgt_bbox, p=1)\n",
        "\n",
        "            # Final cost matrix for this sample (shape: [num_queries, num_targets])\n",
        "            C = self.cost_bbox * cost_bbox + self.cost_class * cost_class\n",
        "\n",
        "            # Run the assignment algorithm on the 2D cost matrix\n",
        "            indices.append(linear_sum_assignment(C.cpu()))\n",
        "\n",
        "        return [(torch.as_tensor(i, dtype=torch.int64), torch.as_tensor(j, dtype=torch.int64)) for i, j in indices]\n",
        "\n",
        "\n",
        "class SetCriterion(nn.Module):\n",
        "    def __init__(self,c):\n",
        "        super().__init__(); p=c['finetuning']; self.m=HungarianMatcher(p['matcher_costs']['set_cost_class'],p['matcher_costs']['set_cost_bbox']); self.w=p['loss_weights']; self.nq=p['model_params']['num_queries']\n",
        "    def loss_match(self,o,t,i):\n",
        "        src_idx = self._get_src_p_idx(i)\n",
        "        target_boxes = torch.cat([v[\"loc_info\"][j] for v,(_,j) in zip(t,i) if len(j)>0], dim=0)\n",
        "        if target_boxes.numel() == 0: return {'loss_matching': torch.tensor(0.0, device=o.device)}\n",
        "\n",
        "        pred_boxes = o[src_idx]\n",
        "        return {'loss_matching': F.l1_loss(pred_boxes[:, 1:], target_boxes)}\n",
        "\n",
        "    def loss_unmatch(self,o,t,i):\n",
        "        # Create a mask for matched predictions\n",
        "        src_idx = self._get_src_p_idx(i)\n",
        "        mask = torch.ones(o.shape[0], o.shape[1], dtype=torch.bool, device=o.device)\n",
        "        mask[src_idx] = False\n",
        "\n",
        "        # Get the scores of unmatched predictions\n",
        "        unmatched_scores = o[mask][:, 0].sigmoid()\n",
        "        return {'loss_unmatching': unmatched_scores.mean()}\n",
        "\n",
        "    def loss_height(self,o,t,i):\n",
        "        src_idx = self._get_src_p_idx(i)\n",
        "        if src_idx[0].numel() == 0: return {'loss_height_constraint': torch.tensor(0.0, device=o.device)}\n",
        "\n",
        "        pred_heights = o[src_idx][:, 2]\n",
        "        batch_indices = src_idx[0]\n",
        "\n",
        "        # Calculate the sum of heights for each sample in the batch\n",
        "        total_height_loss = 0\n",
        "        for b in range(o.shape[0]):\n",
        "            heights_for_sample = pred_heights[batch_indices == b]\n",
        "            if heights_for_sample.numel() > 0:\n",
        "                total_height_loss += torch.abs(heights_for_sample.sum() - 1)\n",
        "\n",
        "        return {'loss_height_constraint': total_height_loss / o.shape[0]}\n",
        "\n",
        "    def _get_src_p_idx(self,i):\n",
        "        b=torch.cat([torch.full_like(s,k) for k,(s,_) in enumerate(i)]); s=torch.cat([s for s,_ in i]); return b,s\n",
        "\n",
        "    def forward(self,o,t):\n",
        "        i=self.m(o,t);\n",
        "        losses = {}\n",
        "        losses.update(self.loss_match(o,t,i))\n",
        "        losses.update(self.loss_unmatch(o,t,i))\n",
        "        losses.update(self.loss_height(o,t,i))\n",
        "        return {ln: l for ln,l in losses.items() if self.w[ln]>0}\n",
        "\n",
        "print(\"✅ Matcher and loss functions defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkCs711SJN9w",
        "outputId": "150d9bab-a047-4284-efcb-321feae0b649"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Matcher and loss functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 9. Define Helper and Utility Functions\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images, targets = zip(*batch)\n",
        "    return torch.stack(images), list(targets)\n",
        "\n",
        "def load_pretrained_encoder_weights(model, path):\n",
        "    print(f\"--> Loading pre-trained weights from {path}\")\n",
        "    pre_dict = torch.load(path)\n",
        "    model_dict = model.state_dict()\n",
        "    enc_dict = {k.replace('module.',''):v for k,v in pre_dict.items() if any(x in k for x in ['e1','e2','e3','mid','start'])}\n",
        "    enc_dict = {'encoder.'+k:v for k,v in enc_dict.items()}\n",
        "    model_dict.update(enc_dict)\n",
        "    model.load_state_dict(model_dict, strict=False)\n",
        "    print(f\"✅ Loaded {len(enc_dict)} pre-trained layers.\")\n",
        "    return model\n",
        "\n",
        "print(\"✅ Helper functions defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VustgxDJJOAq",
        "outputId": "e39b25d7-6810-4f67-ac61-10cce3ea903c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Helper functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 10. Define Pre-training Stage Function (W&B Sweep) (Corrected)\n",
        "from tqdm import tqdm\n",
        "\n",
        "# A global variable to track the best loss across all sweep runs\n",
        "best_pretrain_loss = float('inf')\n",
        "\n",
        "def train_autoencoder_sweep():\n",
        "    global best_pretrain_loss, config\n",
        "    with wandb.init() as run:\n",
        "        sweep_cfg = wandb.config\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # --- CORRECTED: Use the new UNet1D model ---\n",
        "        model = UNet1D(in_channels=sweep_cfg.in_channels, activation=sweep_cfg.act_name).to(device)\n",
        "\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = getattr(torch.optim, sweep_cfg.optimizer)(model.parameters(), lr=sweep_cfg.lr)\n",
        "        train_loader = data.DataLoader(AutoencoderDataset(config), batch_size=sweep_cfg.batch_size, shuffle=True)\n",
        "\n",
        "        print(f\"--- Starting W&B Run with config: {dict(sweep_cfg)} ---\")\n",
        "        for epoch in range(sweep_cfg.epochs):\n",
        "            model.train()\n",
        "            total_loss = 0.0\n",
        "            for img, tgt in train_loader:\n",
        "                img, tgt = img.to(device), tgt.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                output = model(img)\n",
        "                loss = criterion(output, tgt)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            epoch_loss = total_loss / len(train_loader)\n",
        "            wandb.log({\"epoch\": epoch, \"loss\": epoch_loss})\n",
        "\n",
        "            if epoch_loss < best_pretrain_loss:\n",
        "                best_pretrain_loss = epoch_loss\n",
        "                print(f\"    *** New best model found! Loss: {best_pretrain_loss:.6f} (Epoch {epoch+1}) ***\")\n",
        "                torch.save(model.state_dict(), config['paths']['pretrained_encoder_path'])\n",
        "                wandb.summary[\"best_loss\"] = best_pretrain_loss\n",
        "\n",
        "print(\"✅ Pre-training (sweep) function defined with 1D U-Net.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKvDhkF-JOCi",
        "outputId": "ec4ae19e-9dcb-423b-9d8f-a9cae3b69c07"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Pre-training (sweep) function defined with 1D U-Net.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 11. Define Fine-tuning Stage Function\n",
        "\n",
        "def run_finetuning(config):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    ft_params = config['finetuning']\n",
        "    loader = data.DataLoader(BoundaryDataset(config, seed=42), batch_size=ft_params['batch_size'], shuffle=True, collate_fn=collate_fn)\n",
        "    model = W2WTransformerModel(config).to(device)\n",
        "    model = load_pretrained_encoder_weights(model, config['paths']['pretrained_encoder_path'])\n",
        "    criterion = SetCriterion(config).to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=ft_params['learning_rate'])\n",
        "\n",
        "    for epoch in range(ft_params['epochs']):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for images, targets in tqdm(loader, desc=f'Epoch {epoch+1}/{ft_params[\"epochs\"]}'):\n",
        "            images, targets = images.to(device), [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "            loss_dict = criterion(model(images), targets)\n",
        "            losses = sum(loss_dict[k] * criterion.w[k] for k in loss_dict.keys())\n",
        "            optimizer.zero_grad(); losses.backward(); optimizer.step()\n",
        "            total_loss += losses.item(); wandb.log({'finetune_batch_loss': losses.item()})\n",
        "\n",
        "        avg_loss = total_loss / len(loader)\n",
        "        print(f'Epoch {epoch+1} Average Loss: {avg_loss:.4f}')\n",
        "        wandb.log({'finetune_epoch_loss': avg_loss, 'epoch': epoch})\n",
        "\n",
        "    torch.save(model.state_dict(), config['paths']['final_model_path'])\n",
        "    print(f\"✅ Final model saved to {config['paths']['final_model_path']}\")\n",
        "\n",
        "print(\"✅ Fine-tuning function defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-Iw7726JOGh",
        "outputId": "7c56f680-9771-444d-c20c-478dc3968362"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fine-tuning function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 12. Define Inference and Plotting Functions\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def plot_well_correlation(well1, well2, layers1, layers2, matrix, threshold, path):\n",
        "    fig, ax = plt.subplots(figsize=(10, 12)); plt.style.use('seaborn-whitegrid')\n",
        "    if not layers1 or not layers2: print('Warning: One or both wells have no layers to plot.'); return\n",
        "    max_depth = max(layers1[-1]['bottom'], layers2[-1]['bottom']) if layers1 and layers2 else 1000\n",
        "    ax.set_ylim(max_depth + 50, -50); ax.set_xlim(-0.5, 2.5)\n",
        "    n1 = len(set(l['Group'] for l in layers1)); n2 = len(set(l['Group'] for l in layers2))\n",
        "    for l in layers1: ax.add_patch(patches.Rectangle((0, l['Top']), 1, l['Height'], ec='k', fc=plt.cm.viridis(l['Group']/(n1 if n1>0 else 1)), alpha=0.6))\n",
        "    for l in layers2: ax.add_patch(patches.Rectangle((1.5, l['Top']), 1, l['Height'], ec='k', fc=plt.cm.viridis(l['Group']/(n2 if n2>0 else 1)), alpha=0.6))\n",
        "    for i, row in enumerate(matrix):\n",
        "        for j, sim in enumerate(row):\n",
        "            if sim >= threshold: ax.add_patch(patches.Polygon([[1,layers1[i]['Top']],[1,layers1[i]['bottom']],[1.5,layers2[j]['bottom']],[1.5,layers2[j]['Top']]], fc=plt.cm.Greens(sim), alpha=0.5))\n",
        "    ax.set_xticks([0.5, 2]); ax.set_xticklabels([well1, well2], fontsize=14); ax.set_ylabel('Depth', fontsize=12)\n",
        "    ax.set_title('Well to Well Correlation', fontsize=16); plt.savefig(path); plt.close()\n",
        "    print(f'--> Correlation plot saved to {path}')\n",
        "\n",
        "def run_correlation(config):\n",
        "    inf, p = config['inference'], config['paths']\n",
        "    full_data = pd.read_csv(p['processed_csv_path'], delimiter=';')\n",
        "    ref_df, woi_df = full_data[full_data['WELL'] == inf['reference_well']], full_data[full_data['WELL'] == inf['well_of_interest']]\n",
        "    if ref_df.empty or woi_df.empty: print(f\"Error: One/both wells not found: '{inf['reference_well']}', '{inf['well_of_interest']}'.\"); return\n",
        "\n",
        "    with open(p['label_encoder_path']) as f: le = json.load(f)\n",
        "    def get_true_layers(df):\n",
        "        df = df.copy().reset_index(drop=True)\n",
        "        df['group_id'] = df['GROUP'].astype(str).map(le).fillna(-1).astype(int)\n",
        "        b = np.where(df['group_id'].iloc[:-1].values != df['group_id'].iloc[1:].values)[0] + 1\n",
        "        indices = np.concatenate(([0], b, [len(df)]))\n",
        "        layers = []\n",
        "        for i in range(len(indices) - 1):\n",
        "            s, e = indices[i], indices[i+1]\n",
        "            layers.append({'Top':df['DEPTH_MD'].iloc[s],'bottom':df['DEPTH_MD'].iloc[e-1],'Height':df['DEPTH_MD'].iloc[e-1]-df['DEPTH_MD'].iloc[s],'Group':df['group_id'].iloc[s]})\n",
        "        return layers\n",
        "\n",
        "    ref_layers, woi_layers = get_true_layers(ref_df), get_true_layers(woi_df)\n",
        "    sim_matrix = np.zeros((len(ref_layers), len(woi_layers)))\n",
        "    for i,l1 in enumerate(ref_layers):\n",
        "        for j,l2 in enumerate(woi_layers):\n",
        "            if l1['Group'] == l2['Group'] and l1['Group'] != -1: sim_matrix[i,j] = np.random.uniform(0.8, 0.95)\n",
        "            else: sim_matrix[i,j] = np.random.uniform(0.1, 0.4)\n",
        "\n",
        "    print('--> MOCK INFERENCE: Using ground truth layers for visualization.')\n",
        "    output_path = 'well_correlation_plot.png'\n",
        "    plot_well_correlation(inf['reference_well'], inf['well_of_interest'], ref_layers, woi_layers, sim_matrix, inf['correlation_threshold'], output_path)\n",
        "    wandb.log({\"well_correlation_plot\": wandb.Image(output_path)})\n",
        "\n",
        "print(\"✅ Inference and plotting functions defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bGlyIyTJOIw",
        "outputId": "84d5643a-9faa-4a16-e70c-46d9f2706dce"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Inference and plotting functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 13. 🚀 Run the Full Pipeline\n",
        "\n",
        "# --- STAGE 0: DATA PREPARATION ---\n",
        "if config[\"run_data_preparation\"]:\n",
        "    run_data_preparation(config)\n",
        "    print(\"\\n--- STAGE 0 COMPLETE ---\\n\")\n",
        "\n",
        "# --- STAGE 1: PRE-TRAINING (W&B SWEEP) ---\n",
        "if config.get('run_pretraining', False):\n",
        "    print(\"\\n--- LAUNCHING PIPELINE 1: AUTOENCODER PRE-TRAINING (W&B SWEEP) ---\")\n",
        "    sweep_id = wandb.sweep(config['pretraining_sweep'], project=config['wandb']['project'], entity=config['wandb'].get('entity'))\n",
        "    wandb.agent(sweep_id, function=train_autoencoder_sweep, count=config['wandb']['sweep_count'])\n",
        "    print(f\"\\n🏆 Sweep finished. Best pre-trained model saved to {config['paths']['pretrained_encoder_path']}\")\n",
        "    print(\"\\n--- STAGE 1 COMPLETE ---\\n\")\n",
        "\n",
        "# --- STAGE 2: FINE-TUNING ---\n",
        "if config.get('run_finetuning', False):\n",
        "    print(\"\\n--- LAUNCHING PIPELINE 2: FINE-TUNING ---\")\n",
        "    with wandb.init(project=config['wandb']['project'], entity=config['wandb'].get('entity'), job_type='fine-tuning', config=config) as run:\n",
        "        print(f\"--> W&B Run started. View at: {run.get_url()}\")\n",
        "        run_finetuning(config)\n",
        "        artifact = wandb.Artifact(\"boundary-detector-model\", type=\"model\", description=\"Final fine-tuned W2W Transformer model\")\n",
        "        artifact.add_file(config['paths']['final_model_path'])\n",
        "        run.log_artifact(artifact)\n",
        "        print(\"✅ Final model logged as a W&B Artifact.\")\n",
        "    print(\"\\n--- STAGE 2 COMPLETE ---\\n\")\n",
        "\n",
        "# --- STAGE 3: INFERENCE ---\n",
        "if config.get('run_inference', False):\n",
        "    print(\"\\n--- LAUNCHING PIPELINE 3: WELL-TO-WELL INFERENCE ---\")\n",
        "    with wandb.init(project=config['wandb']['project'], entity=config['wandb'].get('entity'), job_type='inference', config=config) as run:\n",
        "        print(f\"--> W&B Run started. View at: {run.get_url()}\")\n",
        "        run_correlation(config)\n",
        "    print(\"\\n--- STAGE 3 COMPLETE ---\\n\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✅✅✅ All Requested Pipeline Stages are Complete! ✅✅✅\")\n",
        "print(\"You can view all your results, models, and charts in your Weights & Biases project.\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YNHZ52v_JOK7",
        "outputId": "05962892-2d41-4958-e8c1-1e2f5cd8ae17"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- LAUNCHING PIPELINE 0: DATA PREPARATION ---\n",
            "--> Searching for .las files in 'data/raw_las_files/'...\n",
            "--> Found 118 .las files. Reading now...\n",
            "--> Saved combined data to 'data/train.csv'\n",
            "\n",
            "--- Available Well Names for Inference ---\n",
            "- 35/4-1\n",
            "- 34/8-7R\n",
            "- 16/11-1S T3\n",
            "- 7/1-2 S\n",
            "- 34/3-2 S\n",
            "- 31/2-10\n",
            "- 25/7-2\n",
            "- 25/11-24 Jakob South\n",
            "- 25/10-9 Aegis\n",
            "- 34/10-33\n",
            "- 16/7-6\n",
            "- 34/3-3 A\n",
            "- 31/2-8\n",
            "- 31/4-5\n",
            "- 35/8-6 S\n",
            "- 34/4-10 R\n",
            "- 16/2-6 Johan Sverdrup\n",
            "- 31/2-1\n",
            "- 25/6-2  Delta-Beta\n",
            "- 31/2-9\n",
            "- 35/11-11\n",
            "- 34/3-1 A\n",
            "- 35/9-2\n",
            "- 31/2-19 S\n",
            "- 31/6-8\n",
            "- 25/8-5 S  Jotun\n",
            "- 16/10-2 Delta\n",
            "- 34/10-21\n",
            "- 25/3-1\n",
            "- 16/8-1\n",
            "- 31/3-4\n",
            "- 35/11-13\n",
            "- 34/10-19\n",
            "- 25/10-10  Balder Triassic\n",
            "- 36/7-3\n",
            "- 15/9-23 Skardkollen\n",
            "- 30/3-3\n",
            "- 34/8-1\n",
            "- 34/11-2 S\n",
            "- 16/7-5\n",
            "- 34/7-13\n",
            "- 31/5-4 S\n",
            "- 16/2-7 Johan Sverdrup Appr\n",
            "- 25/2-13 T4\n",
            "- 16/10-1 Alpha\n",
            "- 35/11-15 S\n",
            "- 32/2-1\n",
            "- 16/4-1\n",
            "- 35/3-7 S\n",
            "- 34/8-3\n",
            "- 35/11-10\n",
            "- 34/11-1\n",
            "- 35/12-1\n",
            "- 25/11-5 Balder Appr\n",
            "- 35/11-7\n",
            "- 16/1-2  Ivar Aasen Appr\n",
            "- 33/6-3 S\n",
            "- 35/11-12\n",
            "- 15/9-14\n",
            "- 31/2-7\n",
            "- 35/11-1\n",
            "- 34/7-21\n",
            "- 25/5-4  Byggve\n",
            "- 25/8-7  Krap 1\n",
            "- 25/9-1  Rummel\n",
            "- 31/3-3\n",
            "- 35/8-4\n",
            "- 15/9-13 Sleipner East Appr\n",
            "- 34/5-1 A\n",
            "- 34/12-1\n",
            "- 25/4-5\n",
            "- 31/3-2\n",
            "- 33/9-1\n",
            "- 17/4-1\n",
            "- 15/9-17\n",
            "- 16/2-16 Johan Sverdrup Appr\n",
            "- 16/5-3 Johan Sverdrup Appr\n",
            "- 16/1-6 A Verdandi Appr\n",
            "- 34/7-20\n",
            "- 33/9-17\n",
            "- 35/9-10 S\n",
            "- 31/6-5\n",
            "- 31/2-21 S\n",
            "- 35/9-8\n",
            "- 34/5-1 S\n",
            "- 30/6-5\n",
            "- 35/6-2 S\n",
            "- 35/9-7\n",
            "- 34/10-16R\n",
            "- 26/4-1\n",
            "- 35/11-6\n",
            "- 16/2-11 A Johan Sverdrup Appr\n",
            "- 33/5-2\n",
            "- 16/10-3 Tyr Central\n",
            "- 16/10-5 Isbjoern\n",
            "- 25/2-7\n",
            "- 25/6-1\n",
            "- 31/3-1\n",
            "- 16/7-4 Sigyn\n",
            "- 29/6-1\n",
            "- 34/10-35\n",
            "- 17/11-1\n",
            "- 35/11-5\n",
            "- 15/9-15 Gungne\n",
            "- 35/9-5\n",
            "- 30/3-5S\n",
            "- 25/11-15  Grane\n",
            "- 25/2-14 Froey Appr\n",
            "- 34/2-4\n",
            "- 25/5-3  Skirne\n",
            "- 7/1-1\n",
            "- 31/4-10\n",
            "- 25/5-1 Froey\n",
            "- 25/6-3\n",
            "- 35/9-6 S\n",
            "- 29/3-1\n",
            "- 25/11-19 S  Balder Appr\n",
            "- 34/6-1\n",
            "------------------------------------------\n",
            "TIP: Copy/paste two of these names into the 'inference' section of the config cell above.\n",
            "\n",
            "--> Saved label encoder to 'artifacts/label_encoder.json'\n",
            "--> Saved StandardScaler to 'artifacts/StandardScaler.bin'\n",
            "\n",
            "✅ Automatically detected 25 features (input channels) from the data.\n",
            "\n",
            "--- STAGE 0 COMPLETE ---\n",
            "\n",
            "\n",
            "--- LAUNCHING PIPELINE 1: AUTOENCODER PRE-TRAINING (W&B SWEEP) ---\n",
            "Create sweep with ID: ftan27pp\n",
            "Sweep URL: https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pf0efbo1 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tact_name: prelu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_channels: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250718_161759-pf0efbo1</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/pf0efbo1' target=\"_blank\">devoted-sweep-1</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/pf0efbo1' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/pf0efbo1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting W&B Run with config: {'act_name': 'prelu', 'batch_size': 16, 'epochs': 25, 'in_channels': 25, 'lr': 0.001, 'optimizer': 'Adam'} ---\n",
            "    *** New best model found! Loss: 0.591166 (Epoch 1) ***\n",
            "    *** New best model found! Loss: 0.397373 (Epoch 2) ***\n",
            "    *** New best model found! Loss: 0.319154 (Epoch 3) ***\n",
            "    *** New best model found! Loss: 0.266730 (Epoch 4) ***\n",
            "    *** New best model found! Loss: 0.234035 (Epoch 5) ***\n",
            "    *** New best model found! Loss: 0.210757 (Epoch 6) ***\n",
            "    *** New best model found! Loss: 0.190185 (Epoch 7) ***\n",
            "    *** New best model found! Loss: 0.173395 (Epoch 8) ***\n",
            "    *** New best model found! Loss: 0.150318 (Epoch 9) ***\n",
            "    *** New best model found! Loss: 0.141442 (Epoch 10) ***\n",
            "    *** New best model found! Loss: 0.138565 (Epoch 11) ***\n",
            "    *** New best model found! Loss: 0.128048 (Epoch 12) ***\n",
            "    *** New best model found! Loss: 0.116649 (Epoch 15) ***\n",
            "    *** New best model found! Loss: 0.110283 (Epoch 16) ***\n",
            "    *** New best model found! Loss: 0.100774 (Epoch 19) ***\n",
            "    *** New best model found! Loss: 0.097506 (Epoch 20) ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▅▄▃▃▃▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_loss</td><td>0.09751</td></tr><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.10566</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">devoted-sweep-1</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/pf0efbo1' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/pf0efbo1</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250718_161759-pf0efbo1/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9itubbu5 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tact_name: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_channels: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: RMSprop\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250718_161939-9itubbu5</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/9itubbu5' target=\"_blank\">dulcet-sweep-2</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/9itubbu5' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/9itubbu5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting W&B Run with config: {'act_name': 'relu', 'batch_size': 16, 'epochs': 25, 'in_channels': 25, 'lr': 0.001, 'optimizer': 'RMSprop'} ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▆▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.21421</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dulcet-sweep-2</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/9itubbu5' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/9itubbu5</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250718_161939-9itubbu5/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3n81j86p with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tact_name: prelu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_channels: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: RMSprop\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250718_162113-3n81j86p</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/3n81j86p' target=\"_blank\">gallant-sweep-3</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/3n81j86p' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/3n81j86p</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting W&B Run with config: {'act_name': 'prelu', 'batch_size': 32, 'epochs': 25, 'in_channels': 25, 'lr': 0.001, 'optimizer': 'RMSprop'} ---\n",
            "    *** New best model found! Loss: 0.094416 (Epoch 15) ***\n",
            "    *** New best model found! Loss: 0.084786 (Epoch 16) ***\n",
            "    *** New best model found! Loss: 0.083738 (Epoch 18) ***\n",
            "    *** New best model found! Loss: 0.074370 (Epoch 20) ***\n",
            "    *** New best model found! Loss: 0.072392 (Epoch 23) ***\n",
            "    *** New best model found! Loss: 0.072260 (Epoch 24) ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▅▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_loss</td><td>0.07226</td></tr><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.07724</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">gallant-sweep-3</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/3n81j86p' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/3n81j86p</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250718_162113-3n81j86p/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8zn3road with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tact_name: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_channels: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: AdamW\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250718_162236-8zn3road</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/8zn3road' target=\"_blank\">rose-sweep-4</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/8zn3road' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/8zn3road</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting W&B Run with config: {'act_name': 'relu', 'batch_size': 16, 'epochs': 25, 'in_channels': 25, 'lr': 0.0001, 'optimizer': 'AdamW'} ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.35288</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">rose-sweep-4</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/8zn3road' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/8zn3road</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250718_162236-8zn3road/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: h64f9ad0 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tact_name: prelu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_channels: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250718_162411-h64f9ad0</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/h64f9ad0' target=\"_blank\">revived-sweep-5</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/h64f9ad0' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/h64f9ad0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting W&B Run with config: {'act_name': 'prelu', 'batch_size': 32, 'epochs': 25, 'in_channels': 25, 'lr': 0.0001, 'optimizer': 'Adam'} ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▆▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.218</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">revived-sweep-5</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/h64f9ad0' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/h64f9ad0</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250718_162411-h64f9ad0/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🏆 Sweep finished. Best pre-trained model saved to trained_models/autoencoder/best_autoencoder.pt\n",
            "\n",
            "--- STAGE 1 COMPLETE ---\n",
            "\n",
            "\n",
            "--- LAUNCHING PIPELINE 2: FINE-TUNING ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'W2W_Matcher_Pipeline_Notebook' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250718_162531-h64f9ad0</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/h64f9ad0' target=\"_blank\">revived-sweep-5</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/h64f9ad0' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/h64f9ad0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> W&B Run started. View at: https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/h64f9ad0\n",
            "--> Dynamically calculated transformer input features: 22528\n",
            "--> Loading pre-trained weights from trained_models/autoencoder/best_autoencoder.pt\n",
            "✅ Loaded 80 pre-trained layers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100: 100%|██████████| 2/2 [00:00<00:00,  3.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Average Loss: 0.9658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/100: 100%|██████████| 2/2 [00:00<00:00, 18.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Average Loss: 0.3554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/100: 100%|██████████| 2/2 [00:00<00:00, 23.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Average Loss: 0.3395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/100: 100%|██████████| 2/2 [00:00<00:00, 21.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Average Loss: 0.3256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/100: 100%|██████████| 2/2 [00:00<00:00, 26.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Average Loss: 0.3231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/100: 100%|██████████| 2/2 [00:00<00:00, 26.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Average Loss: 0.3134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/100: 100%|██████████| 2/2 [00:00<00:00, 26.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Average Loss: 0.3069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/100: 100%|██████████| 2/2 [00:00<00:00, 26.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Average Loss: 0.3350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/100: 100%|██████████| 2/2 [00:00<00:00, 26.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Average Loss: 0.3174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/100: 100%|██████████| 2/2 [00:00<00:00, 27.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Average Loss: 0.3013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/100: 100%|██████████| 2/2 [00:00<00:00, 26.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 Average Loss: 0.3289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/100: 100%|██████████| 2/2 [00:00<00:00, 27.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 Average Loss: 0.2975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/100: 100%|██████████| 2/2 [00:00<00:00, 26.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 Average Loss: 0.3001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/100: 100%|██████████| 2/2 [00:00<00:00, 23.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 Average Loss: 0.3045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/100: 100%|██████████| 2/2 [00:00<00:00, 25.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 Average Loss: 0.3044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/100: 100%|██████████| 2/2 [00:00<00:00, 27.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 Average Loss: 0.3016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/100: 100%|██████████| 2/2 [00:00<00:00, 26.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 Average Loss: 0.2974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/100: 100%|██████████| 2/2 [00:00<00:00, 26.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 Average Loss: 0.2875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/100: 100%|██████████| 2/2 [00:00<00:00, 27.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 Average Loss: 0.2995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/100: 100%|██████████| 2/2 [00:00<00:00, 27.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 Average Loss: 0.2885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/100: 100%|██████████| 2/2 [00:00<00:00, 27.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 Average Loss: 0.2918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/100: 100%|██████████| 2/2 [00:00<00:00, 26.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 Average Loss: 0.2935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/100: 100%|██████████| 2/2 [00:00<00:00, 26.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 Average Loss: 0.2930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/100: 100%|██████████| 2/2 [00:00<00:00, 26.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 Average Loss: 0.2913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/100: 100%|██████████| 2/2 [00:00<00:00, 26.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 Average Loss: 0.2861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/100: 100%|██████████| 2/2 [00:00<00:00, 27.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 Average Loss: 0.2854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/100: 100%|██████████| 2/2 [00:00<00:00, 21.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27 Average Loss: 0.2895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/100: 100%|██████████| 2/2 [00:00<00:00, 25.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 Average Loss: 0.2872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/100: 100%|██████████| 2/2 [00:00<00:00, 26.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 Average Loss: 0.2887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/100: 100%|██████████| 2/2 [00:00<00:00, 25.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 Average Loss: 0.2915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/100: 100%|██████████| 2/2 [00:00<00:00, 26.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31 Average Loss: 0.2891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/100: 100%|██████████| 2/2 [00:00<00:00, 26.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32 Average Loss: 0.2852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/100: 100%|██████████| 2/2 [00:00<00:00, 25.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33 Average Loss: 0.2788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/100: 100%|██████████| 2/2 [00:00<00:00, 27.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34 Average Loss: 0.2861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/100: 100%|██████████| 2/2 [00:00<00:00, 27.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35 Average Loss: 0.2827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/100: 100%|██████████| 2/2 [00:00<00:00, 26.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36 Average Loss: 0.2808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/100: 100%|██████████| 2/2 [00:00<00:00, 26.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37 Average Loss: 0.2794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/100: 100%|██████████| 2/2 [00:00<00:00, 25.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38 Average Loss: 0.2782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/100: 100%|██████████| 2/2 [00:00<00:00, 24.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39 Average Loss: 0.2812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/100: 100%|██████████| 2/2 [00:00<00:00, 26.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40 Average Loss: 0.2855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/100: 100%|██████████| 2/2 [00:00<00:00, 25.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41 Average Loss: 0.2769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/100: 100%|██████████| 2/2 [00:00<00:00, 26.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42 Average Loss: 0.2782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/100: 100%|██████████| 2/2 [00:00<00:00, 26.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43 Average Loss: 0.2777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/100: 100%|██████████| 2/2 [00:00<00:00, 26.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44 Average Loss: 0.2775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/100: 100%|██████████| 2/2 [00:00<00:00, 25.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45 Average Loss: 0.2747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/100: 100%|██████████| 2/2 [00:00<00:00, 26.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46 Average Loss: 0.2750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/100: 100%|██████████| 2/2 [00:00<00:00, 26.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47 Average Loss: 0.2775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/100: 100%|██████████| 2/2 [00:00<00:00, 26.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48 Average Loss: 0.2785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/100: 100%|██████████| 2/2 [00:00<00:00, 26.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49 Average Loss: 0.2780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/100: 100%|██████████| 2/2 [00:00<00:00, 26.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50 Average Loss: 0.2735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 51/100: 100%|██████████| 2/2 [00:00<00:00, 26.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51 Average Loss: 0.2755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 52/100: 100%|██████████| 2/2 [00:00<00:00, 22.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52 Average Loss: 0.2721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 53/100: 100%|██████████| 2/2 [00:00<00:00, 25.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53 Average Loss: 0.2717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 54/100: 100%|██████████| 2/2 [00:00<00:00, 26.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54 Average Loss: 0.2713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 55/100: 100%|██████████| 2/2 [00:00<00:00, 26.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55 Average Loss: 0.2707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 56/100: 100%|██████████| 2/2 [00:00<00:00, 25.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56 Average Loss: 0.2693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 57/100: 100%|██████████| 2/2 [00:00<00:00, 25.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57 Average Loss: 0.2685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 58/100: 100%|██████████| 2/2 [00:00<00:00, 26.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58 Average Loss: 0.2721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 59/100: 100%|██████████| 2/2 [00:00<00:00, 26.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59 Average Loss: 0.2652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 60/100: 100%|██████████| 2/2 [00:00<00:00, 20.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60 Average Loss: 0.2713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 61/100: 100%|██████████| 2/2 [00:00<00:00, 21.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61 Average Loss: 0.2704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 62/100: 100%|██████████| 2/2 [00:00<00:00, 21.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62 Average Loss: 0.2665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 63/100: 100%|██████████| 2/2 [00:00<00:00, 19.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63 Average Loss: 0.2642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 64/100: 100%|██████████| 2/2 [00:00<00:00, 22.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64 Average Loss: 0.2628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 65/100: 100%|██████████| 2/2 [00:00<00:00, 21.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65 Average Loss: 0.2634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 66/100: 100%|██████████| 2/2 [00:00<00:00, 21.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66 Average Loss: 0.2685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 67/100: 100%|██████████| 2/2 [00:00<00:00, 21.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67 Average Loss: 0.2651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 68/100: 100%|██████████| 2/2 [00:00<00:00, 21.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68 Average Loss: 0.2693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 69/100: 100%|██████████| 2/2 [00:00<00:00, 22.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69 Average Loss: 0.2705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 70/100: 100%|██████████| 2/2 [00:00<00:00, 21.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70 Average Loss: 0.2699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 71/100: 100%|██████████| 2/2 [00:00<00:00, 23.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71 Average Loss: 0.2618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 72/100: 100%|██████████| 2/2 [00:00<00:00, 21.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72 Average Loss: 0.2667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 73/100: 100%|██████████| 2/2 [00:00<00:00, 22.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73 Average Loss: 0.2632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 74/100: 100%|██████████| 2/2 [00:00<00:00, 16.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74 Average Loss: 0.2601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 75/100: 100%|██████████| 2/2 [00:00<00:00, 20.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75 Average Loss: 0.2627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 76/100: 100%|██████████| 2/2 [00:00<00:00, 19.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76 Average Loss: 0.2596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 77/100: 100%|██████████| 2/2 [00:00<00:00, 21.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77 Average Loss: 0.2567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 78/100: 100%|██████████| 2/2 [00:00<00:00, 22.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 78 Average Loss: 0.2590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 79/100: 100%|██████████| 2/2 [00:00<00:00, 22.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 79 Average Loss: 0.2561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 80/100: 100%|██████████| 2/2 [00:00<00:00, 22.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 80 Average Loss: 0.2551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 81/100: 100%|██████████| 2/2 [00:00<00:00, 18.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 81 Average Loss: 0.2556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 82/100: 100%|██████████| 2/2 [00:00<00:00, 22.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 82 Average Loss: 0.2573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 83/100: 100%|██████████| 2/2 [00:00<00:00, 14.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 83 Average Loss: 0.2582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 84/100: 100%|██████████| 2/2 [00:00<00:00, 19.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 84 Average Loss: 0.2571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 85/100: 100%|██████████| 2/2 [00:00<00:00, 17.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 85 Average Loss: 0.2537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 86/100: 100%|██████████| 2/2 [00:00<00:00, 18.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 86 Average Loss: 0.2530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 87/100: 100%|██████████| 2/2 [00:00<00:00, 22.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 87 Average Loss: 0.2569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 88/100: 100%|██████████| 2/2 [00:00<00:00, 25.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 88 Average Loss: 0.2541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 89/100: 100%|██████████| 2/2 [00:00<00:00, 25.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 89 Average Loss: 0.2547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 90/100: 100%|██████████| 2/2 [00:00<00:00, 23.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 90 Average Loss: 0.2540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 91/100: 100%|██████████| 2/2 [00:00<00:00, 26.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 91 Average Loss: 0.2521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 92/100: 100%|██████████| 2/2 [00:00<00:00, 25.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 92 Average Loss: 0.2504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 93/100: 100%|██████████| 2/2 [00:00<00:00, 25.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 93 Average Loss: 0.2508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 94/100: 100%|██████████| 2/2 [00:00<00:00, 22.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 94 Average Loss: 0.2533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 95/100: 100%|██████████| 2/2 [00:00<00:00, 26.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 95 Average Loss: 0.2506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 96/100: 100%|██████████| 2/2 [00:00<00:00, 26.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 96 Average Loss: 0.2537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 97/100: 100%|██████████| 2/2 [00:00<00:00, 26.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 97 Average Loss: 0.2508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 98/100: 100%|██████████| 2/2 [00:00<00:00, 27.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 98 Average Loss: 0.2505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 99/100: 100%|██████████| 2/2 [00:00<00:00, 26.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 99 Average Loss: 0.2466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 100/100: 100%|██████████| 2/2 [00:00<00:00, 25.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100 Average Loss: 0.2482\n",
            "✅ Final model saved to trained_models/boundary_detector/final_model.pt\n",
            "✅ Final model logged as a W&B Artifact.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇███</td></tr><tr><td>finetune_batch_loss</td><td>█▇▆▅▅▅▄▄▄▄▄▃▃▃▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▂▁▁▁▁▁▁</td></tr><tr><td>finetune_epoch_loss</td><td>█▇▆█▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>finetune_batch_loss</td><td>0.24614</td></tr><tr><td>finetune_epoch_loss</td><td>0.24821</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">revived-sweep-5</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/h64f9ad0' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/h64f9ad0</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250718_162531-h64f9ad0/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- STAGE 2 COMPLETE ---\n",
            "\n",
            "\n",
            "--- LAUNCHING PIPELINE 3: WELL-TO-WELL INFERENCE ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'W2W_Matcher_Pipeline_Notebook' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250718_162558-h64f9ad0</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/h64f9ad0' target=\"_blank\">revived-sweep-5</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/ftan27pp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/h64f9ad0' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/h64f9ad0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> W&B Run started. View at: https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/h64f9ad0\n",
            "Error: One/both wells not found: '15_9-F-1 A', '15_9-F-1 B'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">revived-sweep-5</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/h64f9ad0' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/h64f9ad0</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250718_162558-h64f9ad0/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- STAGE 3 COMPLETE ---\n",
            "\n",
            "\n",
            "============================================================\n",
            "✅✅✅ All Requested Pipeline Stages are Complete! ✅✅✅\n",
            "You can view all your results, models, and charts in your Weights & Biases project.\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}