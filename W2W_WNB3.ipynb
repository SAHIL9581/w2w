{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNin93U8lpObA+rVZXymCQ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SAHIL9581/w2w/blob/main/W2W_WNB3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Setup Environment & Install Libraries\n",
        "\n",
        "# --- 1. Install All Required Libraries ---\n",
        "print(\"--> Installing all necessary Python libraries (this may take a few minutes)...\")\n",
        "!pip install wandb torch torchvision torchaudio lasio scikit-learn pandas tqdm matplotlib joblib pyyaml -q\n",
        "print(\"✅ Library installation complete.\")\n",
        "\n",
        "\n",
        "# --- 2. Define and Change to Project Directory ---\n",
        "import os\n",
        "\n",
        "# IMPORTANT: This folder is TEMPORARY. All local files will be DELETED when the Colab session ends.\n",
        "# Your results and models will be saved to your online W&B account.\n",
        "PROJECT_PATH = '/content/W2W_Pipeline_WandB'\n",
        "\n",
        "print(f\"\\n--> Setting up a temporary project directory at: {PROJECT_PATH}\")\n",
        "os.makedirs(f\"{PROJECT_PATH}/data/raw_las_files\", exist_ok=True)\n",
        "os.makedirs(f\"{PROJECT_PATH}/artifacts\", exist_ok=True)\n",
        "os.makedirs(f\"{PROJECT_PATH}/trained_models/autoencoder\", exist_ok=True)\n",
        "os.makedirs(f\"{PROJECT_PATH}/trained_models/boundary_detector\", exist_ok=True)\n",
        "\n",
        "# Change the current working directory to the project path\n",
        "os.chdir(PROJECT_PATH)\n",
        "print(f\"✅ Current directory changed to: {os.getcwd()}\")\n",
        "print(\"\\n--- Setup Complete ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRzHJfB1JNuw",
        "outputId": "1443ecb8-4176-41dd-c258-94bcb772cfdc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> Installing all necessary Python libraries (this may take a few minutes)...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✅ Library installation complete.\n",
            "\n",
            "--> Setting up a temporary project directory at: /content/W2W_Pipeline_WandB\n",
            "✅ Current directory changed to: /content/W2W_Pipeline_WandB\n",
            "\n",
            "--- Setup Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Login to Weights & Biases\n",
        "import wandb\n",
        "\n",
        "print(\"--> ACTION REQUIRED: Please log in to your Weights & Biases account.\")\n",
        "# You will be prompted to paste your W&B API key.\n",
        "# You can find your key here: https://wandb.ai/authorize\n",
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgO3SWzHJNw_",
        "outputId": "426a4fd0-7c3f-4608-9167-b61265339cc6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> ACTION REQUIRED: Please log in to your Weights & Biases account.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msahilpareek203\u001b[0m (\u001b[33msahilpareek203-amrita-vishwa-vidyapeetham\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Upload ZIP File with .las Data\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\">>> ACTION REQUIRED: Please upload the ZIP file containing your .las files.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if not uploaded:\n",
        "    print(\"\\n⚠️ Upload was cancelled or failed. Please run this cell again.\")\n",
        "else:\n",
        "    zip_filename = list(uploaded.keys())[0]\n",
        "    print(f\"\\n✅ '{zip_filename}' uploaded successfully.\")\n",
        "\n",
        "    # Unzip into the designated raw data folder\n",
        "    !unzip -q -o \"{zip_filename}\" -d data/raw_las_files/\n",
        "\n",
        "    print(\"--> ZIP file has been unzipped into 'data/raw_las_files/'.\")\n",
        "\n",
        "    # Clean up the uploaded zip file from the root directory\n",
        "    os.remove(zip_filename)\n",
        "    print(\"\\n✅ Data upload is complete. You can now proceed to the next step.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "iYbOznxCJNzP",
        "outputId": "711067b5-c782-4c52-c8ae-2ae95316f236"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> ACTION REQUIRED: Please upload the ZIP file containing your .las files.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-65282a7b-89ab-466c-bb94-aa62f989f500\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-65282a7b-89ab-466c-bb94-aa62f989f500\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train.zip to train.zip\n",
            "\n",
            "✅ 'train.zip' uploaded successfully.\n",
            "--> ZIP file has been unzipped into 'data/raw_las_files/'.\n",
            "\n",
            "✅ Data upload is complete. You can now proceed to the next step.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. Pipeline Configuration (Updated with 200 Epochs)\n",
        "# All settings for the pipeline are controlled from this Python dictionary.\n",
        "\n",
        "config = {\n",
        "    \"run_data_preparation\": True,\n",
        "    \"run_pretraining\": True,\n",
        "    \"run_finetuning\": True,\n",
        "    \"run_inference\": True,\n",
        "\n",
        "    \"paths\": {\n",
        "        \"raw_las_folder\": \"data/raw_las_files/\",\n",
        "        \"processed_csv_path\": \"data/train.csv\",\n",
        "        \"label_encoder_path\": \"artifacts/label_encoder.json\",\n",
        "        \"std_scaler_path\": \"artifacts/StandardScaler.bin\",\n",
        "        \"pretrained_encoder_path\": \"trained_models/autoencoder/best_autoencoder.pt\",\n",
        "        \"final_model_path\": \"trained_models/boundary_detector/final_model.pt\"\n",
        "    },\n",
        "\n",
        "    \"wandb\": {\n",
        "        \"project\": \"W2W_Matcher_Pipeline_Notebook\", # Your W&B project name\n",
        "        \"entity\": None,                             # Your W&B username or team name (optional)\n",
        "        \"sweep_count\": 5                            # Number of hyperparameter combinations to try\n",
        "    },\n",
        "\n",
        "    \"pretraining_sweep\": {\n",
        "        \"name\": \"Autoencoder-Pre-training-Sweep\",\n",
        "        \"method\": \"random\",\n",
        "        \"metric\": {\"name\": \"loss\", \"goal\": \"minimize\"},\n",
        "        \"parameters\": {\n",
        "            \"epochs\": {\"value\": 25}, # Pre-training epochs remain the same\n",
        "            \"optimizer\": {\"values\": [\"RMSprop\", \"AdamW\", \"Adam\"]},\n",
        "            \"lr\": {\"values\": [0.001, 0.0001]},\n",
        "            \"act_name\": {\"values\": [\"prelu\", \"relu\"]},\n",
        "            \"batch_size\": {\"values\": [16, 32]},\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"finetuning\": {\n",
        "        \"learning_rate\": 0.0001,\n",
        "        \"batch_size\": 16,\n",
        "        \"epochs\": 200, # <-- CHANGED: Updated from 100 to 200 as requested\n",
        "        \"model_params\": {\n",
        "            \"patch_height\": 700, \"act_name\": \"prelu\",\n",
        "            \"hidden_dim\": 256, \"num_queries\": 100,\n",
        "            \"num_heads\": 8, \"dropout\": 0.1,\n",
        "            \"num_transformers\": 6, \"output_size\": 3\n",
        "        },\n",
        "        \"matcher_costs\": {\"set_cost_class\": 1, \"set_cost_bbox\": 5},\n",
        "        \"loss_weights\": {\"loss_matching\": 1.0, \"loss_unmatching\": 0.5, \"loss_height_constraint\": 0.5}\n",
        "    },\n",
        "\n",
        "    \"inference\": {\n",
        "        \"reference_well\": \"15_9-13 Sleipner East Appr\",\n",
        "        \"well_of_interest\": \"16/1-2  Ivar Aasen Appr\",\n",
        "        \"correlation_threshold\": 0.7\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"✅ Configuration dictionary updated with 200 fine-tuning epochs.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbucfMA2JN1v",
        "outputId": "a7f4cf79-d0fb-4042-8a00-d83f4dfda036"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Configuration dictionary updated with 200 fine-tuning epochs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5. Define Data Preparation Function (Corrected)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lasio\n",
        "import json\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from joblib import dump\n",
        "\n",
        "def run_data_preparation(config):\n",
        "    print(\"--- LAUNCHING PIPELINE 0: DATA PREPARATION ---\")\n",
        "    paths = config['paths']\n",
        "    search_folder = paths['raw_las_folder']\n",
        "    all_wells_df, las_files_found = [], []\n",
        "\n",
        "    print(f\"--> Searching for .las files in '{search_folder}'...\")\n",
        "    for root, dirs, files in os.walk(search_folder):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.las'):\n",
        "                las_files_found.append(os.path.join(root, file))\n",
        "\n",
        "    if not las_files_found: raise FileNotFoundError(f\"No .las files found in '{search_folder}'.\")\n",
        "    print(f\"--> Found {len(las_files_found)} .las files. Reading now...\")\n",
        "\n",
        "    for filepath in las_files_found:\n",
        "        try:\n",
        "            las = lasio.read(filepath)\n",
        "            df = las.df().reset_index()\n",
        "            df['WELL'] = las.well.WELL.value or os.path.splitext(os.path.basename(filepath))[0]\n",
        "            df['GROUP'] = 'UNKNOWN'\n",
        "            for param in las.params:\n",
        "                if 'GROUP' in param.mnemonic.upper(): df['GROUP'] = param.value\n",
        "            all_wells_df.append(df)\n",
        "        except Exception as e: print(f\"    - Could not read {filepath}: {e}\")\n",
        "\n",
        "    if not all_wells_df: raise ValueError(\"Could not process any .las files.\")\n",
        "    master_df = pd.concat(all_wells_df, ignore_index=True)\n",
        "    if 'DEPT' in master_df.columns: master_df.rename(columns={'DEPT': 'DEPTH_MD'}, inplace=True)\n",
        "    master_df.to_csv(paths['processed_csv_path'], index=False, sep=';')\n",
        "    print(f\"--> Saved combined data to '{paths['processed_csv_path']}'\")\n",
        "\n",
        "    unique_wells = master_df['WELL'].unique()\n",
        "    print(\"\\n--- Available Well Names for Inference ---\")\n",
        "    for well in unique_wells: print(f\"- {well}\")\n",
        "    print(\"------------------------------------------\")\n",
        "    print(\"TIP: Copy/paste two of these names into the 'inference' section of the config cell above.\\n\")\n",
        "\n",
        "    label_encoder = {str(g): i for i, g in enumerate(master_df['GROUP'].unique())}\n",
        "    with open(paths['label_encoder_path'], 'w') as f: json.dump(label_encoder, f, indent=4)\n",
        "    print(f\"--> Saved label encoder to '{paths['label_encoder_path']}'\")\n",
        "\n",
        "    cols_to_drop = ['WELL', 'GROUP'] + [col for col in master_df.columns if 'DEPT' in col.upper()]\n",
        "    numeric_df = master_df.drop(columns=cols_to_drop, errors='ignore').fillna(0)\n",
        "    scaler = StandardScaler().fit(numeric_df)\n",
        "    dump(scaler, paths['std_scaler_path'])\n",
        "    print(f\"--> Saved StandardScaler to '{paths['std_scaler_path']}'\")\n",
        "\n",
        "    # --- CRUCIAL FIX: Dynamically add the number of features to the config ---\n",
        "    num_features = scaler.n_features_in_\n",
        "    print(f\"\\n✅ Automatically detected {num_features} features (input channels) from the data.\")\n",
        "    config['finetuning']['model_params']['in_channels'] = num_features\n",
        "    config['pretraining_sweep']['parameters']['in_channels'] = {'value': num_features}\n",
        "    # --- END OF FIX ---\n",
        "\n",
        "print(\"✅ Data preparation function defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVqmQuw1JN3a",
        "outputId": "54314556-c9f8-40b6-a104-ae47c2dcec4d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Data preparation function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6. Define Dataset Classes (Corrected)\n",
        "import torch\n",
        "from torch.utils import data\n",
        "from joblib import load\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- CORRECTED: AutoencoderDataset now creates patches ---\n",
        "class AutoencoderDataset(data.Dataset):\n",
        "    def __init__(self, c):\n",
        "        p = c['paths']\n",
        "        # Use the same patch height as the fine-tuning stage for consistency\n",
        "        patch_height = c['finetuning']['model_params']['patch_height']\n",
        "\n",
        "        df = pd.read_csv(p['processed_csv_path'], delimiter=';')\n",
        "        scaler = load(p['std_scaler_path'])\n",
        "\n",
        "        self.data_patches = []\n",
        "        # Group by each well to create contiguous patches\n",
        "        for well_name, well_df in df.groupby('WELL'):\n",
        "            cols_to_drop = ['WELL', 'GROUP'] + [col for col in well_df.columns if 'DEPT' in col.upper()]\n",
        "            well_numeric = well_df.drop(columns=cols_to_drop, errors='ignore').fillna(0)\n",
        "\n",
        "            # Ensure the scaler is applied with the correct feature names\n",
        "            if hasattr(scaler, 'feature_names_in_'):\n",
        "                well_numeric = well_numeric[scaler.feature_names_in_]\n",
        "\n",
        "            scaled_data = scaler.transform(well_numeric).astype(np.float32)\n",
        "\n",
        "            # Create patches from this well's data\n",
        "            for i in range(0, len(scaled_data) - patch_height + 1, patch_height):\n",
        "                patch = scaled_data[i:i + patch_height]\n",
        "                # The input to Conv1d should be (channels, length)\n",
        "                self.data_patches.append(patch.T)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_patches)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        patch = self.data_patches[i]\n",
        "        return torch.from_numpy(patch), torch.from_numpy(patch)\n",
        "\n",
        "class BoundaryDataset(data.Dataset):\n",
        "    def __init__(self, c, seed=None):\n",
        "        self.p, self.d = c['finetuning']['model_params'], c['paths']\n",
        "        self.s = seed or np.random.randint(2**32 - 1)\n",
        "        self.x, self.gt = self.get_Xy()\n",
        "\n",
        "    def get_Xy(self):\n",
        "        d = pd.read_csv(self.d['processed_csv_path'], delimiter=';')\n",
        "        np.random.seed(self.s)\n",
        "        w = d[d['WELL'] == np.random.choice(d.WELL.unique())].copy()\n",
        "\n",
        "        with open(self.d['label_encoder_path']) as f: le = json.load(f)\n",
        "        w['GROUP'] = w['GROUP'].astype(str).map(le).bfill().ffill()\n",
        "\n",
        "        cols_to_drop = ['WELL', 'GROUP'] + [col for col in w.columns if 'DEPT' in col.upper()]\n",
        "        w_numeric = w.drop(columns=cols_to_drop, errors='ignore').fillna(0)\n",
        "\n",
        "        scaler = load(self.d['std_scaler_path'])\n",
        "        if hasattr(scaler, 'feature_names_in_'):\n",
        "            w_numeric = w_numeric[scaler.feature_names_in_]\n",
        "\n",
        "        s_d = scaler.transform(w_numeric)\n",
        "\n",
        "        ph = self.p['patch_height']\n",
        "        idx = list(range(0, s_d.shape[0], ph))\n",
        "        x = np.asarray([s_d[i:i + ph] for i in idx if len(s_d[i:i + ph]) == ph], dtype=np.float32)\n",
        "        y = np.asarray([w['GROUP'].values[i:i + ph] for i in idx if len(w['GROUP'].values[i:i + ph]) == ph])\n",
        "        return x, self._get_gt_boundaries(y)\n",
        "\n",
        "    def _get_gt_boundaries(self, y_patches):\n",
        "        gts = []\n",
        "        for y in y_patches:\n",
        "            gt, c = {}, 0\n",
        "            boundaries = np.where(y[:-1] != y[1:])[0] + 1\n",
        "            k = np.concatenate(([0], boundaries, [len(y)]))\n",
        "            for i in range(len(k) - 1):\n",
        "                top, bottom = k[i], k[i+1]\n",
        "                gt[c] = {'Group': int(y[top]), 'Top': top, 'Height': bottom - top}; c += 1\n",
        "            gts.append(gt)\n",
        "        return gts\n",
        "\n",
        "    def __len__(self): return len(self.x)\n",
        "    def __getitem__(self, idx):\n",
        "        img = np.expand_dims(self.x[idx], 0)\n",
        "        data = self.gt[idx]\n",
        "        ph = self.p['patch_height']\n",
        "        tops = torch.tensor([d['Top'] / ph for d in data.values()], dtype=torch.float32).view(-1, 1)\n",
        "        heights = torch.tensor([d['Height'] / ph for d in data.values()], dtype=torch.float32).view(-1, 1)\n",
        "        tgt = {'labels': torch.ones(len(data), dtype=torch.long), 'loc_info': torch.hstack((tops, heights))}\n",
        "        return torch.from_numpy(img), tgt\n",
        "\n",
        "print(\"✅ Dataset classes corrected for patching.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfmlV46sJN5v",
        "outputId": "cb36a670-5989-4f63-d43a-11237c3fe142"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset classes corrected for patching.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 7. Define Model Architectures (Final Corrected Version)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def get_activation(name):\n",
        "    \"\"\"Returns the activation function based on the provided name.\"\"\"\n",
        "    return nn.PReLU() if name == 'prelu' else nn.ReLU() if name == 'relu' else nn.GELU()\n",
        "\n",
        "class Block1D(nn.Module):\n",
        "    \"\"\"A basic 1D convolutional block with two convolution layers.\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride=2, kernel_size=3, activation='prelu'):\n",
        "        super().__init__()\n",
        "        self.b = nn.Sequential(\n",
        "            nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding=kernel_size//2),\n",
        "            nn.BatchNorm1d(out_channels), get_activation(activation),\n",
        "            nn.Conv1d(out_channels, out_channels, kernel_size, 1, padding=kernel_size//2),\n",
        "            nn.BatchNorm1d(out_channels), get_activation(activation)\n",
        "        )\n",
        "    def forward(self, x): return self.b(x)\n",
        "\n",
        "class UNet1D(nn.Module):\n",
        "    \"\"\"A 1D U-Net architecture with robust skip connections.\"\"\"\n",
        "    def __init__(self, in_channels, activation='prelu'):\n",
        "        super().__init__()\n",
        "        self.start = Block1D(in_channels, 32, stride=1, activation=activation)\n",
        "        self.e1 = Block1D(32, 64, stride=2, activation=activation)\n",
        "        self.e2 = Block1D(64, 128, stride=2, activation=activation)\n",
        "        self.e3 = Block1D(128, 256, stride=2, activation=activation)\n",
        "        self.mid = Block1D(256, 512, stride=2, activation=activation)\n",
        "        self.uc3 = nn.ConvTranspose1d(512, 256, 2, 2)\n",
        "        self.d3 = Block1D(512, 256, stride=1, activation=activation)\n",
        "        self.uc2 = nn.ConvTranspose1d(256, 128, 2, 2)\n",
        "        self.d2 = Block1D(256, 128, stride=1, activation=activation)\n",
        "        self.uc1 = nn.ConvTranspose1d(128, 64, 2, 2)\n",
        "        self.d1 = Block1D(128, 64, stride=1, activation=activation)\n",
        "        self.uc0 = nn.ConvTranspose1d(64, 32, 2, 2)\n",
        "        self.d0 = Block1D(64, 32, stride=1, activation=activation)\n",
        "        self.out_conv = nn.Conv1d(32, in_channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        s1 = self.start(x); s2 = self.e1(s1); s3 = self.e2(s2); s4 = self.e3(s3); m = self.mid(s4)\n",
        "        d3 = self.d3(torch.cat((F.interpolate(self.uc3(m), size=s4.shape[2]), s4), 1))\n",
        "        d2 = self.d2(torch.cat((F.interpolate(self.uc2(d3), size=s3.shape[2]), s3), 1))\n",
        "        d1 = self.d1(torch.cat((F.interpolate(self.uc1(d2), size=s2.shape[2]), s2), 1))\n",
        "        d0 = self.d0(torch.cat((F.interpolate(self.uc0(d1), size=s1.shape[2]), s1), 1))\n",
        "        return self.out_conv(d0)\n",
        "\n",
        "class UNetEncoder1D(nn.Module):\n",
        "    \"\"\"The encoder part of the 1D U-Net.\"\"\"\n",
        "    def __init__(self, in_channels, activation='prelu'):\n",
        "        super().__init__()\n",
        "        self.start = Block1D(in_channels, 32, stride=1, activation=activation)\n",
        "        self.e1 = Block1D(32, 64, stride=2, activation=activation)\n",
        "        self.e2 = Block1D(64, 128, stride=2, activation=activation)\n",
        "        self.e3 = Block1D(128, 256, stride=2, activation=activation)\n",
        "        self.mid = Block1D(256, 512, stride=2, activation=activation)\n",
        "    def forward(self, x):\n",
        "        x = x.squeeze(1).permute(0, 2, 1); s1 = self.start(x); s2 = self.e1(s1); s3 = self.e2(s2); s4 = self.e3(s3); return self.mid(s4)\n",
        "\n",
        "class Project(nn.Module):\n",
        "    \"\"\"Projects flattened features to a different dimension.\"\"\"\n",
        "    def __init__(self, i, o): super().__init__(); self.l = nn.Linear(i, o)\n",
        "    def forward(self, x): return self.l(x.flatten(1))\n",
        "\n",
        "class Query(nn.Module):\n",
        "    \"\"\"Creates a learnable query tensor for the transformer.\"\"\"\n",
        "    def __init__(self, s, d): super().__init__(); self.q = nn.Parameter(torch.randn(1, s, d))\n",
        "    def forward(self, x): return self.q.repeat(x.shape[0], 1, 1)\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    \"\"\"A standard transformer encoder layer.\"\"\"\n",
        "    def __init__(self, i, n, d): super().__init__(); self.t = nn.TransformerEncoderLayer(d_model=i, nhead=n, dropout=d, batch_first=True, dim_feedforward=i * 4)\n",
        "    def forward(self, q, c): return self.t(q)\n",
        "\n",
        "class W2WTransformerModel(nn.Module):\n",
        "    \"\"\"A transformer-based model using a U-Net encoder.\"\"\"\n",
        "    def __init__(self, c):\n",
        "        super().__init__()\n",
        "        p = c['finetuning']['model_params']\n",
        "        self.encoder = UNetEncoder1D(p['in_channels'], p['act_name'])\n",
        "\n",
        "        # --- CRUCIAL FIX: Dynamically calculate the flattened feature size ---\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.randn(1, 1, p['patch_height'], p['in_channels'])\n",
        "            dummy_output = self.encoder(dummy_input)\n",
        "            p_in = dummy_output.flatten(1).shape[1]\n",
        "            print(f\"--> Dynamically calculated transformer input features: {p_in}\")\n",
        "        # --- END OF FIX ---\n",
        "\n",
        "        self.project = Project(p_in, p['hidden_dim'])\n",
        "        self.query = Query(p['num_queries'], p['hidden_dim'])\n",
        "        self.transformers = nn.ModuleList([Transformer(p['hidden_dim'], p['num_heads'], p['dropout']) for _ in range(p['num_transformers'])])\n",
        "        self.finalize = nn.Sequential(nn.Linear(p['hidden_dim'], p['output_size']), get_activation(p['act_name']), nn.LayerNorm(p['output_size']))\n",
        "\n",
        "    def forward(self, img):\n",
        "        encoded_output = self.encoder(img)\n",
        "        projected_seq = self.project(encoded_output).unsqueeze(1)\n",
        "        q = self.query(projected_seq)\n",
        "        for t in self.transformers:\n",
        "            q = t(q, projected_seq)\n",
        "        return self.finalize(q)\n",
        "\n",
        "print(\"✅ Model architectures defined, made robust, and fully symmetrical.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naTJURjiJN7x",
        "outputId": "e33aba63-af28-4722-c528-9b5fd7df8094"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model architectures defined, made robust, and fully symmetrical.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 8. Define Matcher and Loss Functions (Final Corrected Version)\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class HungarianMatcher(nn.Module):\n",
        "    \"\"\"\n",
        "    This class computes an assignment between the model's predictions and the ground truth.\n",
        "    It loops through each sample in the batch to create a 2D cost matrix, which is what\n",
        "    the assignment algorithm expects.\n",
        "    \"\"\"\n",
        "    def __init__(self, cost_class: float = 1, cost_bbox: float = 1):\n",
        "        super().__init__()\n",
        "        self.cost_class = cost_class\n",
        "        self.cost_bbox = cost_bbox\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def forward(self, outputs, targets):\n",
        "        bs, num_queries = outputs.shape[:2]\n",
        "\n",
        "        indices = []\n",
        "        # --- CRUCIAL FIX: Iterate over each sample in the batch ---\n",
        "        for i in range(bs):\n",
        "            out_prob = outputs[i, :, :1].sigmoid() # Probabilities for this sample\n",
        "            out_bbox = outputs[i, :, 1:]           # Predicted boxes for this sample\n",
        "\n",
        "            tgt_bbox = targets[i][\"loc_info\"].to(out_prob.device) # Target boxes for this sample\n",
        "\n",
        "            # Compute the classification cost (L1)\n",
        "            cost_class = -out_prob\n",
        "\n",
        "            # Compute the L1 cost between boxes\n",
        "            cost_bbox = torch.cdist(out_bbox, tgt_bbox, p=1)\n",
        "\n",
        "            # Final cost matrix for this sample (shape: [num_queries, num_targets])\n",
        "            C = self.cost_bbox * cost_bbox + self.cost_class * cost_class\n",
        "\n",
        "            # Run the assignment algorithm on the 2D cost matrix\n",
        "            indices.append(linear_sum_assignment(C.cpu()))\n",
        "\n",
        "        return [(torch.as_tensor(i, dtype=torch.int64), torch.as_tensor(j, dtype=torch.int64)) for i, j in indices]\n",
        "\n",
        "\n",
        "class SetCriterion(nn.Module):\n",
        "    def __init__(self,c):\n",
        "        super().__init__(); p=c['finetuning']; self.m=HungarianMatcher(p['matcher_costs']['set_cost_class'],p['matcher_costs']['set_cost_bbox']); self.w=p['loss_weights']; self.nq=p['model_params']['num_queries']\n",
        "    def loss_match(self,o,t,i):\n",
        "        src_idx = self._get_src_p_idx(i)\n",
        "        target_boxes = torch.cat([v[\"loc_info\"][j] for v,(_,j) in zip(t,i) if len(j)>0], dim=0)\n",
        "        if target_boxes.numel() == 0: return {'loss_matching': torch.tensor(0.0, device=o.device)}\n",
        "\n",
        "        pred_boxes = o[src_idx]\n",
        "        return {'loss_matching': F.l1_loss(pred_boxes[:, 1:], target_boxes)}\n",
        "\n",
        "    def loss_unmatch(self,o,t,i):\n",
        "        # Create a mask for matched predictions\n",
        "        src_idx = self._get_src_p_idx(i)\n",
        "        mask = torch.ones(o.shape[0], o.shape[1], dtype=torch.bool, device=o.device)\n",
        "        mask[src_idx] = False\n",
        "\n",
        "        # Get the scores of unmatched predictions\n",
        "        unmatched_scores = o[mask][:, 0].sigmoid()\n",
        "        return {'loss_unmatching': unmatched_scores.mean()}\n",
        "\n",
        "    def loss_height(self,o,t,i):\n",
        "        src_idx = self._get_src_p_idx(i)\n",
        "        if src_idx[0].numel() == 0: return {'loss_height_constraint': torch.tensor(0.0, device=o.device)}\n",
        "\n",
        "        pred_heights = o[src_idx][:, 2]\n",
        "        batch_indices = src_idx[0]\n",
        "\n",
        "        # Calculate the sum of heights for each sample in the batch\n",
        "        total_height_loss = 0\n",
        "        for b in range(o.shape[0]):\n",
        "            heights_for_sample = pred_heights[batch_indices == b]\n",
        "            if heights_for_sample.numel() > 0:\n",
        "                total_height_loss += torch.abs(heights_for_sample.sum() - 1)\n",
        "\n",
        "        return {'loss_height_constraint': total_height_loss / o.shape[0]}\n",
        "\n",
        "    def _get_src_p_idx(self,i):\n",
        "        b=torch.cat([torch.full_like(s,k) for k,(s,_) in enumerate(i)]); s=torch.cat([s for s,_ in i]); return b,s\n",
        "\n",
        "    def forward(self,o,t):\n",
        "        i=self.m(o,t);\n",
        "        losses = {}\n",
        "        losses.update(self.loss_match(o,t,i))\n",
        "        losses.update(self.loss_unmatch(o,t,i))\n",
        "        losses.update(self.loss_height(o,t,i))\n",
        "        return {ln: l for ln,l in losses.items() if self.w[ln]>0}\n",
        "\n",
        "print(\"✅ Matcher and loss functions defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkCs711SJN9w",
        "outputId": "4b4b35d4-2a98-46fd-8e51-3e329e1eebca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Matcher and loss functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 9. Define Helper and Utility Functions\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images, targets = zip(*batch)\n",
        "    return torch.stack(images), list(targets)\n",
        "\n",
        "def load_pretrained_encoder_weights(model, path):\n",
        "    print(f\"--> Loading pre-trained weights from {path}\")\n",
        "    pre_dict = torch.load(path)\n",
        "    model_dict = model.state_dict()\n",
        "    enc_dict = {k.replace('module.',''):v for k,v in pre_dict.items() if any(x in k for x in ['e1','e2','e3','mid','start'])}\n",
        "    enc_dict = {'encoder.'+k:v for k,v in enc_dict.items()}\n",
        "    model_dict.update(enc_dict)\n",
        "    model.load_state_dict(model_dict, strict=False)\n",
        "    print(f\"✅ Loaded {len(enc_dict)} pre-trained layers.\")\n",
        "    return model\n",
        "\n",
        "print(\"✅ Helper functions defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VustgxDJJOAq",
        "outputId": "eca0ae9f-8b04-4f17-c470-d4e16488d174"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Helper functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 10. Define Pre-training Stage Function (W&B Sweep) (Corrected)\n",
        "from tqdm import tqdm\n",
        "\n",
        "# A global variable to track the best loss across all sweep runs\n",
        "best_pretrain_loss = float('inf')\n",
        "\n",
        "def train_autoencoder_sweep():\n",
        "    global best_pretrain_loss, config\n",
        "    with wandb.init() as run:\n",
        "        sweep_cfg = wandb.config\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # --- CORRECTED: Use the new UNet1D model ---\n",
        "        model = UNet1D(in_channels=sweep_cfg.in_channels, activation=sweep_cfg.act_name).to(device)\n",
        "\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = getattr(torch.optim, sweep_cfg.optimizer)(model.parameters(), lr=sweep_cfg.lr)\n",
        "        train_loader = data.DataLoader(AutoencoderDataset(config), batch_size=sweep_cfg.batch_size, shuffle=True)\n",
        "\n",
        "        print(f\"--- Starting W&B Run with config: {dict(sweep_cfg)} ---\")\n",
        "        for epoch in range(sweep_cfg.epochs):\n",
        "            model.train()\n",
        "            total_loss = 0.0\n",
        "            for img, tgt in train_loader:\n",
        "                img, tgt = img.to(device), tgt.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                output = model(img)\n",
        "                loss = criterion(output, tgt)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            epoch_loss = total_loss / len(train_loader)\n",
        "            wandb.log({\"epoch\": epoch, \"loss\": epoch_loss})\n",
        "\n",
        "            if epoch_loss < best_pretrain_loss:\n",
        "                best_pretrain_loss = epoch_loss\n",
        "                print(f\"    *** New best model found! Loss: {best_pretrain_loss:.6f} (Epoch {epoch+1}) ***\")\n",
        "                torch.save(model.state_dict(), config['paths']['pretrained_encoder_path'])\n",
        "                wandb.summary[\"best_loss\"] = best_pretrain_loss\n",
        "\n",
        "print(\"✅ Pre-training (sweep) function defined with 1D U-Net.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKvDhkF-JOCi",
        "outputId": "63fb21ba-0b5d-4483-dde3-296c3803a3f6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Pre-training (sweep) function defined with 1D U-Net.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 11. Define Fine-tuning Stage Function\n",
        "\n",
        "def run_finetuning(config):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    ft_params = config['finetuning']\n",
        "    loader = data.DataLoader(BoundaryDataset(config, seed=42), batch_size=ft_params['batch_size'], shuffle=True, collate_fn=collate_fn)\n",
        "    model = W2WTransformerModel(config).to(device)\n",
        "    model = load_pretrained_encoder_weights(model, config['paths']['pretrained_encoder_path'])\n",
        "    criterion = SetCriterion(config).to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=ft_params['learning_rate'])\n",
        "\n",
        "    for epoch in range(ft_params['epochs']):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for images, targets in tqdm(loader, desc=f'Epoch {epoch+1}/{ft_params[\"epochs\"]}'):\n",
        "            images, targets = images.to(device), [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "            loss_dict = criterion(model(images), targets)\n",
        "            losses = sum(loss_dict[k] * criterion.w[k] for k in loss_dict.keys())\n",
        "            optimizer.zero_grad(); losses.backward(); optimizer.step()\n",
        "            total_loss += losses.item(); wandb.log({'finetune_batch_loss': losses.item()})\n",
        "\n",
        "        avg_loss = total_loss / len(loader)\n",
        "        print(f'Epoch {epoch+1} Average Loss: {avg_loss:.4f}')\n",
        "        wandb.log({'finetune_epoch_loss': avg_loss, 'epoch': epoch})\n",
        "\n",
        "    torch.save(model.state_dict(), config['paths']['final_model_path'])\n",
        "    print(f\"✅ Final model saved to {config['paths']['final_model_path']}\")\n",
        "\n",
        "print(\"✅ Fine-tuning function defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-Iw7726JOGh",
        "outputId": "81d14625-a2e4-4c82-8d14-0035b4aecad1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fine-tuning function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 12. Define Inference and Plotting Functions\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def plot_well_correlation(well1, well2, layers1, layers2, matrix, threshold, path):\n",
        "    fig, ax = plt.subplots(figsize=(10, 12)); plt.style.use('seaborn-whitegrid')\n",
        "    if not layers1 or not layers2: print('Warning: One or both wells have no layers to plot.'); return\n",
        "    max_depth = max(layers1[-1]['bottom'], layers2[-1]['bottom']) if layers1 and layers2 else 1000\n",
        "    ax.set_ylim(max_depth + 50, -50); ax.set_xlim(-0.5, 2.5)\n",
        "    n1 = len(set(l['Group'] for l in layers1)); n2 = len(set(l['Group'] for l in layers2))\n",
        "    for l in layers1: ax.add_patch(patches.Rectangle((0, l['Top']), 1, l['Height'], ec='k', fc=plt.cm.viridis(l['Group']/(n1 if n1>0 else 1)), alpha=0.6))\n",
        "    for l in layers2: ax.add_patch(patches.Rectangle((1.5, l['Top']), 1, l['Height'], ec='k', fc=plt.cm.viridis(l['Group']/(n2 if n2>0 else 1)), alpha=0.6))\n",
        "    for i, row in enumerate(matrix):\n",
        "        for j, sim in enumerate(row):\n",
        "            if sim >= threshold: ax.add_patch(patches.Polygon([[1,layers1[i]['Top']],[1,layers1[i]['bottom']],[1.5,layers2[j]['bottom']],[1.5,layers2[j]['Top']]], fc=plt.cm.Greens(sim), alpha=0.5))\n",
        "    ax.set_xticks([0.5, 2]); ax.set_xticklabels([well1, well2], fontsize=14); ax.set_ylabel('Depth', fontsize=12)\n",
        "    ax.set_title('Well to Well Correlation', fontsize=16); plt.savefig(path); plt.close()\n",
        "    print(f'--> Correlation plot saved to {path}')\n",
        "\n",
        "def run_correlation(config):\n",
        "    inf, p = config['inference'], config['paths']\n",
        "    full_data = pd.read_csv(p['processed_csv_path'], delimiter=';')\n",
        "    ref_df, woi_df = full_data[full_data['WELL'] == inf['reference_well']], full_data[full_data['WELL'] == inf['well_of_interest']]\n",
        "    if ref_df.empty or woi_df.empty: print(f\"Error: One/both wells not found: '{inf['reference_well']}', '{inf['well_of_interest']}'.\"); return\n",
        "\n",
        "    with open(p['label_encoder_path']) as f: le = json.load(f)\n",
        "    def get_true_layers(df):\n",
        "        df = df.copy().reset_index(drop=True)\n",
        "        df['group_id'] = df['GROUP'].astype(str).map(le).fillna(-1).astype(int)\n",
        "        b = np.where(df['group_id'].iloc[:-1].values != df['group_id'].iloc[1:].values)[0] + 1\n",
        "        indices = np.concatenate(([0], b, [len(df)]))\n",
        "        layers = []\n",
        "        for i in range(len(indices) - 1):\n",
        "            s, e = indices[i], indices[i+1]\n",
        "            layers.append({'Top':df['DEPTH_MD'].iloc[s],'bottom':df['DEPTH_MD'].iloc[e-1],'Height':df['DEPTH_MD'].iloc[e-1]-df['DEPTH_MD'].iloc[s],'Group':df['group_id'].iloc[s]})\n",
        "        return layers\n",
        "\n",
        "    ref_layers, woi_layers = get_true_layers(ref_df), get_true_layers(woi_df)\n",
        "    sim_matrix = np.zeros((len(ref_layers), len(woi_layers)))\n",
        "    for i,l1 in enumerate(ref_layers):\n",
        "        for j,l2 in enumerate(woi_layers):\n",
        "            if l1['Group'] == l2['Group'] and l1['Group'] != -1: sim_matrix[i,j] = np.random.uniform(0.8, 0.95)\n",
        "            else: sim_matrix[i,j] = np.random.uniform(0.1, 0.4)\n",
        "\n",
        "    print('--> MOCK INFERENCE: Using ground truth layers for visualization.')\n",
        "    output_path = 'well_correlation_plot.png'\n",
        "    plot_well_correlation(inf['reference_well'], inf['well_of_interest'], ref_layers, woi_layers, sim_matrix, inf['correlation_threshold'], output_path)\n",
        "    wandb.log({\"well_correlation_plot\": wandb.Image(output_path)})\n",
        "\n",
        "print(\"✅ Inference and plotting functions defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bGlyIyTJOIw",
        "outputId": "e4d52fc0-6640-46ab-dbfd-cd48759b992f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Inference and plotting functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 13. 🚀 Run the Full Pipeline\n",
        "\n",
        "# --- STAGE 0: DATA PREPARATION ---\n",
        "if config[\"run_data_preparation\"]:\n",
        "    run_data_preparation(config)\n",
        "    print(\"\\n--- STAGE 0 COMPLETE ---\\n\")\n",
        "\n",
        "# --- STAGE 1: PRE-TRAINING (W&B SWEEP) ---\n",
        "if config.get('run_pretraining', False):\n",
        "    print(\"\\n--- LAUNCHING PIPELINE 1: AUTOENCODER PRE-TRAINING (W&B SWEEP) ---\")\n",
        "    sweep_id = wandb.sweep(config['pretraining_sweep'], project=config['wandb']['project'], entity=config['wandb'].get('entity'))\n",
        "    wandb.agent(sweep_id, function=train_autoencoder_sweep, count=config['wandb']['sweep_count'])\n",
        "    print(f\"\\n🏆 Sweep finished. Best pre-trained model saved to {config['paths']['pretrained_encoder_path']}\")\n",
        "    print(\"\\n--- STAGE 1 COMPLETE ---\\n\")\n",
        "\n",
        "# --- STAGE 2: FINE-TUNING ---\n",
        "if config.get('run_finetuning', False):\n",
        "    print(\"\\n--- LAUNCHING PIPELINE 2: FINE-TUNING ---\")\n",
        "    with wandb.init(project=config['wandb']['project'], entity=config['wandb'].get('entity'), job_type='fine-tuning', config=config) as run:\n",
        "        print(f\"--> W&B Run started. View at: {run.get_url()}\")\n",
        "        run_finetuning(config)\n",
        "        artifact = wandb.Artifact(\"boundary-detector-model\", type=\"model\", description=\"Final fine-tuned W2W Transformer model\")\n",
        "        artifact.add_file(config['paths']['final_model_path'])\n",
        "        run.log_artifact(artifact)\n",
        "        print(\"✅ Final model logged as a W&B Artifact.\")\n",
        "    print(\"\\n--- STAGE 2 COMPLETE ---\\n\")\n",
        "\n",
        "# --- STAGE 3: INFERENCE ---\n",
        "if config.get('run_inference', False):\n",
        "    print(\"\\n--- LAUNCHING PIPELINE 3: WELL-TO-WELL INFERENCE ---\")\n",
        "    with wandb.init(project=config['wandb']['project'], entity=config['wandb'].get('entity'), job_type='inference', config=config) as run:\n",
        "        print(f\"--> W&B Run started. View at: {run.get_url()}\")\n",
        "        run_correlation(config)\n",
        "    print(\"\\n--- STAGE 3 COMPLETE ---\\n\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✅✅✅ All Requested Pipeline Stages are Complete! ✅✅✅\")\n",
        "print(\"You can view all your results, models, and charts in your Weights & Biases project.\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YNHZ52v_JOK7",
        "outputId": "e38673d8-e91e-4c6c-b4b6-64b8cfc5e38c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- LAUNCHING PIPELINE 0: DATA PREPARATION ---\n",
            "--> Searching for .las files in 'data/raw_las_files/'...\n",
            "--> Found 118 .las files. Reading now...\n",
            "--> Saved combined data to 'data/train.csv'\n",
            "\n",
            "--- Available Well Names for Inference ---\n",
            "- 35/4-1\n",
            "- 34/8-7R\n",
            "- 16/11-1S T3\n",
            "- 7/1-2 S\n",
            "- 34/3-2 S\n",
            "- 31/2-10\n",
            "- 25/7-2\n",
            "- 25/11-24 Jakob South\n",
            "- 25/10-9 Aegis\n",
            "- 34/10-33\n",
            "- 16/7-6\n",
            "- 34/3-3 A\n",
            "- 31/2-8\n",
            "- 31/4-5\n",
            "- 35/8-6 S\n",
            "- 34/4-10 R\n",
            "- 16/2-6 Johan Sverdrup\n",
            "- 31/2-1\n",
            "- 25/6-2  Delta-Beta\n",
            "- 31/2-9\n",
            "- 35/11-11\n",
            "- 34/3-1 A\n",
            "- 35/9-2\n",
            "- 31/2-19 S\n",
            "- 31/6-8\n",
            "- 25/8-5 S  Jotun\n",
            "- 16/10-2 Delta\n",
            "- 34/10-21\n",
            "- 25/3-1\n",
            "- 16/8-1\n",
            "- 31/3-4\n",
            "- 35/11-13\n",
            "- 34/10-19\n",
            "- 25/10-10  Balder Triassic\n",
            "- 36/7-3\n",
            "- 15/9-23 Skardkollen\n",
            "- 30/3-3\n",
            "- 34/8-1\n",
            "- 34/11-2 S\n",
            "- 16/7-5\n",
            "- 34/7-13\n",
            "- 31/5-4 S\n",
            "- 16/2-7 Johan Sverdrup Appr\n",
            "- 25/2-13 T4\n",
            "- 16/10-1 Alpha\n",
            "- 35/11-15 S\n",
            "- 32/2-1\n",
            "- 16/4-1\n",
            "- 35/3-7 S\n",
            "- 34/8-3\n",
            "- 35/11-10\n",
            "- 34/11-1\n",
            "- 35/12-1\n",
            "- 25/11-5 Balder Appr\n",
            "- 35/11-7\n",
            "- 16/1-2  Ivar Aasen Appr\n",
            "- 33/6-3 S\n",
            "- 35/11-12\n",
            "- 15/9-14\n",
            "- 31/2-7\n",
            "- 35/11-1\n",
            "- 34/7-21\n",
            "- 25/5-4  Byggve\n",
            "- 25/8-7  Krap 1\n",
            "- 25/9-1  Rummel\n",
            "- 31/3-3\n",
            "- 35/8-4\n",
            "- 15/9-13 Sleipner East Appr\n",
            "- 34/5-1 A\n",
            "- 34/12-1\n",
            "- 25/4-5\n",
            "- 31/3-2\n",
            "- 33/9-1\n",
            "- 17/4-1\n",
            "- 15/9-17\n",
            "- 16/2-16 Johan Sverdrup Appr\n",
            "- 16/5-3 Johan Sverdrup Appr\n",
            "- 16/1-6 A Verdandi Appr\n",
            "- 34/7-20\n",
            "- 33/9-17\n",
            "- 35/9-10 S\n",
            "- 31/6-5\n",
            "- 31/2-21 S\n",
            "- 35/9-8\n",
            "- 34/5-1 S\n",
            "- 30/6-5\n",
            "- 35/6-2 S\n",
            "- 35/9-7\n",
            "- 34/10-16R\n",
            "- 26/4-1\n",
            "- 35/11-6\n",
            "- 16/2-11 A Johan Sverdrup Appr\n",
            "- 33/5-2\n",
            "- 16/10-3 Tyr Central\n",
            "- 16/10-5 Isbjoern\n",
            "- 25/2-7\n",
            "- 25/6-1\n",
            "- 31/3-1\n",
            "- 16/7-4 Sigyn\n",
            "- 29/6-1\n",
            "- 34/10-35\n",
            "- 17/11-1\n",
            "- 35/11-5\n",
            "- 15/9-15 Gungne\n",
            "- 35/9-5\n",
            "- 30/3-5S\n",
            "- 25/11-15  Grane\n",
            "- 25/2-14 Froey Appr\n",
            "- 34/2-4\n",
            "- 25/5-3  Skirne\n",
            "- 7/1-1\n",
            "- 31/4-10\n",
            "- 25/5-1 Froey\n",
            "- 25/6-3\n",
            "- 35/9-6 S\n",
            "- 29/3-1\n",
            "- 25/11-19 S  Balder Appr\n",
            "- 34/6-1\n",
            "------------------------------------------\n",
            "TIP: Copy/paste two of these names into the 'inference' section of the config cell above.\n",
            "\n",
            "--> Saved label encoder to 'artifacts/label_encoder.json'\n",
            "--> Saved StandardScaler to 'artifacts/StandardScaler.bin'\n",
            "\n",
            "✅ Automatically detected 25 features (input channels) from the data.\n",
            "\n",
            "--- STAGE 0 COMPLETE ---\n",
            "\n",
            "\n",
            "--- LAUNCHING PIPELINE 1: AUTOENCODER PRE-TRAINING (W&B SWEEP) ---\n",
            "Create sweep with ID: 55uu3ywb\n",
            "Sweep URL: https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: atzyttuu with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tact_name: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_channels: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: RMSprop\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msahilpareek203\u001b[0m (\u001b[33msahilpareek203-amrita-vishwa-vidyapeetham\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250718_165435-atzyttuu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/atzyttuu' target=\"_blank\">fresh-sweep-1</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/atzyttuu' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/atzyttuu</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting W&B Run with config: {'act_name': 'relu', 'batch_size': 32, 'epochs': 25, 'in_channels': 25, 'lr': 0.0001, 'optimizer': 'RMSprop'} ---\n",
            "    *** New best model found! Loss: 0.821698 (Epoch 1) ***\n",
            "    *** New best model found! Loss: 0.685048 (Epoch 2) ***\n",
            "    *** New best model found! Loss: 0.628560 (Epoch 3) ***\n",
            "    *** New best model found! Loss: 0.591594 (Epoch 4) ***\n",
            "    *** New best model found! Loss: 0.560599 (Epoch 5) ***\n",
            "    *** New best model found! Loss: 0.537167 (Epoch 6) ***\n",
            "    *** New best model found! Loss: 0.514409 (Epoch 7) ***\n",
            "    *** New best model found! Loss: 0.492698 (Epoch 8) ***\n",
            "    *** New best model found! Loss: 0.476900 (Epoch 9) ***\n",
            "    *** New best model found! Loss: 0.465546 (Epoch 10) ***\n",
            "    *** New best model found! Loss: 0.449828 (Epoch 11) ***\n",
            "    *** New best model found! Loss: 0.438199 (Epoch 12) ***\n",
            "    *** New best model found! Loss: 0.428672 (Epoch 13) ***\n",
            "    *** New best model found! Loss: 0.418053 (Epoch 14) ***\n",
            "    *** New best model found! Loss: 0.405186 (Epoch 15) ***\n",
            "    *** New best model found! Loss: 0.398655 (Epoch 16) ***\n",
            "    *** New best model found! Loss: 0.387775 (Epoch 17) ***\n",
            "    *** New best model found! Loss: 0.383545 (Epoch 18) ***\n",
            "    *** New best model found! Loss: 0.376542 (Epoch 19) ***\n",
            "    *** New best model found! Loss: 0.370999 (Epoch 20) ***\n",
            "    *** New best model found! Loss: 0.360110 (Epoch 21) ***\n",
            "    *** New best model found! Loss: 0.359047 (Epoch 22) ***\n",
            "    *** New best model found! Loss: 0.351101 (Epoch 23) ***\n",
            "    *** New best model found! Loss: 0.343097 (Epoch 25) ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_loss</td><td>0.3431</td></tr><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.3431</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fresh-sweep-1</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/atzyttuu' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/atzyttuu</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250718_165435-atzyttuu/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xg2aixgc with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tact_name: prelu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_channels: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: AdamW\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250718_165605-xg2aixgc</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/xg2aixgc' target=\"_blank\">morning-sweep-2</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/xg2aixgc' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/xg2aixgc</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting W&B Run with config: {'act_name': 'prelu', 'batch_size': 16, 'epochs': 25, 'in_channels': 25, 'lr': 0.0001, 'optimizer': 'AdamW'} ---\n",
            "    *** New best model found! Loss: 0.326887 (Epoch 12) ***\n",
            "    *** New best model found! Loss: 0.315534 (Epoch 13) ***\n",
            "    *** New best model found! Loss: 0.305542 (Epoch 14) ***\n",
            "    *** New best model found! Loss: 0.292467 (Epoch 15) ***\n",
            "    *** New best model found! Loss: 0.289918 (Epoch 16) ***\n",
            "    *** New best model found! Loss: 0.278840 (Epoch 17) ***\n",
            "    *** New best model found! Loss: 0.272129 (Epoch 18) ***\n",
            "    *** New best model found! Loss: 0.264500 (Epoch 19) ***\n",
            "    *** New best model found! Loss: 0.259720 (Epoch 20) ***\n",
            "    *** New best model found! Loss: 0.256637 (Epoch 21) ***\n",
            "    *** New best model found! Loss: 0.247150 (Epoch 22) ***\n",
            "    *** New best model found! Loss: 0.242329 (Epoch 23) ***\n",
            "    *** New best model found! Loss: 0.232932 (Epoch 24) ***\n",
            "    *** New best model found! Loss: 0.228160 (Epoch 25) ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▆▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_loss</td><td>0.22816</td></tr><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.22816</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">morning-sweep-2</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/xg2aixgc' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/xg2aixgc</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250718_165605-xg2aixgc/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vfc55sl4 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tact_name: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_channels: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250718_165750-vfc55sl4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/vfc55sl4' target=\"_blank\">genial-sweep-3</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/vfc55sl4' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/vfc55sl4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting W&B Run with config: {'act_name': 'relu', 'batch_size': 16, 'epochs': 25, 'in_channels': 25, 'lr': 0.001, 'optimizer': 'Adam'} ---\n",
            "    *** New best model found! Loss: 0.225706 (Epoch 19) ***\n",
            "    *** New best model found! Loss: 0.215721 (Epoch 20) ***\n",
            "    *** New best model found! Loss: 0.202339 (Epoch 21) ***\n",
            "    *** New best model found! Loss: 0.189587 (Epoch 25) ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_loss</td><td>0.18959</td></tr><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.18959</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">genial-sweep-3</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/vfc55sl4' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/vfc55sl4</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250718_165750-vfc55sl4/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: avagz9q5 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tact_name: prelu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_channels: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250718_165924-avagz9q5</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/avagz9q5' target=\"_blank\">firm-sweep-4</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/avagz9q5' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/avagz9q5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting W&B Run with config: {'act_name': 'prelu', 'batch_size': 16, 'epochs': 25, 'in_channels': 25, 'lr': 0.001, 'optimizer': 'Adam'} ---\n",
            "    *** New best model found! Loss: 0.187360 (Epoch 7) ***\n",
            "    *** New best model found! Loss: 0.175058 (Epoch 8) ***\n",
            "    *** New best model found! Loss: 0.155503 (Epoch 9) ***\n",
            "    *** New best model found! Loss: 0.146177 (Epoch 10) ***\n",
            "    *** New best model found! Loss: 0.133447 (Epoch 11) ***\n",
            "    *** New best model found! Loss: 0.126933 (Epoch 14) ***\n",
            "    *** New best model found! Loss: 0.117395 (Epoch 15) ***\n",
            "    *** New best model found! Loss: 0.115042 (Epoch 16) ***\n",
            "    *** New best model found! Loss: 0.115025 (Epoch 17) ***\n",
            "    *** New best model found! Loss: 0.111491 (Epoch 19) ***\n",
            "    *** New best model found! Loss: 0.105559 (Epoch 20) ***\n",
            "    *** New best model found! Loss: 0.103705 (Epoch 21) ***\n",
            "    *** New best model found! Loss: 0.098445 (Epoch 24) ***\n",
            "    *** New best model found! Loss: 0.098367 (Epoch 25) ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_loss</td><td>0.09837</td></tr><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.09837</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">firm-sweep-4</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/avagz9q5' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/avagz9q5</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250718_165924-avagz9q5/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cgkgh9tl with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tact_name: prelu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_channels: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: AdamW\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250718_170105-cgkgh9tl</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/cgkgh9tl' target=\"_blank\">radiant-sweep-5</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/cgkgh9tl' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/cgkgh9tl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting W&B Run with config: {'act_name': 'prelu', 'batch_size': 16, 'epochs': 25, 'in_channels': 25, 'lr': 0.001, 'optimizer': 'AdamW'} ---\n",
            "    *** New best model found! Loss: 0.092284 (Epoch 25) ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_loss</td><td>0.09228</td></tr><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.09228</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">radiant-sweep-5</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/cgkgh9tl' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/cgkgh9tl</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250718_170105-cgkgh9tl/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🏆 Sweep finished. Best pre-trained model saved to trained_models/autoencoder/best_autoencoder.pt\n",
            "\n",
            "--- STAGE 1 COMPLETE ---\n",
            "\n",
            "\n",
            "--- LAUNCHING PIPELINE 2: FINE-TUNING ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'W2W_Matcher_Pipeline_Notebook' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250718_170239-cgkgh9tl</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/cgkgh9tl' target=\"_blank\">radiant-sweep-5</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/cgkgh9tl' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/cgkgh9tl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> W&B Run started. View at: https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/cgkgh9tl\n",
            "--> Dynamically calculated transformer input features: 22528\n",
            "--> Loading pre-trained weights from trained_models/autoencoder/best_autoencoder.pt\n",
            "✅ Loaded 80 pre-trained layers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/200: 100%|██████████| 2/2 [00:00<00:00,  2.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Average Loss: 0.7407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/200: 100%|██████████| 2/2 [00:00<00:00, 18.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Average Loss: 0.3601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/200: 100%|██████████| 2/2 [00:00<00:00, 21.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Average Loss: 0.3420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/200: 100%|██████████| 2/2 [00:00<00:00, 22.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Average Loss: 0.3401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/200: 100%|██████████| 2/2 [00:00<00:00, 25.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Average Loss: 0.3345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/200: 100%|██████████| 2/2 [00:00<00:00, 27.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Average Loss: 0.3286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/200: 100%|██████████| 2/2 [00:00<00:00, 26.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Average Loss: 0.3278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/200: 100%|██████████| 2/2 [00:00<00:00, 26.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Average Loss: 0.3477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/200: 100%|██████████| 2/2 [00:00<00:00, 26.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Average Loss: 0.3468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/200: 100%|██████████| 2/2 [00:00<00:00, 26.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Average Loss: 0.3326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/200: 100%|██████████| 2/2 [00:00<00:00, 26.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 Average Loss: 0.3521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/200: 100%|██████████| 2/2 [00:00<00:00, 26.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 Average Loss: 0.3251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/200: 100%|██████████| 2/2 [00:00<00:00, 25.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 Average Loss: 0.3132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/200: 100%|██████████| 2/2 [00:00<00:00, 25.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 Average Loss: 0.3091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/200: 100%|██████████| 2/2 [00:00<00:00, 27.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 Average Loss: 0.3076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/200: 100%|██████████| 2/2 [00:00<00:00, 26.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 Average Loss: 0.3112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/200: 100%|██████████| 2/2 [00:00<00:00, 23.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 Average Loss: 0.3034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/200: 100%|██████████| 2/2 [00:00<00:00, 26.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 Average Loss: 0.3010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/200: 100%|██████████| 2/2 [00:00<00:00, 26.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 Average Loss: 0.2969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/200: 100%|██████████| 2/2 [00:00<00:00, 26.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 Average Loss: 0.3029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/200: 100%|██████████| 2/2 [00:00<00:00, 25.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 Average Loss: 0.2957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/200: 100%|██████████| 2/2 [00:00<00:00, 25.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 Average Loss: 0.2960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/200: 100%|██████████| 2/2 [00:00<00:00, 26.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 Average Loss: 0.2929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/200: 100%|██████████| 2/2 [00:00<00:00, 25.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 Average Loss: 0.2904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/200: 100%|██████████| 2/2 [00:00<00:00, 14.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 Average Loss: 0.2910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/200: 100%|██████████| 2/2 [00:00<00:00, 26.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 Average Loss: 0.2894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/200: 100%|██████████| 2/2 [00:00<00:00, 26.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27 Average Loss: 0.2898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/200: 100%|██████████| 2/2 [00:00<00:00, 22.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 Average Loss: 0.2908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/200: 100%|██████████| 2/2 [00:00<00:00, 27.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 Average Loss: 0.2901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/200: 100%|██████████| 2/2 [00:00<00:00, 24.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 Average Loss: 0.2886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/200: 100%|██████████| 2/2 [00:00<00:00, 25.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31 Average Loss: 0.2878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/200: 100%|██████████| 2/2 [00:00<00:00, 25.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32 Average Loss: 0.2826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/200: 100%|██████████| 2/2 [00:00<00:00, 25.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33 Average Loss: 0.2877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/200: 100%|██████████| 2/2 [00:00<00:00, 25.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34 Average Loss: 0.2893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/200: 100%|██████████| 2/2 [00:00<00:00, 26.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35 Average Loss: 0.2838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/200: 100%|██████████| 2/2 [00:00<00:00, 25.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36 Average Loss: 0.2835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/200: 100%|██████████| 2/2 [00:00<00:00, 25.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37 Average Loss: 0.2835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/200: 100%|██████████| 2/2 [00:00<00:00, 26.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38 Average Loss: 0.2794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/200: 100%|██████████| 2/2 [00:00<00:00, 24.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39 Average Loss: 0.2788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/200: 100%|██████████| 2/2 [00:00<00:00, 23.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40 Average Loss: 0.2817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/200: 100%|██████████| 2/2 [00:00<00:00, 26.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41 Average Loss: 0.2773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/200: 100%|██████████| 2/2 [00:00<00:00, 24.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42 Average Loss: 0.2771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/200: 100%|██████████| 2/2 [00:00<00:00, 25.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43 Average Loss: 0.2792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/200: 100%|██████████| 2/2 [00:00<00:00, 26.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44 Average Loss: 0.2736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/200: 100%|██████████| 2/2 [00:00<00:00, 25.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45 Average Loss: 0.2786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/200: 100%|██████████| 2/2 [00:00<00:00, 27.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46 Average Loss: 0.2743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/200: 100%|██████████| 2/2 [00:00<00:00, 26.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47 Average Loss: 0.2742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/200: 100%|██████████| 2/2 [00:00<00:00, 26.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48 Average Loss: 0.2737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/200: 100%|██████████| 2/2 [00:00<00:00, 25.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49 Average Loss: 0.2718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/200: 100%|██████████| 2/2 [00:00<00:00, 25.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50 Average Loss: 0.2783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 51/200: 100%|██████████| 2/2 [00:00<00:00, 26.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51 Average Loss: 0.2741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 52/200: 100%|██████████| 2/2 [00:00<00:00, 27.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52 Average Loss: 0.2776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 53/200: 100%|██████████| 2/2 [00:00<00:00, 22.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53 Average Loss: 0.2765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 54/200: 100%|██████████| 2/2 [00:00<00:00, 25.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54 Average Loss: 0.2743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 55/200: 100%|██████████| 2/2 [00:00<00:00, 24.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55 Average Loss: 0.2690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 56/200: 100%|██████████| 2/2 [00:00<00:00, 26.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56 Average Loss: 0.2858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 57/200: 100%|██████████| 2/2 [00:00<00:00, 25.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57 Average Loss: 0.2723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 58/200: 100%|██████████| 2/2 [00:00<00:00, 26.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58 Average Loss: 0.2741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 59/200: 100%|██████████| 2/2 [00:00<00:00, 26.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59 Average Loss: 0.2782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 60/200: 100%|██████████| 2/2 [00:00<00:00, 26.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60 Average Loss: 0.2777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 61/200: 100%|██████████| 2/2 [00:00<00:00, 26.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61 Average Loss: 0.2709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 62/200: 100%|██████████| 2/2 [00:00<00:00, 25.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62 Average Loss: 0.2724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 63/200: 100%|██████████| 2/2 [00:00<00:00, 25.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63 Average Loss: 0.3258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 64/200: 100%|██████████| 2/2 [00:00<00:00, 20.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64 Average Loss: 0.2967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 65/200: 100%|██████████| 2/2 [00:00<00:00, 16.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65 Average Loss: 0.3006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 66/200: 100%|██████████| 2/2 [00:00<00:00, 21.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66 Average Loss: 0.2808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 67/200: 100%|██████████| 2/2 [00:00<00:00, 22.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67 Average Loss: 0.2794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 68/200: 100%|██████████| 2/2 [00:00<00:00, 21.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68 Average Loss: 0.2992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 69/200: 100%|██████████| 2/2 [00:00<00:00, 22.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69 Average Loss: 0.2716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 70/200: 100%|██████████| 2/2 [00:00<00:00, 24.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70 Average Loss: 0.2821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 71/200: 100%|██████████| 2/2 [00:00<00:00, 24.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71 Average Loss: 0.2883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 72/200: 100%|██████████| 2/2 [00:00<00:00, 19.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72 Average Loss: 0.2949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 73/200: 100%|██████████| 2/2 [00:00<00:00, 22.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73 Average Loss: 0.2848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 74/200: 100%|██████████| 2/2 [00:00<00:00, 23.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74 Average Loss: 0.2797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 75/200: 100%|██████████| 2/2 [00:00<00:00, 20.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75 Average Loss: 0.2720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 76/200: 100%|██████████| 2/2 [00:00<00:00, 21.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76 Average Loss: 0.2642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 77/200: 100%|██████████| 2/2 [00:00<00:00, 22.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77 Average Loss: 0.2653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 78/200: 100%|██████████| 2/2 [00:00<00:00, 22.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 78 Average Loss: 0.2596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 79/200: 100%|██████████| 2/2 [00:00<00:00, 22.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 79 Average Loss: 0.2581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 80/200: 100%|██████████| 2/2 [00:00<00:00, 20.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 80 Average Loss: 0.2594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 81/200: 100%|██████████| 2/2 [00:00<00:00, 23.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 81 Average Loss: 0.2578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 82/200: 100%|██████████| 2/2 [00:00<00:00, 21.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 82 Average Loss: 0.2572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 83/200: 100%|██████████| 2/2 [00:00<00:00, 23.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 83 Average Loss: 0.2586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 84/200: 100%|██████████| 2/2 [00:00<00:00, 23.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 84 Average Loss: 0.2558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 85/200: 100%|██████████| 2/2 [00:00<00:00, 22.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 85 Average Loss: 0.2598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 86/200: 100%|██████████| 2/2 [00:00<00:00, 17.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 86 Average Loss: 0.2548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 87/200: 100%|██████████| 2/2 [00:00<00:00, 18.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 87 Average Loss: 0.2537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 88/200: 100%|██████████| 2/2 [00:00<00:00, 18.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 88 Average Loss: 0.2544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 89/200: 100%|██████████| 2/2 [00:00<00:00, 22.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 89 Average Loss: 0.2580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 90/200: 100%|██████████| 2/2 [00:00<00:00, 18.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 90 Average Loss: 0.2511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 91/200: 100%|██████████| 2/2 [00:00<00:00, 19.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 91 Average Loss: 0.2534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 92/200: 100%|██████████| 2/2 [00:00<00:00, 19.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 92 Average Loss: 0.2509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 93/200: 100%|██████████| 2/2 [00:00<00:00, 17.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 93 Average Loss: 0.2508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 94/200: 100%|██████████| 2/2 [00:00<00:00, 20.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 94 Average Loss: 0.2493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 95/200: 100%|██████████| 2/2 [00:00<00:00, 27.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 95 Average Loss: 0.2498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 96/200: 100%|██████████| 2/2 [00:00<00:00, 23.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 96 Average Loss: 0.2519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 97/200: 100%|██████████| 2/2 [00:00<00:00, 26.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 97 Average Loss: 0.2501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 98/200: 100%|██████████| 2/2 [00:00<00:00, 26.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 98 Average Loss: 0.2483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 99/200: 100%|██████████| 2/2 [00:00<00:00, 27.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 99 Average Loss: 0.2469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 100/200: 100%|██████████| 2/2 [00:00<00:00, 26.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100 Average Loss: 0.2521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 101/200: 100%|██████████| 2/2 [00:00<00:00, 26.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 101 Average Loss: 0.2479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 102/200: 100%|██████████| 2/2 [00:00<00:00, 26.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 102 Average Loss: 0.2493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 103/200: 100%|██████████| 2/2 [00:00<00:00, 25.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 103 Average Loss: 0.2480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 104/200: 100%|██████████| 2/2 [00:00<00:00, 25.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 104 Average Loss: 0.2448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 105/200: 100%|██████████| 2/2 [00:00<00:00, 26.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 105 Average Loss: 0.2482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 106/200: 100%|██████████| 2/2 [00:00<00:00, 26.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 106 Average Loss: 0.2465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 107/200: 100%|██████████| 2/2 [00:00<00:00, 24.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 107 Average Loss: 0.2441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 108/200: 100%|██████████| 2/2 [00:00<00:00, 25.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 108 Average Loss: 0.2445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 109/200: 100%|██████████| 2/2 [00:00<00:00, 23.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 109 Average Loss: 0.2429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 110/200: 100%|██████████| 2/2 [00:00<00:00, 26.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 110 Average Loss: 0.2397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 111/200: 100%|██████████| 2/2 [00:00<00:00, 25.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 111 Average Loss: 0.2458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 112/200: 100%|██████████| 2/2 [00:00<00:00, 26.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 112 Average Loss: 0.2415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 113/200: 100%|██████████| 2/2 [00:00<00:00, 26.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 113 Average Loss: 0.2426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 114/200: 100%|██████████| 2/2 [00:00<00:00, 25.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 114 Average Loss: 0.2413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 115/200: 100%|██████████| 2/2 [00:00<00:00, 24.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 115 Average Loss: 0.2389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 116/200: 100%|██████████| 2/2 [00:00<00:00, 25.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 116 Average Loss: 0.2435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 117/200: 100%|██████████| 2/2 [00:00<00:00, 26.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 117 Average Loss: 0.2398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 118/200: 100%|██████████| 2/2 [00:00<00:00, 26.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 118 Average Loss: 0.2400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 119/200: 100%|██████████| 2/2 [00:00<00:00, 26.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 119 Average Loss: 0.2411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 120/200: 100%|██████████| 2/2 [00:00<00:00, 25.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 120 Average Loss: 0.2401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 121/200: 100%|██████████| 2/2 [00:00<00:00, 23.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 121 Average Loss: 0.2382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 122/200: 100%|██████████| 2/2 [00:00<00:00, 25.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 122 Average Loss: 0.2358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 123/200: 100%|██████████| 2/2 [00:00<00:00, 25.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 123 Average Loss: 0.2393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 124/200: 100%|██████████| 2/2 [00:00<00:00, 25.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 124 Average Loss: 0.2354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 125/200: 100%|██████████| 2/2 [00:00<00:00, 25.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 125 Average Loss: 0.2349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 126/200: 100%|██████████| 2/2 [00:00<00:00, 26.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 126 Average Loss: 0.2344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 127/200: 100%|██████████| 2/2 [00:00<00:00, 25.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 127 Average Loss: 0.2338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 128/200: 100%|██████████| 2/2 [00:00<00:00, 24.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 128 Average Loss: 0.2367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 129/200: 100%|██████████| 2/2 [00:00<00:00, 24.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 129 Average Loss: 0.2332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 130/200: 100%|██████████| 2/2 [00:00<00:00, 26.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 130 Average Loss: 0.2352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 131/200: 100%|██████████| 2/2 [00:00<00:00, 25.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 131 Average Loss: 0.2325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 132/200: 100%|██████████| 2/2 [00:00<00:00, 25.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 132 Average Loss: 0.2324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 133/200: 100%|██████████| 2/2 [00:00<00:00, 23.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 133 Average Loss: 0.2299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 134/200: 100%|██████████| 2/2 [00:00<00:00, 25.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 134 Average Loss: 0.2326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 135/200: 100%|██████████| 2/2 [00:00<00:00, 25.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 135 Average Loss: 0.2325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 136/200: 100%|██████████| 2/2 [00:00<00:00, 25.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 136 Average Loss: 0.2332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 137/200: 100%|██████████| 2/2 [00:00<00:00, 24.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 137 Average Loss: 0.2314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 138/200: 100%|██████████| 2/2 [00:00<00:00, 26.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 138 Average Loss: 0.2331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 139/200: 100%|██████████| 2/2 [00:00<00:00, 27.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 139 Average Loss: 0.2292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 140/200: 100%|██████████| 2/2 [00:00<00:00, 23.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 140 Average Loss: 0.2267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 141/200: 100%|██████████| 2/2 [00:00<00:00, 25.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 141 Average Loss: 0.2308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 142/200: 100%|██████████| 2/2 [00:00<00:00, 26.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 142 Average Loss: 0.2273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 143/200: 100%|██████████| 2/2 [00:00<00:00, 24.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 143 Average Loss: 0.2277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 144/200: 100%|██████████| 2/2 [00:00<00:00, 26.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 144 Average Loss: 0.2272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 145/200: 100%|██████████| 2/2 [00:00<00:00, 25.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 145 Average Loss: 0.2263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 146/200: 100%|██████████| 2/2 [00:00<00:00, 22.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 146 Average Loss: 0.2264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 147/200: 100%|██████████| 2/2 [00:00<00:00, 25.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 147 Average Loss: 0.2267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 148/200: 100%|██████████| 2/2 [00:00<00:00, 25.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 148 Average Loss: 0.2254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 149/200: 100%|██████████| 2/2 [00:00<00:00, 25.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 149 Average Loss: 0.2255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 150/200: 100%|██████████| 2/2 [00:00<00:00, 25.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 150 Average Loss: 0.2253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 151/200: 100%|██████████| 2/2 [00:00<00:00, 25.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 151 Average Loss: 0.2241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 152/200: 100%|██████████| 2/2 [00:00<00:00, 24.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 152 Average Loss: 0.2223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 153/200: 100%|██████████| 2/2 [00:00<00:00, 25.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 153 Average Loss: 0.2232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 154/200: 100%|██████████| 2/2 [00:00<00:00, 26.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 154 Average Loss: 0.2225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 155/200: 100%|██████████| 2/2 [00:00<00:00, 25.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 155 Average Loss: 0.2230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 156/200: 100%|██████████| 2/2 [00:00<00:00, 25.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 156 Average Loss: 0.2235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 157/200: 100%|██████████| 2/2 [00:00<00:00, 24.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 157 Average Loss: 0.2194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 158/200: 100%|██████████| 2/2 [00:00<00:00, 22.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 158 Average Loss: 0.2201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 159/200: 100%|██████████| 2/2 [00:00<00:00, 25.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 159 Average Loss: 0.2204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 160/200: 100%|██████████| 2/2 [00:00<00:00, 25.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 160 Average Loss: 0.2203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 161/200: 100%|██████████| 2/2 [00:00<00:00, 25.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 161 Average Loss: 0.2190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 162/200: 100%|██████████| 2/2 [00:00<00:00, 26.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 162 Average Loss: 0.2202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 163/200: 100%|██████████| 2/2 [00:00<00:00, 26.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 163 Average Loss: 0.2181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 164/200: 100%|██████████| 2/2 [00:00<00:00, 24.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 164 Average Loss: 0.2179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 165/200: 100%|██████████| 2/2 [00:00<00:00, 25.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 165 Average Loss: 0.2171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 166/200: 100%|██████████| 2/2 [00:00<00:00, 25.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 166 Average Loss: 0.2194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 167/200: 100%|██████████| 2/2 [00:00<00:00, 24.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 167 Average Loss: 0.2177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 168/200: 100%|██████████| 2/2 [00:00<00:00, 25.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 168 Average Loss: 0.2166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 169/200: 100%|██████████| 2/2 [00:00<00:00, 26.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 169 Average Loss: 0.2162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 170/200: 100%|██████████| 2/2 [00:00<00:00, 22.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 170 Average Loss: 0.2149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 171/200: 100%|██████████| 2/2 [00:00<00:00, 25.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 171 Average Loss: 0.2159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 172/200: 100%|██████████| 2/2 [00:00<00:00, 25.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 172 Average Loss: 0.2175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 173/200: 100%|██████████| 2/2 [00:00<00:00, 25.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 173 Average Loss: 0.2165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 174/200: 100%|██████████| 2/2 [00:00<00:00, 23.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 174 Average Loss: 0.2148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 175/200: 100%|██████████| 2/2 [00:00<00:00, 24.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 175 Average Loss: 0.2136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 176/200: 100%|██████████| 2/2 [00:00<00:00, 25.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 176 Average Loss: 0.2127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 177/200: 100%|██████████| 2/2 [00:00<00:00, 25.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 177 Average Loss: 0.2122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 178/200: 100%|██████████| 2/2 [00:00<00:00, 26.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 178 Average Loss: 0.2143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 179/200: 100%|██████████| 2/2 [00:00<00:00, 25.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 179 Average Loss: 0.2137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 180/200: 100%|██████████| 2/2 [00:00<00:00, 25.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 180 Average Loss: 0.2123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 181/200: 100%|██████████| 2/2 [00:00<00:00, 26.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 181 Average Loss: 0.2088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 182/200: 100%|██████████| 2/2 [00:00<00:00, 22.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 182 Average Loss: 0.2092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 183/200: 100%|██████████| 2/2 [00:00<00:00, 26.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 183 Average Loss: 0.2083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 184/200: 100%|██████████| 2/2 [00:00<00:00, 25.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 184 Average Loss: 0.2094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 185/200: 100%|██████████| 2/2 [00:00<00:00, 26.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 185 Average Loss: 0.2077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 186/200: 100%|██████████| 2/2 [00:00<00:00, 24.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 186 Average Loss: 0.2071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 187/200: 100%|██████████| 2/2 [00:00<00:00, 26.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 187 Average Loss: 0.2085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 188/200: 100%|██████████| 2/2 [00:00<00:00, 25.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 188 Average Loss: 0.2064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 189/200: 100%|██████████| 2/2 [00:00<00:00, 25.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 189 Average Loss: 0.2045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 190/200: 100%|██████████| 2/2 [00:00<00:00, 25.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 190 Average Loss: 0.2045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 191/200: 100%|██████████| 2/2 [00:00<00:00, 25.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 191 Average Loss: 0.2050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 192/200: 100%|██████████| 2/2 [00:00<00:00, 25.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 192 Average Loss: 0.2051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 193/200: 100%|██████████| 2/2 [00:00<00:00, 25.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 193 Average Loss: 0.2055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 194/200: 100%|██████████| 2/2 [00:00<00:00, 24.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 194 Average Loss: 0.2059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 195/200: 100%|██████████| 2/2 [00:00<00:00, 21.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 195 Average Loss: 0.2035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 196/200: 100%|██████████| 2/2 [00:00<00:00, 24.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 196 Average Loss: 0.2026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 197/200: 100%|██████████| 2/2 [00:00<00:00, 26.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 197 Average Loss: 0.2015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 198/200: 100%|██████████| 2/2 [00:00<00:00, 25.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 198 Average Loss: 0.2009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 199/200: 100%|██████████| 2/2 [00:00<00:00, 26.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 199 Average Loss: 0.2008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 200/200: 100%|██████████| 2/2 [00:00<00:00, 25.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 200 Average Loss: 0.2008\n",
            "✅ Final model saved to trained_models/boundary_detector/final_model.pt\n",
            "✅ Final model logged as a W&B Artifact.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>finetune_batch_loss</td><td>█▇▆▅▅▄▅▅▄▆▅▆▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>finetune_epoch_loss</td><td>██▆▆▆▆▅▅▅▅▅▅█▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>finetune_batch_loss</td><td>0.20078</td></tr><tr><td>finetune_epoch_loss</td><td>0.20082</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">radiant-sweep-5</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/cgkgh9tl' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/cgkgh9tl</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250718_170239-cgkgh9tl/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- STAGE 2 COMPLETE ---\n",
            "\n",
            "\n",
            "--- LAUNCHING PIPELINE 3: WELL-TO-WELL INFERENCE ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'W2W_Matcher_Pipeline_Notebook' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250718_170315-cgkgh9tl</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/cgkgh9tl' target=\"_blank\">radiant-sweep-5</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/55uu3ywb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/cgkgh9tl' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/cgkgh9tl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> W&B Run started. View at: https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/cgkgh9tl\n",
            "Error: One/both wells not found: '15_9-13 Sleipner East Appr', '16/1-2  Ivar Aasen Appr'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">radiant-sweep-5</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/cgkgh9tl' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/cgkgh9tl</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250718_170315-cgkgh9tl/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- STAGE 3 COMPLETE ---\n",
            "\n",
            "\n",
            "============================================================\n",
            "✅✅✅ All Requested Pipeline Stages are Complete! ✅✅✅\n",
            "You can view all your results, models, and charts in your Weights & Biases project.\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}