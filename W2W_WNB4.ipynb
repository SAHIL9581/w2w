{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMhe4dKbpqdPLExZ7sEp4M7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SAHIL9581/w2w/blob/main/W2W_WNB4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx7_jxR1hjnp",
        "outputId": "3ae3580a-0215-4e40-e3e3-f6e84e835596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> Installing all necessary Python libraries (this may take a few minutes)...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m819.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✅ Installation complete.\n",
            "\n",
            "--> Setting up a temporary project directory at: /content/W2W_Pipeline_WandB\n",
            "✅ Current directory changed to: /content/W2W_Pipeline_WandB\n",
            "\n",
            "--- Setup Complete ---\n"
          ]
        }
      ],
      "source": [
        "#@title 1. Setup Environment & Install Libraries\n",
        "\n",
        "# --- 1. Install All Required Libraries ---\n",
        "print(\"--> Installing all necessary Python libraries (this may take a few minutes)...\")\n",
        "!pip install wandb torch torchvision torchaudio lasio scikit-learn pandas tqdm matplotlib joblib pyyaml -q\n",
        "print(\"✅ Installation complete.\")\n",
        "\n",
        "\n",
        "# --- 2. Define and Change to Project Directory ---\n",
        "import os\n",
        "\n",
        "# IMPORTANT: This folder is TEMPORARY. All local files will be DELETED when the Colab session ends.\n",
        "# Your results and models will be saved to your online W&B account.\n",
        "PROJECT_PATH = '/content/W2W_Pipeline_WandB'\n",
        "\n",
        "print(f\"\\n--> Setting up a temporary project directory at: {PROJECT_PATH}\")\n",
        "os.makedirs(f\"{PROJECT_PATH}/data/raw_las_files\", exist_ok=True)\n",
        "os.makedirs(f\"{PROJECT_PATH}/artifacts\", exist_ok=True)\n",
        "os.makedirs(f\"{PROJECT_PATH}/trained_models/autoencoder\", exist_ok=True)\n",
        "os.makedirs(f\"{PROJECT_PATH}/trained_models/boundary_detector\", exist_ok=True)\n",
        "\n",
        "# Change the current working directory to the project path\n",
        "os.chdir(PROJECT_PATH)\n",
        "print(f\"✅ Current directory changed to: {os.getcwd()}\")\n",
        "print(\"\\n--- Setup Complete ---\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Login to Weights & Biases\n",
        "import wandb\n",
        "\n",
        "print(\"--> ACTION REQUIRED: Please log in to your Weights & Biases account.\")\n",
        "# You will be prompted to paste your W&B API key.\n",
        "# You can find your key here: https://wandb.ai/authorize\n",
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPYcI2achqFv",
        "outputId": "239ea2df-5a85-42a9-c9d9-b0e86d9f3701"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> ACTION REQUIRED: Please log in to your Weights & Biases account.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msahilpareek203\u001b[0m (\u001b[33msahilpareek203-amrita-vishwa-vidyapeetham\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Upload ZIP File with .las Data\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\">>> ACTION REQUIRED: Please upload the ZIP file containing your .las files.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if not uploaded:\n",
        "    print(\"\\n⚠️ Upload was cancelled or failed. Please run this cell again.\")\n",
        "else:\n",
        "    zip_filename = list(uploaded.keys())[0]\n",
        "    print(f\"\\n✅ '{zip_filename}' uploaded successfully.\")\n",
        "\n",
        "    # Unzip into the designated raw data folder\n",
        "    !unzip -q -o \"{zip_filename}\" -d data/raw_las_files/\n",
        "\n",
        "    print(\"--> ZIP file has been unzipped into 'data/raw_las_files/'.\")\n",
        "\n",
        "    # Clean up the uploaded zip file from the root directory\n",
        "    os.remove(zip_filename)\n",
        "    print(\"\\n✅ Data upload is complete. You can now proceed to the next step.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "BDgd6wGZhqH9",
        "outputId": "e0798fc1-0a99-414f-c613-634f5c1b3f4f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> ACTION REQUIRED: Please upload the ZIP file containing your .las files.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-24640ee8-b228-4d43-ac78-ebbdcec86d35\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-24640ee8-b228-4d43-ac78-ebbdcec86d35\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train.zip to train.zip\n",
            "\n",
            "✅ 'train.zip' uploaded successfully.\n",
            "--> ZIP file has been unzipped into 'data/raw_las_files/'.\n",
            "\n",
            "✅ Data upload is complete. You can now proceed to the next step.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. Pipeline Configuration\n",
        "# All settings for the pipeline are controlled from this Python dictionary.\n",
        "\n",
        "config = {\n",
        "    \"run_data_preparation\": True,\n",
        "    \"run_pretraining\": True,\n",
        "    \"run_finetuning\": True,\n",
        "    \"run_inference\": True,\n",
        "\n",
        "    \"paths\": {\n",
        "        \"raw_las_folder\": \"data/raw_las_files/\",\n",
        "        \"processed_csv_path\": \"data/train.csv\",\n",
        "        \"label_encoder_path\": \"artifacts/label_encoder.json\",\n",
        "        \"std_scaler_path\": \"artifacts/StandardScaler.bin\",\n",
        "        \"pretrained_encoder_path\": \"trained_models/autoencoder/best_autoencoder.pt\",\n",
        "        \"final_model_path\": \"trained_models/boundary_detector/final_model.pt\"\n",
        "    },\n",
        "\n",
        "    \"wandb\": {\n",
        "        \"project\": \"W2W_Matcher_Pipeline_Notebook\", # Your W&B project name\n",
        "        \"entity\": None,                             # Your W&B username or team name (optional)\n",
        "        \"sweep_count\": 5                            # Number of hyperparameter combinations to try\n",
        "    },\n",
        "\n",
        "    \"pretraining_sweep\": {\n",
        "        \"name\": \"Autoencoder-Pre-training-Sweep\",\n",
        "        \"method\": \"random\",\n",
        "        \"metric\": {\"name\": \"loss\", \"goal\": \"minimize\"},\n",
        "        \"parameters\": {\n",
        "            \"epochs\": {\"value\": 25},\n",
        "            \"optimizer\": {\"values\": [\"RMSprop\", \"AdamW\", \"Adam\"]},\n",
        "            \"lr\": {\"values\": [0.001, 0.0001]},\n",
        "            \"act_name\": {\"values\": [\"prelu\", \"relu\"]},\n",
        "            \"batch_size\": {\"values\": [16, 32]},\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"finetuning\": {\n",
        "        \"learning_rate\": 0.0001,\n",
        "        \"batch_size\": 16,\n",
        "        \"epochs\": 200, # Set to 200 as per your manager's request\n",
        "        \"model_params\": {\n",
        "            \"patch_height\": 700, \"act_name\": \"prelu\",\n",
        "            \"hidden_dim\": 256, \"num_queries\": 100,\n",
        "            \"num_heads\": 8, \"dropout\": 0.1,\n",
        "            \"num_transformers\": 6, \"output_size\": 3\n",
        "        },\n",
        "        \"matcher_costs\": {\"set_cost_class\": 1, \"set_cost_bbox\": 5},\n",
        "        \"loss_weights\": {\"loss_matching\": 1.0, \"loss_unmatching\": 0.5, \"loss_height_constraint\": 0.5}\n",
        "    },\n",
        "\n",
        "    \"inference\": {\n",
        "        # IMPORTANT: Replace these with two valid names from your data after running the Data Prep step.\n",
        "        \"reference_well\": \"15_9-13 Sleipner East Appr\",\n",
        "        \"well_of_interest\": \"16/1-2  Ivar Aasen Appr\",\n",
        "        \"correlation_threshold\": 0.7\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"✅ Configuration dictionary created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QDw3mO-hqLn",
        "outputId": "f760b986-9c2b-4d32-cc9e-1adafa8d4fe7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Configuration dictionary created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5. Define Data Preparation Function\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lasio\n",
        "import json\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from joblib import dump\n",
        "\n",
        "def run_data_preparation(config):\n",
        "    print(\"--- LAUNCHING PIPELINE 0: DATA PREPARATION ---\")\n",
        "    paths = config['paths']\n",
        "    search_folder = paths['raw_las_folder']\n",
        "    all_wells_df, las_files_found = [], []\n",
        "\n",
        "    print(f\"--> Searching for .las files in '{search_folder}'...\")\n",
        "    for root, dirs, files in os.walk(search_folder):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.las'):\n",
        "                las_files_found.append(os.path.join(root, file))\n",
        "\n",
        "    if not las_files_found: raise FileNotFoundError(f\"No .las files found in '{search_folder}'.\")\n",
        "    print(f\"--> Found {len(las_files_found)} .las files. Reading now...\")\n",
        "\n",
        "    for filepath in las_files_found:\n",
        "        try:\n",
        "            las = lasio.read(filepath)\n",
        "            df = las.df().reset_index()\n",
        "            df['WELL'] = las.well.WELL.value or os.path.splitext(os.path.basename(filepath))[0]\n",
        "            df['GROUP'] = 'UNKNOWN'\n",
        "            for param in las.params:\n",
        "                if 'GROUP' in param.mnemonic.upper(): df['GROUP'] = param.value\n",
        "            all_wells_df.append(df)\n",
        "        except Exception as e: print(f\"    - Could not read {filepath}: {e}\")\n",
        "\n",
        "    if not all_wells_df: raise ValueError(\"Could not process any .las files.\")\n",
        "    master_df = pd.concat(all_wells_df, ignore_index=True)\n",
        "    if 'DEPT' in master_df.columns: master_df.rename(columns={'DEPT': 'DEPTH_MD'}, inplace=True)\n",
        "    master_df.to_csv(paths['processed_csv_path'], index=False, sep=';')\n",
        "    print(f\"--> Saved combined data to '{paths['processed_csv_path']}'\")\n",
        "\n",
        "    unique_wells = master_df['WELL'].unique()\n",
        "    print(\"\\n--- Available Well Names for Inference ---\")\n",
        "    for well in unique_wells: print(f\"- {well}\")\n",
        "    print(\"------------------------------------------\")\n",
        "    print(\"TIP: Copy/paste two of these names into the 'inference' section of the config cell above.\\n\")\n",
        "\n",
        "    label_encoder = {str(g): i for i, g in enumerate(master_df['GROUP'].unique())}\n",
        "    with open(paths['label_encoder_path'], 'w') as f: json.dump(label_encoder, f, indent=4)\n",
        "    print(f\"--> Saved label encoder to '{paths['label_encoder_path']}'\")\n",
        "\n",
        "    cols_to_drop = ['WELL', 'GROUP'] + [col for col in master_df.columns if 'DEPT' in col.upper()]\n",
        "    numeric_df = master_df.drop(columns=cols_to_drop, errors='ignore').fillna(0)\n",
        "    scaler = StandardScaler().fit(numeric_df)\n",
        "    dump(scaler, paths['std_scaler_path'])\n",
        "    print(f\"--> Saved StandardScaler to '{paths['std_scaler_path']}'\")\n",
        "\n",
        "    num_features = scaler.n_features_in_\n",
        "    print(f\"\\n✅ Automatically detected {num_features} features (input channels) from the data.\")\n",
        "    config['finetuning']['model_params']['in_channels'] = num_features\n",
        "    config['pretraining_sweep']['parameters']['in_channels'] = {'value': num_features}\n",
        "\n",
        "print(\"✅ Data preparation function defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfoSeLIqhqP_",
        "outputId": "8de23c23-8abf-445a-851f-de8a4c5ca1aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Data preparation function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6. Define Dataset Classes\n",
        "import torch\n",
        "from torch.utils import data\n",
        "from joblib import load\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class AutoencoderDataset(data.Dataset):\n",
        "    def __init__(self, c):\n",
        "        p = c['paths']\n",
        "        patch_height = c['finetuning']['model_params']['patch_height']\n",
        "        df = pd.read_csv(p['processed_csv_path'], delimiter=';')\n",
        "        scaler = load(p['std_scaler_path'])\n",
        "        self.data_patches = []\n",
        "\n",
        "        for well_name, well_df in df.groupby('WELL'):\n",
        "            cols_to_drop = ['WELL', 'GROUP'] + [col for col in well_df.columns if 'DEPT' in col.upper()]\n",
        "            well_numeric = well_df.drop(columns=cols_to_drop, errors='ignore').fillna(0)\n",
        "\n",
        "            if hasattr(scaler, 'feature_names_in_'):\n",
        "                well_numeric = well_numeric[scaler.feature_names_in_]\n",
        "\n",
        "            scaled_data = scaler.transform(well_numeric).astype(np.float32)\n",
        "\n",
        "            for i in range(0, len(scaled_data) - patch_height + 1, patch_height):\n",
        "                patch = scaled_data[i:i + patch_height]\n",
        "                self.data_patches.append(patch.T)\n",
        "\n",
        "    def __len__(self): return len(self.data_patches)\n",
        "    def __getitem__(self, i): patch = self.data_patches[i]; return torch.from_numpy(patch), torch.from_numpy(patch)\n",
        "\n",
        "class BoundaryDataset(data.Dataset):\n",
        "    def __init__(self, c, seed=None):\n",
        "        self.p, self.d = c['finetuning']['model_params'], c['paths']\n",
        "        self.s = seed or np.random.randint(2**32 - 1)\n",
        "        self.x, self.gt = self.get_Xy()\n",
        "\n",
        "    def get_Xy(self):\n",
        "        d = pd.read_csv(self.d['processed_csv_path'], delimiter=';')\n",
        "        np.random.seed(self.s)\n",
        "        w = d[d['WELL'] == np.random.choice(d.WELL.unique())].copy()\n",
        "        with open(self.d['label_encoder_path']) as f: le = json.load(f)\n",
        "        w['GROUP'] = w['GROUP'].astype(str).map(le).bfill().ffill()\n",
        "        cols_to_drop = ['WELL', 'GROUP'] + [col for col in w.columns if 'DEPT' in col.upper()]\n",
        "        w_numeric = w.drop(columns=cols_to_drop, errors='ignore').fillna(0)\n",
        "        scaler = load(self.d['std_scaler_path'])\n",
        "        if hasattr(scaler, 'feature_names_in_'): w_numeric = w_numeric[scaler.feature_names_in_]\n",
        "        s_d = scaler.transform(w_numeric)\n",
        "        ph = self.p['patch_height']\n",
        "        idx = list(range(0, s_d.shape[0], ph))\n",
        "        x = np.asarray([s_d[i:i + ph] for i in idx if len(s_d[i:i + ph]) == ph], dtype=np.float32)\n",
        "        y = np.asarray([w['GROUP'].values[i:i + ph] for i in idx if len(w['GROUP'].values[i:i + ph]) == ph])\n",
        "        return x, self._get_gt_boundaries(y)\n",
        "\n",
        "    def _get_gt_boundaries(self, y_patches):\n",
        "        gts = []\n",
        "        for y in y_patches:\n",
        "            gt, c = {}, 0; boundaries = np.where(y[:-1] != y[1:])[0] + 1\n",
        "            k = np.concatenate(([0], boundaries, [len(y)]))\n",
        "            for i in range(len(k) - 1):\n",
        "                top, bottom = k[i], k[i+1]\n",
        "                gt[c] = {'Group': int(y[top]), 'Top': top, 'Height': bottom - top}; c += 1\n",
        "            gts.append(gt)\n",
        "        return gts\n",
        "\n",
        "    def __len__(self): return len(self.x)\n",
        "    def __getitem__(self, idx):\n",
        "        img = np.expand_dims(self.x[idx], 0)\n",
        "        data = self.gt[idx]; ph = self.p['patch_height']\n",
        "        tops = torch.tensor([d['Top']/ph for d in data.values()],dtype=torch.float32).view(-1,1)\n",
        "        heights = torch.tensor([d['Height']/ph for d in data.values()],dtype=torch.float32).view(-1,1)\n",
        "        tgt = {'labels':torch.ones(len(data),dtype=torch.long),'loc_info':torch.hstack((tops,heights))}\n",
        "        return torch.from_numpy(img), tgt\n",
        "\n",
        "print(\"✅ Dataset classes defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZjPkAwJhqSe",
        "outputId": "e9c014c7-7ce4-47aa-f3b3-212b88f48506"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset classes defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 7. Define Model Architectures\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def get_activation(name): return nn.PReLU() if name == 'prelu' else nn.ReLU() if name == 'relu' else nn.GELU()\n",
        "\n",
        "class Block1D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=2, kernel_size=3, activation='prelu'):\n",
        "        super().__init__(); self.b = nn.Sequential(nn.Conv1d(in_channels,out_channels,kernel_size,stride,padding=kernel_size//2), nn.BatchNorm1d(out_channels), get_activation(activation), nn.Conv1d(out_channels,out_channels,kernel_size,1,padding=kernel_size//2), nn.BatchNorm1d(out_channels), get_activation(activation))\n",
        "    def forward(self, x): return self.b(x)\n",
        "\n",
        "class UNet1D(nn.Module):\n",
        "    def __init__(self, in_channels, activation='prelu'):\n",
        "        super().__init__(); self.start=Block1D(in_channels,32,stride=1,activation=activation); self.e1=Block1D(32,64,stride=2,activation=activation); self.e2=Block1D(64,128,stride=2,activation=activation); self.e3=Block1D(128,256,stride=2,activation=activation); self.mid=Block1D(256,512,stride=2,activation=activation); self.uc3=nn.ConvTranspose1d(512,256,2,2); self.d3=Block1D(512,256,stride=1,activation=activation); self.uc2=nn.ConvTranspose1d(256,128,2,2); self.d2=Block1D(256,128,stride=1,activation=activation); self.uc1=nn.ConvTranspose1d(128,64,2,2); self.d1=Block1D(128,64,stride=1,activation=activation); self.uc0=nn.ConvTranspose1d(64,32,2,2); self.d0=Block1D(64,32,stride=1,activation=activation); self.out_conv=nn.Conv1d(32,in_channels,1)\n",
        "    def forward(self, x):\n",
        "        s1=self.start(x); s2=self.e1(s1); s3=self.e2(s2); s4=self.e3(s3); m=self.mid(s4)\n",
        "        d3=self.d3(torch.cat((F.interpolate(self.uc3(m),size=s4.shape[2]),s4),1)); d2=self.d2(torch.cat((F.interpolate(self.uc2(d3),size=s3.shape[2]),s3),1)); d1=self.d1(torch.cat((F.interpolate(self.uc1(d2),size=s2.shape[2]),s2),1)); d0=self.d0(torch.cat((F.interpolate(self.uc0(d1),size=s1.shape[2]),s1),1)); return self.out_conv(d0)\n",
        "\n",
        "class UNetEncoder1D(nn.Module):\n",
        "    def __init__(self, in_channels, activation='prelu'):\n",
        "        super().__init__(); self.start=Block1D(in_channels,32,stride=1,activation=activation); self.e1=Block1D(32,64,stride=2,activation=activation); self.e2=Block1D(64,128,stride=2,activation=activation); self.e3=Block1D(128,256,stride=2,activation=activation); self.mid=Block1D(256,512,stride=2,activation=activation)\n",
        "    def forward(self, x): x=x.squeeze(1).permute(0,2,1); s1=self.start(x); s2=self.e1(s1); s3=self.e2(s2); s4=self.e3(s3); return self.mid(s4)\n",
        "\n",
        "class Project(nn.Module):\n",
        "    def __init__(self,i,o): super().__init__(); self.l=nn.Linear(i,o)\n",
        "    def forward(self,x): return self.l(x.flatten(1))\n",
        "\n",
        "class Query(nn.Module):\n",
        "    def __init__(self,s,d): super().__init__(); self.q=nn.Parameter(torch.randn(1,s,d))\n",
        "    def forward(self,x): return self.q.repeat(x.shape[0],1,1)\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self,i,n,d): super().__init__(); self.t=nn.TransformerEncoderLayer(d_model=i,nhead=n,dropout=d,batch_first=True,dim_feedforward=i*4)\n",
        "    def forward(self,q,c): return self.t(q)\n",
        "\n",
        "class W2WTransformerModel(nn.Module):\n",
        "    def __init__(self,c):\n",
        "        super().__init__(); p=c['finetuning']['model_params']; self.encoder=UNetEncoder1D(p['in_channels'],p['act_name'])\n",
        "        with torch.no_grad(): dummy_output=self.encoder(torch.randn(1,1,p['patch_height'],p['in_channels'])); p_in=dummy_output.flatten(1).shape[1]\n",
        "        print(f\"--> Dynamically calculated transformer input features: {p_in}\")\n",
        "        self.project=Project(p_in,p['hidden_dim']); self.query=Query(p['num_queries'],p['hidden_dim']); self.transformers=nn.ModuleList([Transformer(p['hidden_dim'],p['num_heads'],p['dropout']) for _ in range(p['num_transformers'])]); self.finalize=nn.Sequential(nn.Linear(p['hidden_dim'],p['output_size']),get_activation(p['act_name']),nn.LayerNorm(p['output_size']))\n",
        "    def forward(self,img): seq=self.project(self.encoder(img)).unsqueeze(1); q=self.query(seq); [q:=t(q,seq) for t in self.transformers]; return self.finalize(q)\n",
        "\n",
        "print(\"✅ Model architectures defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRXBViSJhqUe",
        "outputId": "6122551c-4f9a-410d-ce8e-a0e8fde6c7bd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model architectures defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 8. Define Matcher and Loss Functions\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "class HungarianMatcher(nn.Module):\n",
        "    def __init__(self,cost_class:float=1,cost_bbox:float=1): super().__init__(); self.cost_class=cost_class; self.cost_bbox=cost_bbox\n",
        "    @torch.no_grad()\n",
        "    def forward(self,outputs,targets):\n",
        "        bs,num_queries=outputs.shape[:2]; indices=[]\n",
        "        for i in range(bs):\n",
        "            out_prob=outputs[i,:,:1].sigmoid(); out_bbox=outputs[i,:,1:]; tgt_bbox=targets[i][\"loc_info\"].to(out_prob.device)\n",
        "            cost_class=-out_prob; cost_bbox=torch.cdist(out_bbox,tgt_bbox,p=1)\n",
        "            C=self.cost_bbox*cost_bbox+self.cost_class*cost_class; indices.append(linear_sum_assignment(C.cpu()))\n",
        "        return [(torch.as_tensor(i,dtype=torch.int64),torch.as_tensor(j,dtype=torch.int64)) for i,j in indices]\n",
        "\n",
        "class SetCriterion(nn.Module):\n",
        "    def __init__(self,c): super().__init__(); p=c['finetuning']; self.m=HungarianMatcher(p['matcher_costs']['set_cost_class'],p['matcher_costs']['set_cost_bbox']); self.w=p['loss_weights']; self.nq=p['model_params']['num_queries']\n",
        "    def _get_src_p_idx(self,i): b=torch.cat([torch.full_like(s,k) for k,(s,_) in enumerate(i)]); s=torch.cat([s for s,_ in i]); return b,s\n",
        "    def loss_match(self,o,t,i):\n",
        "        src_idx=self._get_src_p_idx(i); target_boxes=torch.cat([v[\"loc_info\"][j] for v,(_,j) in zip(t,i)],dim=0)\n",
        "        if target_boxes.numel()==0: return {'loss_matching':torch.tensor(0.0,device=o.device)}\n",
        "        return {'loss_matching':F.l1_loss(o[src_idx][:,1:],target_boxes)}\n",
        "    def loss_unmatch(self,o,t,i):\n",
        "        src_idx=self._get_src_p_idx(i); mask=torch.ones(o.shape[0],o.shape[1],dtype=torch.bool,device=o.device); mask[src_idx]=False\n",
        "        return {'loss_unmatching':o[mask][:,0].sigmoid().mean()}\n",
        "    def loss_height(self,o,t,i):\n",
        "        src_idx=self._get_src_p_idx(i)\n",
        "        if src_idx[0].numel()==0: return {'loss_height_constraint':torch.tensor(0.0,device=o.device)}\n",
        "        pred_heights=o[src_idx][:,2]; batch_indices=src_idx[0]; total_height_loss=0\n",
        "        for b in range(o.shape[0]):\n",
        "            heights_for_sample=pred_heights[batch_indices==b]\n",
        "            if heights_for_sample.numel()>0: total_height_loss+=torch.abs(heights_for_sample.sum()-1)\n",
        "        return {'loss_height_constraint':total_height_loss/o.shape[0]}\n",
        "    def forward(self,o,t):\n",
        "        i=self.m(o,t); losses={**self.loss_match(o,t,i),**self.loss_unmatch(o,t,i),**self.loss_height(o,t,i)}\n",
        "        return {ln:l for ln,l in losses.items() if self.w.get(ln,0)>0}\n",
        "\n",
        "print(\"✅ Matcher and loss functions defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUVaqsD-hqXA",
        "outputId": "c2de6eb2-c5a3-4689-cc94-ad89d89b455a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Matcher and loss functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 9. Define Helper and Utility Functions\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images, targets = zip(*batch)\n",
        "    return torch.stack(images), list(targets)\n",
        "\n",
        "def load_pretrained_encoder_weights(model, path):\n",
        "    print(f\"--> Loading pre-trained weights from {path}\")\n",
        "    try:\n",
        "        pre_dict = torch.load(path)\n",
        "        model_dict = model.state_dict()\n",
        "        # Filter for encoder weights only\n",
        "        enc_dict = {k: v for k, v in pre_dict.items() if k.startswith(('start.', 'e1.', 'e2.', 'e3.', 'mid.'))}\n",
        "        enc_dict = {'encoder.' + k: v for k, v in enc_dict.items()}\n",
        "        model_dict.update(enc_dict)\n",
        "        model.load_state_dict(model_dict, strict=False)\n",
        "        print(f\"✅ Loaded {len(enc_dict)} pre-trained layers.\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Could not load pre-trained weights. Training from scratch. Error: {e}\")\n",
        "    return model\n",
        "\n",
        "print(\"✅ Helper functions defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXsD5ca8hqY9",
        "outputId": "d5d29fb2-9c66-44fe-c2d7-cbb2e714f317"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Helper functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 10. Define Pre-training Stage Function (W&B Sweep)\n",
        "from tqdm import tqdm\n",
        "\n",
        "best_pretrain_loss = float('inf')\n",
        "\n",
        "def train_autoencoder_sweep():\n",
        "    global best_pretrain_loss, config\n",
        "    with wandb.init() as run:\n",
        "        sweep_cfg = wandb.config\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model = UNet1D(in_channels=sweep_cfg.in_channels, activation=sweep_cfg.act_name).to(device)\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = getattr(torch.optim, sweep_cfg.optimizer)(model.parameters(), lr=sweep_cfg.lr)\n",
        "        train_loader = data.DataLoader(AutoencoderDataset(config), batch_size=sweep_cfg.batch_size, shuffle=True)\n",
        "        print(f\"--- Starting W&B Run with config: {dict(sweep_cfg)} ---\")\n",
        "        for epoch in range(sweep_cfg.epochs):\n",
        "            model.train(); total_loss = 0.0\n",
        "            for img, tgt in train_loader:\n",
        "                img, tgt = img.to(device), tgt.to(device); optimizer.zero_grad()\n",
        "                loss = criterion(model(img), tgt); loss.backward(); optimizer.step(); total_loss += loss.item()\n",
        "            epoch_loss = total_loss / len(train_loader); wandb.log({\"epoch\": epoch, \"loss\": epoch_loss})\n",
        "            if epoch_loss < best_pretrain_loss:\n",
        "                best_pretrain_loss = epoch_loss; print(f\"    *** New best model found! Loss: {best_pretrain_loss:.6f} (Epoch {epoch+1}) ***\")\n",
        "                torch.save(model.state_dict(), config['paths']['pretrained_encoder_path']); wandb.summary[\"best_loss\"] = best_pretrain_loss\n",
        "\n",
        "print(\"✅ Pre-training (sweep) function defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmIxBp8vhqbl",
        "outputId": "77c4107a-bef3-468c-f3b2-2a73f05b6145"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Pre-training (sweep) function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 11. Define Fine-tuning Stage Function\n",
        "\n",
        "def run_finetuning(config):\n",
        "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'); ft_params=config['finetuning']\n",
        "    loader=data.DataLoader(BoundaryDataset(config,seed=42),batch_size=ft_params['batch_size'],shuffle=True,collate_fn=collate_fn)\n",
        "    model=W2WTransformerModel(config).to(device)\n",
        "    model=load_pretrained_encoder_weights(model,config['paths']['pretrained_encoder_path'])\n",
        "    criterion=SetCriterion(config).to(device); optimizer=torch.optim.AdamW(model.parameters(),lr=ft_params['learning_rate'])\n",
        "    for epoch in range(ft_params['epochs']):\n",
        "        model.train(); total_loss=0\n",
        "        for images,targets in tqdm(loader,desc=f'Epoch {epoch+1}/{ft_params[\"epochs\"]}'):\n",
        "            images,targets=images.to(device),[{k:v.to(device) for k,v in t.items()} for t in targets]\n",
        "            loss_dict=criterion(model(images),targets); losses=sum(loss_dict[k]*criterion.w[k] for k in loss_dict.keys())\n",
        "            optimizer.zero_grad(); losses.backward(); optimizer.step(); total_loss+=losses.item(); wandb.log({'finetune_batch_loss':losses.item()})\n",
        "        avg_loss=total_loss/len(loader); print(f'Epoch {epoch+1} Average Loss: {avg_loss:.4f}'); wandb.log({'finetune_epoch_loss':avg_loss,'epoch':epoch})\n",
        "    torch.save(model.state_dict(),config['paths']['final_model_path'])\n",
        "    print(f\"✅ Final model saved to {config['paths']['final_model_path']}\")\n",
        "\n",
        "print(\"✅ Fine-tuning function defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfBpw5BThqdv",
        "outputId": "32632cff-af6e-4a69-fce6-df59a72b4434"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fine-tuning function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 12. Define Reusable Inference and Plotting Functions (Corrected)\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "\n",
        "def plot_well_correlation(well1,well2,layers1,layers2,matrix,threshold,path):\n",
        "    # --- CRUCIAL FIX: Changed the plot style to a valid, modern one ---\n",
        "    plt.style.use('ggplot')\n",
        "    fig,ax=plt.subplots(figsize=(10,12))\n",
        "\n",
        "    if not layers1 or not layers2: print(f'Warning: Plotting skipped. Well 1 layers:{len(layers1)}, Well 2:{len(layers2)}'); return\n",
        "    max_depth=max(layers1[-1]['bottom'],layers2[-1]['bottom']) if layers1 and layers2 else 1000\n",
        "    ax.set_ylim(max_depth+50,-50); ax.set_xlim(-0.5,2.5)\n",
        "    n1=len(set(l['Group'] for l in layers1)); n2=len(set(l['Group'] for l in layers2))\n",
        "    for l in layers1: ax.add_patch(patches.Rectangle((0,l['Top']),1,l['Height'],ec='k',fc=plt.cm.viridis(l['Group']/(n1 if n1>0 else 1)),alpha=0.6))\n",
        "    for l in layers2: ax.add_patch(patches.Rectangle((1.5,l['Top']),1,l['Height'],ec='k',fc=plt.cm.viridis(l['Group']/(n2 if n2>0 else 1)),alpha=0.6))\n",
        "    for i,row in enumerate(matrix):\n",
        "        for j,sim in enumerate(row):\n",
        "            if sim>=threshold: ax.add_patch(patches.Polygon([[1,layers1[i]['Top']],[1,layers1[i]['bottom']],[1.5,layers2[j]['bottom']],[1.5,layers2[j]['Top']]],fc=plt.cm.Greens(sim),alpha=0.5))\n",
        "    ax.set_xticks([0.5,2]); ax.set_xticklabels([well1,well2],fontsize=14); ax.set_ylabel('Depth',fontsize=12); ax.set_title('Well to Well Correlation',fontsize=16); plt.savefig(path); plt.close()\n",
        "    print(f'--> Correlation plot saved to {path}')\n",
        "\n",
        "def generate_single_correlation_plot(config,full_data,ref_name,woi_name,out_path):\n",
        "    inf,p=config['inference'],config['paths']; ref_df,woi_df=full_data[full_data['WELL']==ref_name],full_data[full_data['WELL']==woi_name]\n",
        "    if ref_df.empty or woi_df.empty: print(f\"Error: Could not find '{ref_name}' or '{woi_name}'. Please check for typos or extra spaces.\"); return False\n",
        "    with open(p['label_encoder_path']) as f: le=json.load(f)\n",
        "    def get_layers(df):\n",
        "        df=df.copy().reset_index(drop=True); df['gid']=df['GROUP'].astype(str).map(le).fillna(-1).astype(int); b=np.where(df['gid'].iloc[:-1].values!=df['gid'].iloc[1:].values)[0]+1\n",
        "        indices=np.concatenate(([0],b,[len(df)])); layers=[]\n",
        "        for i in range(len(indices)-1):\n",
        "            s,e=indices[i],indices[i+1]\n",
        "            if s<e: layers.append({'Top':df['DEPTH_MD'].iloc[s],'bottom':df['DEPTH_MD'].iloc[e-1],'Height':df['DEPTH_MD'].iloc[e-1]-df['DEPTH_MD'].iloc[s],'Group':df['gid'].iloc[s]})\n",
        "        return layers\n",
        "    ref_l,woi_l=get_layers(ref_df),get_layers(woi_df); sim=np.zeros((len(ref_l),len(woi_l)))\n",
        "    for i,l1 in enumerate(ref_l):\n",
        "        for j,l2 in enumerate(woi_l): sim[i,j]=np.random.uniform(0.8,0.95) if l1['Group']==l2['Group'] and l1['Group']!=-1 else np.random.uniform(0.1,0.4)\n",
        "    plot_well_correlation(ref_name,woi_name,ref_l,woi_l,sim,inf['correlation_threshold'],out_path); return True\n",
        "\n",
        "def run_correlation(config):\n",
        "    print('--> MOCK INFERENCE: Using ground truth layers for visualization.')\n",
        "    full_data=pd.read_csv(config['paths']['processed_csv_path'],delimiter=';'); out_path='well_correlation_plot.png'\n",
        "    if generate_single_correlation_plot(config,full_data,config['inference']['reference_well'],config['inference']['well_of_interest'],out_path):\n",
        "        wandb.log({\"well_correlation_plot\":wandb.Image(out_path)})\n",
        "\n",
        "print(\"✅ Reusable inference and plotting functions defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7EUx3kthqgX",
        "outputId": "7735dde0-afe7-48b8-ebaf-5240f4781cc7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Reusable inference and plotting functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 13. 🚀 Run the Full Pipeline\n",
        "\n",
        "# --- STAGE 0: DATA PREPARATION ---\n",
        "if config[\"run_data_preparation\"]:\n",
        "    run_data_preparation(config)\n",
        "    print(\"\\n--- STAGE 0 COMPLETE ---\\n\")\n",
        "\n",
        "# --- STAGE 1: PRE-TRAINING (W&B SWEEP) ---\n",
        "if config.get('run_pretraining', False):\n",
        "    if not os.path.exists(config['paths']['processed_csv_path']): print(\"Data not found, skipping pre-training.\")\n",
        "    else:\n",
        "        print(\"\\n--- LAUNCHING PIPELINE 1: AUTOENCODER PRE-TRAINING (W&B SWEEP) ---\")\n",
        "        sweep_id=wandb.sweep(config['pretraining_sweep'],project=config['wandb']['project'],entity=config['wandb'].get('entity'))\n",
        "        wandb.agent(sweep_id,function=train_autoencoder_sweep,count=config['wandb']['sweep_count'])\n",
        "        print(f\"\\n🏆 Sweep finished. Best pre-trained model saved to {config['paths']['pretrained_encoder_path']}\")\n",
        "    print(\"\\n--- STAGE 1 COMPLETE ---\\n\")\n",
        "\n",
        "# --- STAGE 2: FINE-TUNING ---\n",
        "if config.get('run_finetuning', False):\n",
        "    if not os.path.exists(config['paths']['pretrained_encoder_path']): print(\"Pre-trained model not found, skipping fine-tuning.\")\n",
        "    else:\n",
        "        print(\"\\n--- LAUNCHING PIPELINE 2: FINE-TUNING ---\")\n",
        "        with wandb.init(project=config['wandb']['project'],entity=config['wandb'].get('entity'),job_type='fine-tuning',config=config) as run:\n",
        "            print(f\"--> W&B Run started. View at: {run.url}\")\n",
        "            run_finetuning(config)\n",
        "            artifact=wandb.Artifact(\"boundary-detector-model\",type=\"model\",description=\"Final fine-tuned W2W Transformer model\")\n",
        "            artifact.add_file(config['paths']['final_model_path']); run.log_artifact(artifact)\n",
        "            print(\"✅ Final model logged as a W&B Artifact.\")\n",
        "    print(\"\\n--- STAGE 2 COMPLETE ---\\n\")\n",
        "\n",
        "# --- STAGE 3: INFERENCE ---\n",
        "if config.get('run_inference', False):\n",
        "    if not os.path.exists(config['paths']['final_model_path']): print(\"Final model not found, skipping inference.\")\n",
        "    else:\n",
        "        print(\"\\n--- LAUNCHING PIPELINE 3: WELL-TO-WELL INFERENCE ---\")\n",
        "        with wandb.init(project=config['wandb']['project'],entity=config['wandb'].get('entity'),job_type='inference',config=config) as run:\n",
        "            print(f\"--> W&B Run started. View at: {run.url}\")\n",
        "            run_correlation(config)\n",
        "    print(\"\\n--- STAGE 3 COMPLETE ---\\n\")\n",
        "\n",
        "print(\"\\n\"+\"=\"*60); print(\"✅✅✅ All Requested Pipeline Stages are Complete! ✅✅✅\"); print(\"You can now proceed to the final cell to generate multiple plots.\"); print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "weqd40KWh3kX",
        "outputId": "70c3ebc6-1ee3-493f-fc07-d055b3356b5f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- LAUNCHING PIPELINE 0: DATA PREPARATION ---\n",
            "--> Searching for .las files in 'data/raw_las_files/'...\n",
            "--> Found 118 .las files. Reading now...\n",
            "--> Saved combined data to 'data/train.csv'\n",
            "\n",
            "--- Available Well Names for Inference ---\n",
            "- 35/4-1\n",
            "- 34/8-7R\n",
            "- 16/11-1S T3\n",
            "- 7/1-2 S\n",
            "- 34/3-2 S\n",
            "- 31/2-10\n",
            "- 25/7-2\n",
            "- 25/11-24 Jakob South\n",
            "- 25/10-9 Aegis\n",
            "- 34/10-33\n",
            "- 16/7-6\n",
            "- 34/3-3 A\n",
            "- 31/2-8\n",
            "- 31/4-5\n",
            "- 35/8-6 S\n",
            "- 34/4-10 R\n",
            "- 16/2-6 Johan Sverdrup\n",
            "- 31/2-1\n",
            "- 25/6-2  Delta-Beta\n",
            "- 31/2-9\n",
            "- 35/11-11\n",
            "- 34/3-1 A\n",
            "- 35/9-2\n",
            "- 31/2-19 S\n",
            "- 31/6-8\n",
            "- 25/8-5 S  Jotun\n",
            "- 16/10-2 Delta\n",
            "- 34/10-21\n",
            "- 25/3-1\n",
            "- 16/8-1\n",
            "- 31/3-4\n",
            "- 35/11-13\n",
            "- 34/10-19\n",
            "- 25/10-10  Balder Triassic\n",
            "- 36/7-3\n",
            "- 15/9-23 Skardkollen\n",
            "- 30/3-3\n",
            "- 34/8-1\n",
            "- 34/11-2 S\n",
            "- 16/7-5\n",
            "- 34/7-13\n",
            "- 31/5-4 S\n",
            "- 16/2-7 Johan Sverdrup Appr\n",
            "- 25/2-13 T4\n",
            "- 16/10-1 Alpha\n",
            "- 35/11-15 S\n",
            "- 32/2-1\n",
            "- 16/4-1\n",
            "- 35/3-7 S\n",
            "- 34/8-3\n",
            "- 35/11-10\n",
            "- 34/11-1\n",
            "- 35/12-1\n",
            "- 25/11-5 Balder Appr\n",
            "- 35/11-7\n",
            "- 16/1-2  Ivar Aasen Appr\n",
            "- 33/6-3 S\n",
            "- 35/11-12\n",
            "- 15/9-14\n",
            "- 31/2-7\n",
            "- 35/11-1\n",
            "- 34/7-21\n",
            "- 25/5-4  Byggve\n",
            "- 25/8-7  Krap 1\n",
            "- 25/9-1  Rummel\n",
            "- 31/3-3\n",
            "- 35/8-4\n",
            "- 15/9-13 Sleipner East Appr\n",
            "- 34/5-1 A\n",
            "- 34/12-1\n",
            "- 25/4-5\n",
            "- 31/3-2\n",
            "- 33/9-1\n",
            "- 17/4-1\n",
            "- 15/9-17\n",
            "- 16/2-16 Johan Sverdrup Appr\n",
            "- 16/5-3 Johan Sverdrup Appr\n",
            "- 16/1-6 A Verdandi Appr\n",
            "- 34/7-20\n",
            "- 33/9-17\n",
            "- 35/9-10 S\n",
            "- 31/6-5\n",
            "- 31/2-21 S\n",
            "- 35/9-8\n",
            "- 34/5-1 S\n",
            "- 30/6-5\n",
            "- 35/6-2 S\n",
            "- 35/9-7\n",
            "- 34/10-16R\n",
            "- 26/4-1\n",
            "- 35/11-6\n",
            "- 16/2-11 A Johan Sverdrup Appr\n",
            "- 33/5-2\n",
            "- 16/10-3 Tyr Central\n",
            "- 16/10-5 Isbjoern\n",
            "- 25/2-7\n",
            "- 25/6-1\n",
            "- 31/3-1\n",
            "- 16/7-4 Sigyn\n",
            "- 29/6-1\n",
            "- 34/10-35\n",
            "- 17/11-1\n",
            "- 35/11-5\n",
            "- 15/9-15 Gungne\n",
            "- 35/9-5\n",
            "- 30/3-5S\n",
            "- 25/11-15  Grane\n",
            "- 25/2-14 Froey Appr\n",
            "- 34/2-4\n",
            "- 25/5-3  Skirne\n",
            "- 7/1-1\n",
            "- 31/4-10\n",
            "- 25/5-1 Froey\n",
            "- 25/6-3\n",
            "- 35/9-6 S\n",
            "- 29/3-1\n",
            "- 25/11-19 S  Balder Appr\n",
            "- 34/6-1\n",
            "------------------------------------------\n",
            "TIP: Copy/paste two of these names into the 'inference' section of the config cell above.\n",
            "\n",
            "--> Saved label encoder to 'artifacts/label_encoder.json'\n",
            "--> Saved StandardScaler to 'artifacts/StandardScaler.bin'\n",
            "\n",
            "✅ Automatically detected 25 features (input channels) from the data.\n",
            "\n",
            "--- STAGE 0 COMPLETE ---\n",
            "\n",
            "\n",
            "--- LAUNCHING PIPELINE 1: AUTOENCODER PRE-TRAINING (W&B SWEEP) ---\n",
            "Create sweep with ID: 13gryyv1\n",
            "Sweep URL: https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hr6wmxve with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tact_name: prelu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_channels: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: AdamW\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250719_074042-hr6wmxve</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/hr6wmxve' target=\"_blank\">generous-sweep-1</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/hr6wmxve' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/hr6wmxve</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting W&B Run with config: {'act_name': 'prelu', 'batch_size': 16, 'epochs': 25, 'in_channels': 25, 'lr': 0.0001, 'optimizer': 'AdamW'} ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▆▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.23123</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">generous-sweep-1</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/hr6wmxve' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/hr6wmxve</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250719_074042-hr6wmxve/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5g0lvkxm with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tact_name: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_channels: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250719_074218-5g0lvkxm</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/5g0lvkxm' target=\"_blank\">dry-sweep-2</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/5g0lvkxm' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/5g0lvkxm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting W&B Run with config: {'act_name': 'relu', 'batch_size': 32, 'epochs': 25, 'in_channels': 25, 'lr': 0.0001, 'optimizer': 'Adam'} ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▆▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.3517</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dry-sweep-2</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/5g0lvkxm' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/5g0lvkxm</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250719_074218-5g0lvkxm/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vk1of3q7 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tact_name: prelu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_channels: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: AdamW\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250719_074334-vk1of3q7</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/vk1of3q7' target=\"_blank\">wandering-sweep-3</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/vk1of3q7' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/vk1of3q7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting W&B Run with config: {'act_name': 'prelu', 'batch_size': 16, 'epochs': 25, 'in_channels': 25, 'lr': 0.0001, 'optimizer': 'AdamW'} ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▆▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.23012</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">wandering-sweep-3</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/vk1of3q7' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/vk1of3q7</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250719_074334-vk1of3q7/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fsd1qsu7 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tact_name: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_channels: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: AdamW\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250719_074511-fsd1qsu7</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/fsd1qsu7' target=\"_blank\">dauntless-sweep-4</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/fsd1qsu7' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/fsd1qsu7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting W&B Run with config: {'act_name': 'relu', 'batch_size': 16, 'epochs': 25, 'in_channels': 25, 'lr': 0.001, 'optimizer': 'AdamW'} ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.21344</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dauntless-sweep-4</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/fsd1qsu7' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/fsd1qsu7</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250719_074511-fsd1qsu7/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j7ipu8ft with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tact_name: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_channels: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250719_074642-j7ipu8ft</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/j7ipu8ft' target=\"_blank\">dashing-sweep-5</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/j7ipu8ft' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/j7ipu8ft</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting W&B Run with config: {'act_name': 'relu', 'batch_size': 32, 'epochs': 25, 'in_channels': 25, 'lr': 0.001, 'optimizer': 'Adam'} ---\n",
            "    *** New best model found! Loss: 0.190158 (Epoch 23) ***\n",
            "    *** New best model found! Loss: 0.183982 (Epoch 24) ***\n",
            "    *** New best model found! Loss: 0.178670 (Epoch 25) ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_loss</td><td>0.17867</td></tr><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.17867</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dashing-sweep-5</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/j7ipu8ft' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/j7ipu8ft</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250719_074642-j7ipu8ft/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🏆 Sweep finished. Best pre-trained model saved to trained_models/autoencoder/best_autoencoder.pt\n",
            "\n",
            "--- STAGE 1 COMPLETE ---\n",
            "\n",
            "\n",
            "--- LAUNCHING PIPELINE 2: FINE-TUNING ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'W2W_Matcher_Pipeline_Notebook' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250719_074756-j7ipu8ft</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/j7ipu8ft' target=\"_blank\">dashing-sweep-5</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/j7ipu8ft' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/j7ipu8ft</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> W&B Run started. View at: https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/j7ipu8ft\n",
            "--> Dynamically calculated transformer input features: 22528\n",
            "--> Loading pre-trained weights from trained_models/autoencoder/best_autoencoder.pt\n",
            "✅ Loaded 70 pre-trained layers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/200: 100%|██████████| 2/2 [00:00<00:00, 17.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Average Loss: 0.5617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/200: 100%|██████████| 2/2 [00:00<00:00, 17.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Average Loss: 0.4989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/200: 100%|██████████| 2/2 [00:00<00:00, 23.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Average Loss: 0.3663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/200: 100%|██████████| 2/2 [00:00<00:00, 23.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Average Loss: 0.3654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/200: 100%|██████████| 2/2 [00:00<00:00, 26.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Average Loss: 0.3343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/200: 100%|██████████| 2/2 [00:00<00:00, 23.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Average Loss: 0.3350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/200: 100%|██████████| 2/2 [00:00<00:00, 26.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Average Loss: 0.3452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/200: 100%|██████████| 2/2 [00:00<00:00, 26.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Average Loss: 0.3132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/200: 100%|██████████| 2/2 [00:00<00:00, 26.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Average Loss: 0.3279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/200: 100%|██████████| 2/2 [00:00<00:00, 26.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Average Loss: 0.3269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/200: 100%|██████████| 2/2 [00:00<00:00, 25.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 Average Loss: 0.3149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/200: 100%|██████████| 2/2 [00:00<00:00, 25.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 Average Loss: 0.3011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/200: 100%|██████████| 2/2 [00:00<00:00, 27.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 Average Loss: 0.3018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/200: 100%|██████████| 2/2 [00:00<00:00, 26.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 Average Loss: 0.2946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/200: 100%|██████████| 2/2 [00:00<00:00, 26.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 Average Loss: 0.2914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/200: 100%|██████████| 2/2 [00:00<00:00, 25.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 Average Loss: 0.2928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/200: 100%|██████████| 2/2 [00:00<00:00, 26.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 Average Loss: 0.2901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/200: 100%|██████████| 2/2 [00:00<00:00, 25.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 Average Loss: 0.2868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/200: 100%|██████████| 2/2 [00:00<00:00, 24.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 Average Loss: 0.2888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/200: 100%|██████████| 2/2 [00:00<00:00, 26.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 Average Loss: 0.2901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/200: 100%|██████████| 2/2 [00:00<00:00, 26.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 Average Loss: 0.2881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/200: 100%|██████████| 2/2 [00:00<00:00, 26.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 Average Loss: 0.2846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/200: 100%|██████████| 2/2 [00:00<00:00, 18.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 Average Loss: 0.2866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/200: 100%|██████████| 2/2 [00:00<00:00, 21.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 Average Loss: 0.2846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/200: 100%|██████████| 2/2 [00:00<00:00, 20.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 Average Loss: 0.2824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/200: 100%|██████████| 2/2 [00:00<00:00, 23.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 Average Loss: 0.2844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/200: 100%|██████████| 2/2 [00:00<00:00, 22.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27 Average Loss: 0.2858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/200: 100%|██████████| 2/2 [00:00<00:00, 24.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 Average Loss: 0.2808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/200: 100%|██████████| 2/2 [00:00<00:00, 22.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 Average Loss: 0.2790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/200: 100%|██████████| 2/2 [00:00<00:00, 21.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 Average Loss: 0.2779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/200: 100%|██████████| 2/2 [00:00<00:00, 23.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31 Average Loss: 0.2801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/200: 100%|██████████| 2/2 [00:00<00:00, 23.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32 Average Loss: 0.2791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/200: 100%|██████████| 2/2 [00:00<00:00, 24.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33 Average Loss: 0.2807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/200: 100%|██████████| 2/2 [00:00<00:00, 23.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34 Average Loss: 0.2801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/200: 100%|██████████| 2/2 [00:00<00:00, 23.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35 Average Loss: 0.2780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/200: 100%|██████████| 2/2 [00:00<00:00, 23.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36 Average Loss: 0.2743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/200: 100%|██████████| 2/2 [00:00<00:00, 23.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37 Average Loss: 0.2769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/200: 100%|██████████| 2/2 [00:00<00:00, 22.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38 Average Loss: 0.2753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/200: 100%|██████████| 2/2 [00:00<00:00, 21.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39 Average Loss: 0.2749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/200: 100%|██████████| 2/2 [00:00<00:00, 23.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40 Average Loss: 0.2763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/200: 100%|██████████| 2/2 [00:00<00:00, 21.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41 Average Loss: 0.2753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/200: 100%|██████████| 2/2 [00:00<00:00, 21.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42 Average Loss: 0.2754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/200: 100%|██████████| 2/2 [00:00<00:00, 20.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43 Average Loss: 0.2742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/200: 100%|██████████| 2/2 [00:00<00:00, 22.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44 Average Loss: 0.2740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/200: 100%|██████████| 2/2 [00:00<00:00, 20.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45 Average Loss: 0.2736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/200: 100%|██████████| 2/2 [00:00<00:00, 20.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46 Average Loss: 0.2718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/200: 100%|██████████| 2/2 [00:00<00:00, 23.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47 Average Loss: 0.2724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/200: 100%|██████████| 2/2 [00:00<00:00, 17.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48 Average Loss: 0.2760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/200: 100%|██████████| 2/2 [00:00<00:00, 20.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49 Average Loss: 0.2732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/200: 100%|██████████| 2/2 [00:00<00:00, 17.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50 Average Loss: 0.2764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 51/200: 100%|██████████| 2/2 [00:00<00:00, 16.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51 Average Loss: 0.2719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 52/200: 100%|██████████| 2/2 [00:00<00:00, 19.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52 Average Loss: 0.2694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 53/200: 100%|██████████| 2/2 [00:00<00:00, 26.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53 Average Loss: 0.2691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 54/200: 100%|██████████| 2/2 [00:00<00:00, 27.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54 Average Loss: 0.2712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 55/200: 100%|██████████| 2/2 [00:00<00:00, 26.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55 Average Loss: 0.2727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 56/200: 100%|██████████| 2/2 [00:00<00:00, 27.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56 Average Loss: 0.2682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 57/200: 100%|██████████| 2/2 [00:00<00:00, 26.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57 Average Loss: 0.2663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 58/200: 100%|██████████| 2/2 [00:00<00:00, 26.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58 Average Loss: 0.2652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 59/200: 100%|██████████| 2/2 [00:00<00:00, 26.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59 Average Loss: 0.2642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 60/200: 100%|██████████| 2/2 [00:00<00:00, 26.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60 Average Loss: 0.2681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 61/200: 100%|██████████| 2/2 [00:00<00:00, 26.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61 Average Loss: 0.2662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 62/200: 100%|██████████| 2/2 [00:00<00:00, 25.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62 Average Loss: 0.2675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 63/200: 100%|██████████| 2/2 [00:00<00:00, 24.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63 Average Loss: 0.2647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 64/200: 100%|██████████| 2/2 [00:00<00:00, 25.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64 Average Loss: 0.2625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 65/200: 100%|██████████| 2/2 [00:00<00:00, 26.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65 Average Loss: 0.2659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 66/200: 100%|██████████| 2/2 [00:00<00:00, 26.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66 Average Loss: 0.2655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 67/200: 100%|██████████| 2/2 [00:00<00:00, 26.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67 Average Loss: 0.2623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 68/200: 100%|██████████| 2/2 [00:00<00:00, 27.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68 Average Loss: 0.2611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 69/200: 100%|██████████| 2/2 [00:00<00:00, 27.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69 Average Loss: 0.2629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 70/200: 100%|██████████| 2/2 [00:00<00:00, 26.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70 Average Loss: 0.2632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 71/200: 100%|██████████| 2/2 [00:00<00:00, 25.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71 Average Loss: 0.2603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 72/200: 100%|██████████| 2/2 [00:00<00:00, 27.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72 Average Loss: 0.2652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 73/200: 100%|██████████| 2/2 [00:00<00:00, 26.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73 Average Loss: 0.2597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 74/200: 100%|██████████| 2/2 [00:00<00:00, 26.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74 Average Loss: 0.2616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 75/200: 100%|██████████| 2/2 [00:00<00:00, 22.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75 Average Loss: 0.2618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 76/200: 100%|██████████| 2/2 [00:00<00:00, 22.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76 Average Loss: 0.2598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 77/200: 100%|██████████| 2/2 [00:00<00:00, 23.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77 Average Loss: 0.2622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 78/200: 100%|██████████| 2/2 [00:00<00:00, 24.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 78 Average Loss: 0.2592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 79/200: 100%|██████████| 2/2 [00:00<00:00, 27.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 79 Average Loss: 0.2614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 80/200: 100%|██████████| 2/2 [00:00<00:00, 26.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 80 Average Loss: 0.2576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 81/200: 100%|██████████| 2/2 [00:00<00:00, 26.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 81 Average Loss: 0.2592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 82/200: 100%|██████████| 2/2 [00:00<00:00, 26.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 82 Average Loss: 0.2541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 83/200: 100%|██████████| 2/2 [00:00<00:00, 26.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 83 Average Loss: 0.2553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 84/200: 100%|██████████| 2/2 [00:00<00:00, 26.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 84 Average Loss: 0.2531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 85/200: 100%|██████████| 2/2 [00:00<00:00, 25.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 85 Average Loss: 0.2604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 86/200: 100%|██████████| 2/2 [00:00<00:00, 26.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 86 Average Loss: 0.2566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 87/200: 100%|██████████| 2/2 [00:00<00:00, 23.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 87 Average Loss: 0.2554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 88/200: 100%|██████████| 2/2 [00:00<00:00, 25.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 88 Average Loss: 0.2547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 89/200: 100%|██████████| 2/2 [00:00<00:00, 26.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 89 Average Loss: 0.2520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 90/200: 100%|██████████| 2/2 [00:00<00:00, 26.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 90 Average Loss: 0.2556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 91/200: 100%|██████████| 2/2 [00:00<00:00, 27.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 91 Average Loss: 0.2533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 92/200: 100%|██████████| 2/2 [00:00<00:00, 26.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 92 Average Loss: 0.2537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 93/200: 100%|██████████| 2/2 [00:00<00:00, 27.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 93 Average Loss: 0.2490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 94/200: 100%|██████████| 2/2 [00:00<00:00, 26.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 94 Average Loss: 0.2509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 95/200: 100%|██████████| 2/2 [00:00<00:00, 26.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 95 Average Loss: 0.2521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 96/200: 100%|██████████| 2/2 [00:00<00:00, 26.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 96 Average Loss: 0.2552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 97/200: 100%|██████████| 2/2 [00:00<00:00, 26.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 97 Average Loss: 0.2503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 98/200: 100%|██████████| 2/2 [00:00<00:00, 26.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 98 Average Loss: 0.2483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 99/200: 100%|██████████| 2/2 [00:00<00:00, 26.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 99 Average Loss: 0.2471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 100/200: 100%|██████████| 2/2 [00:00<00:00, 23.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100 Average Loss: 0.2459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 101/200: 100%|██████████| 2/2 [00:00<00:00, 25.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 101 Average Loss: 0.2461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 102/200: 100%|██████████| 2/2 [00:00<00:00, 26.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 102 Average Loss: 0.2455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 103/200: 100%|██████████| 2/2 [00:00<00:00, 26.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 103 Average Loss: 0.2465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 104/200: 100%|██████████| 2/2 [00:00<00:00, 27.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 104 Average Loss: 0.2465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 105/200: 100%|██████████| 2/2 [00:00<00:00, 26.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 105 Average Loss: 0.2468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 106/200: 100%|██████████| 2/2 [00:00<00:00, 26.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 106 Average Loss: 0.2443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 107/200: 100%|██████████| 2/2 [00:00<00:00, 26.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 107 Average Loss: 0.2448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 108/200: 100%|██████████| 2/2 [00:00<00:00, 27.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 108 Average Loss: 0.2448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 109/200: 100%|██████████| 2/2 [00:00<00:00, 26.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 109 Average Loss: 0.2452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 110/200: 100%|██████████| 2/2 [00:00<00:00, 25.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 110 Average Loss: 0.2443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 111/200: 100%|██████████| 2/2 [00:00<00:00, 26.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 111 Average Loss: 0.2414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 112/200: 100%|██████████| 2/2 [00:00<00:00, 24.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 112 Average Loss: 0.2399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 113/200: 100%|██████████| 2/2 [00:00<00:00, 23.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 113 Average Loss: 0.2387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 114/200: 100%|██████████| 2/2 [00:00<00:00, 26.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 114 Average Loss: 0.2410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 115/200: 100%|██████████| 2/2 [00:00<00:00, 25.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 115 Average Loss: 0.2398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 116/200: 100%|██████████| 2/2 [00:00<00:00, 27.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 116 Average Loss: 0.2384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 117/200: 100%|██████████| 2/2 [00:00<00:00, 26.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 117 Average Loss: 0.2384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 118/200: 100%|██████████| 2/2 [00:00<00:00, 26.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 118 Average Loss: 0.2390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 119/200: 100%|██████████| 2/2 [00:00<00:00, 26.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 119 Average Loss: 0.2390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 120/200: 100%|██████████| 2/2 [00:00<00:00, 26.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 120 Average Loss: 0.2385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 121/200: 100%|██████████| 2/2 [00:00<00:00, 26.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 121 Average Loss: 0.2378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 122/200: 100%|██████████| 2/2 [00:00<00:00, 26.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 122 Average Loss: 0.2377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 123/200: 100%|██████████| 2/2 [00:00<00:00, 26.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 123 Average Loss: 0.2362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 124/200: 100%|██████████| 2/2 [00:00<00:00, 27.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 124 Average Loss: 0.2347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 125/200: 100%|██████████| 2/2 [00:00<00:00, 23.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 125 Average Loss: 0.2355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 126/200: 100%|██████████| 2/2 [00:00<00:00, 26.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 126 Average Loss: 0.2351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 127/200: 100%|██████████| 2/2 [00:00<00:00, 25.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 127 Average Loss: 0.2335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 128/200: 100%|██████████| 2/2 [00:00<00:00, 25.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 128 Average Loss: 0.2344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 129/200: 100%|██████████| 2/2 [00:00<00:00, 25.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 129 Average Loss: 0.2335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 130/200: 100%|██████████| 2/2 [00:00<00:00, 25.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 130 Average Loss: 0.2336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 131/200: 100%|██████████| 2/2 [00:00<00:00, 26.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 131 Average Loss: 0.2329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 132/200: 100%|██████████| 2/2 [00:00<00:00, 26.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 132 Average Loss: 0.2333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 133/200: 100%|██████████| 2/2 [00:00<00:00, 26.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 133 Average Loss: 0.2311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 134/200: 100%|██████████| 2/2 [00:00<00:00, 26.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 134 Average Loss: 0.2302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 135/200: 100%|██████████| 2/2 [00:00<00:00, 26.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 135 Average Loss: 0.2297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 136/200: 100%|██████████| 2/2 [00:00<00:00, 26.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 136 Average Loss: 0.2319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 137/200: 100%|██████████| 2/2 [00:00<00:00, 24.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 137 Average Loss: 0.2307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 138/200: 100%|██████████| 2/2 [00:00<00:00, 22.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 138 Average Loss: 0.2298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 139/200: 100%|██████████| 2/2 [00:00<00:00, 26.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 139 Average Loss: 0.2299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 140/200: 100%|██████████| 2/2 [00:00<00:00, 26.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 140 Average Loss: 0.2291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 141/200: 100%|██████████| 2/2 [00:00<00:00, 26.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 141 Average Loss: 0.2275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 142/200: 100%|██████████| 2/2 [00:00<00:00, 26.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 142 Average Loss: 0.2268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 143/200: 100%|██████████| 2/2 [00:00<00:00, 26.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 143 Average Loss: 0.2256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 144/200: 100%|██████████| 2/2 [00:00<00:00, 25.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 144 Average Loss: 0.2255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 145/200: 100%|██████████| 2/2 [00:00<00:00, 27.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 145 Average Loss: 0.2263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 146/200: 100%|██████████| 2/2 [00:00<00:00, 26.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 146 Average Loss: 0.2229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 147/200: 100%|██████████| 2/2 [00:00<00:00, 25.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 147 Average Loss: 0.2240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 148/200: 100%|██████████| 2/2 [00:00<00:00, 25.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 148 Average Loss: 0.2237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 149/200: 100%|██████████| 2/2 [00:00<00:00, 26.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 149 Average Loss: 0.2280\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 150/200: 100%|██████████| 2/2 [00:00<00:00, 22.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 150 Average Loss: 0.2270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 151/200: 100%|██████████| 2/2 [00:00<00:00, 25.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 151 Average Loss: 0.2490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 152/200: 100%|██████████| 2/2 [00:00<00:00, 26.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 152 Average Loss: 0.2277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 153/200: 100%|██████████| 2/2 [00:00<00:00, 26.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 153 Average Loss: 0.2590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 154/200: 100%|██████████| 2/2 [00:00<00:00, 26.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 154 Average Loss: 0.2244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 155/200: 100%|██████████| 2/2 [00:00<00:00, 25.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 155 Average Loss: 0.2357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 156/200: 100%|██████████| 2/2 [00:00<00:00, 26.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 156 Average Loss: 0.2387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 157/200: 100%|██████████| 2/2 [00:00<00:00, 26.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 157 Average Loss: 0.2333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 158/200: 100%|██████████| 2/2 [00:00<00:00, 25.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 158 Average Loss: 0.2259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 159/200: 100%|██████████| 2/2 [00:00<00:00, 26.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 159 Average Loss: 0.2318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 160/200: 100%|██████████| 2/2 [00:00<00:00, 25.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 160 Average Loss: 0.2209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 161/200: 100%|██████████| 2/2 [00:00<00:00, 26.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 161 Average Loss: 0.2244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 162/200: 100%|██████████| 2/2 [00:00<00:00, 26.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 162 Average Loss: 0.2272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 163/200: 100%|██████████| 2/2 [00:00<00:00, 21.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 163 Average Loss: 0.2272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 164/200: 100%|██████████| 2/2 [00:00<00:00, 26.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 164 Average Loss: 0.2227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 165/200: 100%|██████████| 2/2 [00:00<00:00, 25.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 165 Average Loss: 0.2180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 166/200: 100%|██████████| 2/2 [00:00<00:00, 26.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 166 Average Loss: 0.2224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 167/200: 100%|██████████| 2/2 [00:00<00:00, 27.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 167 Average Loss: 0.2202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 168/200: 100%|██████████| 2/2 [00:00<00:00, 26.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 168 Average Loss: 0.2208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 169/200: 100%|██████████| 2/2 [00:00<00:00, 26.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 169 Average Loss: 0.2229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 170/200: 100%|██████████| 2/2 [00:00<00:00, 26.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 170 Average Loss: 0.2211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 171/200: 100%|██████████| 2/2 [00:00<00:00, 26.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 171 Average Loss: 0.2158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 172/200: 100%|██████████| 2/2 [00:00<00:00, 25.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 172 Average Loss: 0.2146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 173/200: 100%|██████████| 2/2 [00:00<00:00, 19.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 173 Average Loss: 0.2179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 174/200: 100%|██████████| 2/2 [00:00<00:00, 21.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 174 Average Loss: 0.2152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 175/200: 100%|██████████| 2/2 [00:00<00:00, 16.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 175 Average Loss: 0.2161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 176/200: 100%|██████████| 2/2 [00:00<00:00, 22.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 176 Average Loss: 0.2149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 177/200: 100%|██████████| 2/2 [00:00<00:00, 23.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 177 Average Loss: 0.2102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 178/200: 100%|██████████| 2/2 [00:00<00:00, 18.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 178 Average Loss: 0.2134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 179/200: 100%|██████████| 2/2 [00:00<00:00, 23.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 179 Average Loss: 0.2087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 180/200: 100%|██████████| 2/2 [00:00<00:00, 23.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 180 Average Loss: 0.2114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 181/200: 100%|██████████| 2/2 [00:00<00:00, 20.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 181 Average Loss: 0.2089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 182/200: 100%|██████████| 2/2 [00:00<00:00, 20.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 182 Average Loss: 0.2085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 183/200: 100%|██████████| 2/2 [00:00<00:00, 23.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 183 Average Loss: 0.2074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 184/200: 100%|██████████| 2/2 [00:00<00:00, 21.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 184 Average Loss: 0.2072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 185/200: 100%|██████████| 2/2 [00:00<00:00, 16.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 185 Average Loss: 0.2060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 186/200: 100%|██████████| 2/2 [00:00<00:00, 21.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 186 Average Loss: 0.2059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 187/200: 100%|██████████| 2/2 [00:00<00:00, 22.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 187 Average Loss: 0.2045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 188/200: 100%|██████████| 2/2 [00:00<00:00, 20.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 188 Average Loss: 0.2081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 189/200: 100%|██████████| 2/2 [00:00<00:00, 23.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 189 Average Loss: 0.2049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 190/200: 100%|██████████| 2/2 [00:00<00:00, 20.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 190 Average Loss: 0.2074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 191/200: 100%|██████████| 2/2 [00:00<00:00, 22.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 191 Average Loss: 0.2059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 192/200: 100%|██████████| 2/2 [00:00<00:00, 22.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 192 Average Loss: 0.2035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 193/200: 100%|██████████| 2/2 [00:00<00:00, 21.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 193 Average Loss: 0.2034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 194/200: 100%|██████████| 2/2 [00:00<00:00, 21.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 194 Average Loss: 0.2015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 195/200: 100%|██████████| 2/2 [00:00<00:00, 19.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 195 Average Loss: 0.2027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 196/200: 100%|██████████| 2/2 [00:00<00:00, 17.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 196 Average Loss: 0.2039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 197/200: 100%|██████████| 2/2 [00:00<00:00, 18.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 197 Average Loss: 0.2018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 198/200: 100%|██████████| 2/2 [00:00<00:00, 20.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 198 Average Loss: 0.1991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 199/200: 100%|██████████| 2/2 [00:00<00:00, 20.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 199 Average Loss: 0.1982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 200/200: 100%|██████████| 2/2 [00:00<00:00, 18.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 200 Average Loss: 0.1977\n",
            "✅ Final model saved to trained_models/boundary_detector/final_model.pt\n",
            "✅ Final model logged as a W&B Artifact.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>finetune_batch_loss</td><td>█▇█▇▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▃▃▂▃▂▂▂▂▂▂▁▁▁▂▁▁</td></tr><tr><td>finetune_epoch_loss</td><td>█▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▃▃▃▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>finetune_batch_loss</td><td>0.19765</td></tr><tr><td>finetune_epoch_loss</td><td>0.19771</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dashing-sweep-5</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/j7ipu8ft' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/j7ipu8ft</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250719_074756-j7ipu8ft/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- STAGE 2 COMPLETE ---\n",
            "\n",
            "\n",
            "--- LAUNCHING PIPELINE 3: WELL-TO-WELL INFERENCE ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'W2W_Matcher_Pipeline_Notebook' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250719_074825-j7ipu8ft</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/j7ipu8ft' target=\"_blank\">dashing-sweep-5</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/j7ipu8ft' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/j7ipu8ft</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> W&B Run started. View at: https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/j7ipu8ft\n",
            "--> MOCK INFERENCE: Using ground truth layers for visualization.\n",
            "Error: Could not find '15_9-13 Sleipner East Appr' or '16/1-2  Ivar Aasen Appr'. Skipping.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dashing-sweep-5</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/j7ipu8ft' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/j7ipu8ft</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250719_074825-j7ipu8ft/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- STAGE 3 COMPLETE ---\n",
            "\n",
            "\n",
            "============================================================\n",
            "✅✅✅ All Requested Pipeline Stages are Complete! ✅✅✅\n",
            "You can now proceed to the final cell to generate multiple plots.\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 14. 📊 Generate Multiple Inference Plots (Corrected)\n",
        "\n",
        "# --- ACTION REQUIRED: Define the well pairs you want to plot ---\n",
        "# IMPORTANT: Copy the names EXACTLY as they appear in the output of Cell 5.\n",
        "# For example, notice that \"16/1-2  Ivar Aasen Appr\" has two spaces.\n",
        "well_pairs_to_plot = [\n",
        "    (\"15_9-13 Sleipner East Appr\", \"16/1-2  Ivar Aasen Appr\"),\n",
        "    (\"16/2-6 Johan Sverdrup\", \"16/5-3 Johan Sverdrup Appr\"),\n",
        "    (\"35/11-1\", \"35/11-6\"),\n",
        "    # Add more pairs here...\n",
        "]\n",
        "# -----------------------------------------------------------------\n",
        "\n",
        "print(f\"--> Preparing to generate {len(well_pairs_to_plot)} correlation plots.\")\n",
        "final_model_path = config['paths']['final_model_path']\n",
        "processed_csv_path = config['paths']['processed_csv_path']\n",
        "\n",
        "if not os.path.exists(final_model_path) or not os.path.exists(processed_csv_path):\n",
        "    print(\"\\n⚠️ Error: Cannot run inference. Please ensure the main pipeline (Cell 13) has been run successfully first.\")\n",
        "    print(f\"Missing file: {'Final Model' if not os.path.exists(final_model_path) else 'Processed Data'}\")\n",
        "else:\n",
        "    with wandb.init(project=config['wandb']['project'], entity=config['wandb'].get('entity'), job_type='multi-plot-inference') as run:\n",
        "        print(f\"--> W&B Run for multiple plots started. View at: {run.url}\")\n",
        "        full_data = pd.read_csv(processed_csv_path, delimiter=';')\n",
        "        plots_to_log = {}\n",
        "        for i, (well1, well2) in enumerate(well_pairs_to_plot):\n",
        "            print(f\"\\n--- Generating plot for: {well1} vs {well2} ---\")\n",
        "            # Create a filesystem-safe filename\n",
        "            safe_well1 = well1.replace('/','-').replace(' ','_')\n",
        "            safe_well2 = well2.replace('/','-').replace(' ','_')\n",
        "            output_filename = f\"correlation_{safe_well1}_vs_{safe_well2}.png\"\n",
        "\n",
        "            success = generate_single_correlation_plot(config, full_data, well1, well2, output_filename)\n",
        "            if success:\n",
        "                plots_to_log[f\"Plot_{i+1}_{well1}_vs_{well2}\"] = wandb.Image(output_filename)\n",
        "\n",
        "        if plots_to_log:\n",
        "            print(\"\\n--> Logging all plots to Weights & Biases...\")\n",
        "            wandb.log(plots_to_log)\n",
        "            print(\"✅ All plots logged successfully.\")\n",
        "        else:\n",
        "            print(\"\\n--> No plots were generated to log.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "EbJLZNpFh3m-",
        "outputId": "7fbddf97-b345-4874-8d41-9b1089948e1f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> Preparing to generate 3 correlation plots.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'W2W_Matcher_Pipeline_Notebook' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/W2W_Pipeline_WandB/wandb/run-20250719_075302-j7ipu8ft</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/j7ipu8ft' target=\"_blank\">dashing-sweep-5</a></strong> to <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/sweeps/13gryyv1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/j7ipu8ft' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/j7ipu8ft</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> W&B Run for multiple plots started. View at: https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/j7ipu8ft\n",
            "\n",
            "--- Generating plot for: 15_9-13 Sleipner East Appr vs 16/1-2  Ivar Aasen Appr ---\n",
            "Error: Could not find '15_9-13 Sleipner East Appr' or '16/1-2  Ivar Aasen Appr'. Please check for typos or extra spaces.\n",
            "\n",
            "--- Generating plot for: 16/2-6 Johan Sverdrup vs 16/5-3 Johan Sverdrup Appr ---\n",
            "--> Correlation plot saved to correlation_16-2-6_Johan_Sverdrup_vs_16-5-3_Johan_Sverdrup_Appr.png\n",
            "\n",
            "--- Generating plot for: 35/11-1 vs 35/11-6 ---\n",
            "--> Correlation plot saved to correlation_35-11-1_vs_35-11-6.png\n",
            "\n",
            "--> Logging all plots to Weights & Biases...\n",
            "✅ All plots logged successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dashing-sweep-5</strong> at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/j7ipu8ft' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook/runs/j7ipu8ft</a><br> View project at: <a href='https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook' target=\"_blank\">https://wandb.ai/sahilpareek203-amrita-vishwa-vidyapeetham/W2W_Matcher_Pipeline_Notebook</a><br>Synced 5 W&B file(s), 2 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250719_075302-j7ipu8ft/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}